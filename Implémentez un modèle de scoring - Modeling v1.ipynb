{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f20321d0",
   "metadata": {},
   "source": [
    "### Import librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d542465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "\n",
    "# Libraries for vizualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "\n",
    "# Library for ignoring warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "de18c6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show exact values on barplots\n",
    "def show_values(axs, orient=\"v\", space=.01):\n",
    "    def _single(ax):\n",
    "        if orient == \"v\":\n",
    "            for p in ax.patches:\n",
    "                _x = p.get_x() + p.get_width() / 2\n",
    "                _y = p.get_y() + p.get_height() + (p.get_height()*0.01)\n",
    "                value = '{:.0f}'.format(p.get_height())\n",
    "                ax.text(_x, _y, value, ha=\"center\") \n",
    "        elif orient == \"h\":\n",
    "            for p in ax.patches:\n",
    "                _x = p.get_x() + p.get_width() + float(space)\n",
    "                _y = p.get_y() + p.get_height() - (p.get_height()*0.5)\n",
    "                value = '{:.0f}'.format(p.get_width())\n",
    "                ax.text(_x, _y, value, ha=\"left\")\n",
    "\n",
    "    if isinstance(axs, np.ndarray):\n",
    "        for idx, ax in np.ndenumerate(axs):\n",
    "            _single(ax)\n",
    "    else:\n",
    "        _single(axs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd379b0f",
   "metadata": {},
   "source": [
    "### Import pre-processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd9c9467",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_nan40 = pd.read_csv('train_df_nan40.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d716b645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove special characters in train_df_nan40 feature names\n",
    "train_df_nan40.columns = train_df_nan40.columns.str.replace(':', '')\n",
    "train_df_nan40.columns = train_df_nan40.columns.str.replace(',', '')\n",
    "train_df_nan40.columns = train_df_nan40.columns.str.replace(']', '')\n",
    "train_df_nan40.columns = train_df_nan40.columns.str.replace('[', '')\n",
    "train_df_nan40.columns = train_df_nan40.columns.str.replace('{', '')\n",
    "train_df_nan40.columns = train_df_nan40.columns.str.replace('}', '')\n",
    "train_df_nan40.columns = train_df_nan40.columns.str.replace('\"', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5173ca9e",
   "metadata": {},
   "source": [
    "# Create and evaluate classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2336ee73",
   "metadata": {},
   "source": [
    "### Evaluate DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e076a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary functions\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e439a72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X (features matrix) and y (Target) from train_df_nan40\n",
    "X = train_df_nan40.drop(['index', 'SK_ID_CURR', 'TARGET'], 1)\n",
    "y = train_df_nan40.TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69e7d361",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracy scores\n",
      "[0.91927092 0.91927092 0.91926961 0.91926961 0.91926961]\n",
      "test_accuracy mean score\n",
      "0.919\n",
      "------------\n",
      "test_f1_weighted scores\n",
      "[0.88060421 0.88060421 0.88060229 0.88060229 0.88060229]\n",
      "test_f1_weighted mean score\n",
      "0.881\n",
      "------------\n",
      "test_roc_auc scores\n",
      "[0.5 0.5 0.5 0.5 0.5]\n",
      "test_roc_auc mean score\n",
      "0.5\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "# Create DummyClassifier with 'most_frequent' strategy\n",
    "dummy_clf = DummyClassifier(strategy = 'most_frequent')\n",
    "# Define cross validation strategy\n",
    "cv = StratifiedKFold(n_splits = 5, random_state = 1, shuffle = True)\n",
    "# Define scoring strategy\n",
    "scoring = ('accuracy', 'f1_weighted', 'roc_auc')\n",
    "# Evaluate accuracy, AUC and f1 scores after cross validation\n",
    "scores = cross_validate(dummy_clf, \n",
    "                        X, y, \n",
    "                        cv = cv,\n",
    "                        scoring = scoring)\n",
    "\n",
    "# Print test scores and mean scores for each metric\n",
    "list_scoring = ['test_accuracy', 'test_f1_weighted', 'test_roc_auc']\n",
    "for score in list_scoring:\n",
    "    print(f'{score} scores')\n",
    "    print(scores[score])\n",
    "    print(f'{score} mean score')\n",
    "    print(round(scores[score].mean(), 3))\n",
    "    print('------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f35146",
   "metadata": {},
   "source": [
    "-> accuracy mean score = 0.919 just means that the majority class represents 91.9% of the whole dataset\n",
    "-> roc_auc mean score = 0.5 corresponds to the score of a random classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f1afb01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracy scores\n",
      "[0.85115931 0.85161458 0.85250646 0.85109185 0.85060406]\n",
      "test_accuracy mean score\n",
      "0.851\n",
      "------------\n",
      "test_f1_weighted scores\n",
      "[0.85089843 0.85140943 0.8526484  0.85114652 0.85091809]\n",
      "test_f1_weighted mean score\n",
      "0.851\n",
      "------------\n",
      "test_roc_auc scores\n",
      "[0.49866435 0.4998129  0.49772107 0.49811847 0.49834925]\n",
      "test_roc_auc mean score\n",
      "0.499\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "# Create DummyClassifier with 'stratified' strategy\n",
    "dummy_clf = DummyClassifier(strategy = 'stratified')\n",
    "# Define cv strategy\n",
    "cv = StratifiedKFold(n_splits = 5, random_state = 1, shuffle = True)\n",
    "# Define scoring strategy\n",
    "scoring = ('accuracy', 'f1_weighted', 'roc_auc')\n",
    "# Evaluate accuracy, AUC and f1 scores after cross validation\n",
    "scores = cross_validate(dummy_clf, \n",
    "                        X, y, \n",
    "                        cv = cv,\n",
    "                        scoring = scoring)\n",
    "\n",
    "# Print test scores and mean scores for each metric\n",
    "list_scoring = ['test_accuracy', 'test_f1_weighted', 'test_roc_auc']\n",
    "for score in list_scoring:\n",
    "    print(f'{score} scores')\n",
    "    print(scores[score])\n",
    "    print(f'{score} mean score')\n",
    "    print(round(scores[score].mean(), 3))\n",
    "    print('------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae52e305",
   "metadata": {},
   "source": [
    "-> roc_auc mean score = 0.499 corresponds to the score of a random classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efb0a91",
   "metadata": {},
   "source": [
    "-> Other classifiers will be evaluated using roc_auc scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0f060a",
   "metadata": {},
   "source": [
    "### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4eba4f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END ..............., score=(train=0.663, test=0.658) total time= 1.3min\n",
      "[CV 2/5] END ..............., score=(train=0.672, test=0.667) total time=  22.5s\n",
      "[CV 3/5] END ..............., score=(train=0.671, test=0.674) total time=  26.2s\n",
      "[CV 4/5] END ..............., score=(train=0.669, test=0.664) total time=  21.1s\n",
      "[CV 5/5] END ..............., score=(train=0.659, test=0.664) total time=  23.2s\n",
      "cv_score_lgbm: 0.665507676587798\n",
      "Execution time in seconds: 206.40424728393555\n",
      "Execution time in minutes: 3.4400707880655923\n"
     ]
    }
   ],
   "source": [
    "# SGD Classifier with scaler/classifier pipeline (no oversampling)\n",
    "# Using default parameters\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "startFitTime = time.time()\n",
    "\n",
    "# Create pipeline (imbpipeline)\n",
    "pipeline = Pipeline(steps = [['scaler', StandardScaler()],\n",
    "                             ['classifier', SGDClassifier(random_state = 11)]])\n",
    "\n",
    "# Define stratifiedKfold\n",
    "stratified_kfold = StratifiedKFold(n_splits = 5,\n",
    "                                   shuffle = True,\n",
    "                                   random_state = 11)\n",
    "\n",
    "# Using default parameters\n",
    "param_grid = {}\n",
    "\n",
    "gs_sgdc_default = GridSearchCV(estimator = pipeline,\n",
    "                               param_grid = param_grid,\n",
    "                               scoring = 'roc_auc',\n",
    "                               cv = stratified_kfold,\n",
    "                               verbose = 5,\n",
    "                               return_train_score = True)\n",
    "\n",
    "\n",
    "gs_sgdc_default.fit(X, y)\n",
    "\n",
    "cv_score_sgdc_default = gs_sgdc_default.best_score_\n",
    "print('cv_score_sgdc_default:', cv_score_sgdc_default)\n",
    "\n",
    "cv_results_sgdc_default = gs_sgdc_default.cv_results_\n",
    "df_sgdc_default = pd.DataFrame(cv_results_sgdc_default)\n",
    "\n",
    "executionFitTime = (time.time() - startFitTime)\n",
    "print('Execution time in seconds: ' + str(executionFitTime))\n",
    "print('Execution time in minutes: ' + str(executionFitTime / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc541fd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV 1/5] END classifier__alpha=0.0001, classifier__loss=hinge, classifier__max_iter=1000, classifier__penalty=l2;, score=(train=0.645, test=0.646) total time=  22.9s\n",
      "[CV 2/5] END classifier__alpha=0.0001, classifier__loss=hinge, classifier__max_iter=1000, classifier__penalty=l2;, score=(train=0.688, test=0.686) total time=  33.3s\n",
      "[CV 3/5] END classifier__alpha=0.0001, classifier__loss=hinge, classifier__max_iter=1000, classifier__penalty=l2;, score=(train=0.667, test=0.664) total time=  20.5s\n",
      "[CV 4/5] END classifier__alpha=0.0001, classifier__loss=hinge, classifier__max_iter=1000, classifier__penalty=l2;, score=(train=0.658, test=0.650) total time=  21.4s\n",
      "[CV 5/5] END classifier__alpha=0.0001, classifier__loss=hinge, classifier__max_iter=1000, classifier__penalty=l2;, score=(train=0.657, test=0.654) total time=  18.1s\n",
      "[CV 1/5] END classifier__alpha=0.0001, classifier__loss=log, classifier__max_iter=1000, classifier__penalty=l2;, score=(train=0.757, test=0.751) total time=  27.6s\n",
      "[CV 2/5] END classifier__alpha=0.0001, classifier__loss=log, classifier__max_iter=1000, classifier__penalty=l2;, score=(train=0.745, test=0.741) total time=  18.2s\n",
      "[CV 3/5] END classifier__alpha=0.0001, classifier__loss=log, classifier__max_iter=1000, classifier__penalty=l2;, score=(train=0.747, test=0.742) total time=  17.0s\n",
      "[CV 4/5] END classifier__alpha=0.0001, classifier__loss=log, classifier__max_iter=1000, classifier__penalty=l2;, score=(train=0.746, test=0.743) total time=  17.7s\n",
      "[CV 5/5] END classifier__alpha=0.0001, classifier__loss=log, classifier__max_iter=1000, classifier__penalty=l2;, score=(train=0.752, test=0.743) total time=  19.5s\n",
      "[CV 1/5] END classifier__alpha=0.01, classifier__loss=hinge, classifier__max_iter=1000, classifier__penalty=l2;, score=(train=0.692, test=0.689) total time=  21.4s\n",
      "[CV 2/5] END classifier__alpha=0.01, classifier__loss=hinge, classifier__max_iter=1000, classifier__penalty=l2;, score=(train=0.759, test=0.755) total time=  52.9s\n",
      "[CV 3/5] END classifier__alpha=0.01, classifier__loss=hinge, classifier__max_iter=1000, classifier__penalty=l2;, score=(train=0.683, test=0.672) total time=  20.7s\n",
      "[CV 4/5] END classifier__alpha=0.01, classifier__loss=hinge, classifier__max_iter=1000, classifier__penalty=l2;, score=(train=0.667, test=0.664) total time=  16.7s\n",
      "[CV 5/5] END classifier__alpha=0.01, classifier__loss=hinge, classifier__max_iter=1000, classifier__penalty=l2;, score=(train=0.668, test=0.670) total time=  12.0s\n",
      "[CV 1/5] END classifier__alpha=0.01, classifier__loss=log, classifier__max_iter=1000, classifier__penalty=l2;, score=(train=0.769, test=0.765) total time=  11.5s\n",
      "[CV 2/5] END classifier__alpha=0.01, classifier__loss=log, classifier__max_iter=1000, classifier__penalty=l2;, score=(train=0.768, test=0.766) total time=  14.6s\n",
      "[CV 3/5] END classifier__alpha=0.01, classifier__loss=log, classifier__max_iter=1000, classifier__penalty=l2;, score=(train=0.768, test=0.764) total time=  21.9s\n",
      "[CV 4/5] END classifier__alpha=0.01, classifier__loss=log, classifier__max_iter=1000, classifier__penalty=l2;, score=(train=0.768, test=0.761) total time=  22.7s\n",
      "[CV 5/5] END classifier__alpha=0.01, classifier__loss=log, classifier__max_iter=1000, classifier__penalty=l2;, score=(train=0.768, test=0.762) total time=  39.9s\n",
      "[CV 1/5] END classifier__alpha=1.0, classifier__loss=hinge, classifier__max_iter=1000, classifier__penalty=l2;, score=(train=0.760, test=0.755) total time=  10.1s\n",
      "[CV 2/5] END classifier__alpha=1.0, classifier__loss=hinge, classifier__max_iter=1000, classifier__penalty=l2;, score=(train=0.709, test=0.711) total time=  20.6s\n",
      "[CV 3/5] END classifier__alpha=1.0, classifier__loss=hinge, classifier__max_iter=1000, classifier__penalty=l2;, score=(train=0.708, test=0.708) total time=  20.9s\n",
      "[CV 4/5] END classifier__alpha=1.0, classifier__loss=hinge, classifier__max_iter=1000, classifier__penalty=l2;, score=(train=0.705, test=0.703) total time=  17.4s\n",
      "[CV 5/5] END classifier__alpha=1.0, classifier__loss=hinge, classifier__max_iter=1000, classifier__penalty=l2;, score=(train=0.729, test=0.725) total time=   8.9s\n",
      "[CV 1/5] END classifier__alpha=1.0, classifier__loss=log, classifier__max_iter=1000, classifier__penalty=l2;, score=(train=0.722, test=0.721) total time=   9.2s\n",
      "[CV 2/5] END classifier__alpha=1.0, classifier__loss=log, classifier__max_iter=1000, classifier__penalty=l2;, score=(train=0.723, test=0.724) total time=   8.2s\n",
      "[CV 3/5] END classifier__alpha=1.0, classifier__loss=log, classifier__max_iter=1000, classifier__penalty=l2;, score=(train=0.722, test=0.722) total time=   8.5s\n",
      "[CV 4/5] END classifier__alpha=1.0, classifier__loss=log, classifier__max_iter=1000, classifier__penalty=l2;, score=(train=0.725, test=0.721) total time=   9.3s\n",
      "[CV 5/5] END classifier__alpha=1.0, classifier__loss=log, classifier__max_iter=1000, classifier__penalty=l2;, score=(train=0.728, test=0.724) total time=   9.0s\n",
      "[CV 1/5] END classifier__alpha=100.0, classifier__loss=hinge, classifier__max_iter=1000, classifier__penalty=l2;, score=(train=0.703, test=0.702) total time=  13.1s\n",
      "[CV 2/5] END classifier__alpha=100.0, classifier__loss=hinge, classifier__max_iter=1000, classifier__penalty=l2;, score=(train=0.702, test=0.704) total time=  13.2s\n",
      "[CV 3/5] END classifier__alpha=100.0, classifier__loss=hinge, classifier__max_iter=1000, classifier__penalty=l2;, score=(train=0.702, test=0.702) total time=  18.1s\n",
      "[CV 4/5] END classifier__alpha=100.0, classifier__loss=hinge, classifier__max_iter=1000, classifier__penalty=l2;, score=(train=0.703, test=0.700) total time=  10.9s\n",
      "[CV 5/5] END classifier__alpha=100.0, classifier__loss=hinge, classifier__max_iter=1000, classifier__penalty=l2;, score=(train=0.703, test=0.699) total time=  10.2s\n",
      "[CV 1/5] END classifier__alpha=100.0, classifier__loss=log, classifier__max_iter=1000, classifier__penalty=l2;, score=(train=0.704, test=0.703) total time=   7.5s\n",
      "[CV 2/5] END classifier__alpha=100.0, classifier__loss=log, classifier__max_iter=1000, classifier__penalty=l2;, score=(train=0.703, test=0.705) total time=   7.6s\n",
      "[CV 3/5] END classifier__alpha=100.0, classifier__loss=log, classifier__max_iter=1000, classifier__penalty=l2;, score=(train=0.703, test=0.703) total time=   7.8s\n",
      "[CV 4/5] END classifier__alpha=100.0, classifier__loss=log, classifier__max_iter=1000, classifier__penalty=l2;, score=(train=0.704, test=0.701) total time=   7.2s\n",
      "[CV 5/5] END classifier__alpha=100.0, classifier__loss=log, classifier__max_iter=1000, classifier__penalty=l2;, score=(train=0.704, test=0.700) total time=   7.1s\n",
      "cv_score_sgdc: 0.7633640385540257\n",
      "Execution time in seconds: 765.6950597763062\n",
      "Execution time in minutes: 12.761584329605103\n"
     ]
    }
   ],
   "source": [
    "# SGD Classifier with scaler/classifier pipeline (no oversampling)\n",
    "# Testing parameters with gridsearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "startFitTime = time.time()\n",
    "\n",
    "# Create pipeline (imbpipeline)\n",
    "pipeline = Pipeline(steps = [['scaler', StandardScaler()],\n",
    "                             ['classifier', SGDClassifier()]])\n",
    "\n",
    "# Define stratifiedKfold\n",
    "stratified_kfold = StratifiedKFold(n_splits = 5,\n",
    "                                   shuffle = True,\n",
    "                                   random_state = 11)\n",
    "\n",
    "# Testing different parameters\n",
    "param_grid = {'classifier__alpha': [1e-4, 1e-2, 1e0, 1e2], # learning rate\n",
    "              'classifier__max_iter': [1000], # number of epochs,\n",
    "              'classifier__loss': ['hinge', 'log'], # linear SVM or logistic regression,\n",
    "              'classifier__penalty': ['l2']}\n",
    "\n",
    "gs_sgdc = GridSearchCV(estimator = pipeline,\n",
    "                       param_grid = param_grid,\n",
    "                       scoring = 'roc_auc',\n",
    "                       cv = stratified_kfold,\n",
    "                       verbose = 5,\n",
    "                       return_train_score = True)\n",
    "\n",
    "\n",
    "gs_sgdc.fit(X, y)\n",
    "\n",
    "cv_score_sgdc = gs_sgdc.best_score_\n",
    "print('cv_score_sgdc:', cv_score_sgdc)\n",
    "\n",
    "cv_results_sgdc = gs_sgdc.cv_results_\n",
    "df_sgdc = pd.DataFrame(cv_results_sgdc)\n",
    "\n",
    "executionFitTime = (time.time() - startFitTime)\n",
    "print('Execution time in seconds: ' + str(executionFitTime))\n",
    "print('Execution time in minutes: ' + str(executionFitTime / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7471c8ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "param_classifier__loss\n",
       "hinge    0.693008\n",
       "log      0.733115\n",
       "Name: mean_test_score, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare loss params : hinge (linearSVM) and log(logistic regression)\n",
    "df_sgdc.groupby('param_classifier__loss')['mean_test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04f80f9",
   "metadata": {},
   "source": [
    "-> Logistic regression results in better roc_auc scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e17f79e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__alpha</th>\n",
       "      <th>param_classifier__loss</th>\n",
       "      <th>param_classifier__max_iter</th>\n",
       "      <th>param_classifier__penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.769146</td>\n",
       "      <td>9.813351</td>\n",
       "      <td>0.465238</td>\n",
       "      <td>0.152395</td>\n",
       "      <td>0.01</td>\n",
       "      <td>log</td>\n",
       "      <td>1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'classifier__alpha': 0.01, 'classifier__loss'...</td>\n",
       "      <td>0.764517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.763364</td>\n",
       "      <td>0.001704</td>\n",
       "      <td>1</td>\n",
       "      <td>0.769062</td>\n",
       "      <td>0.768191</td>\n",
       "      <td>0.767918</td>\n",
       "      <td>0.768153</td>\n",
       "      <td>0.768259</td>\n",
       "      <td>0.768316</td>\n",
       "      <td>0.000390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.686957</td>\n",
       "      <td>3.812885</td>\n",
       "      <td>0.418668</td>\n",
       "      <td>0.075504</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>log</td>\n",
       "      <td>1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'classifier__alpha': 0.0001, 'classifier__los...</td>\n",
       "      <td>0.751428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.744100</td>\n",
       "      <td>0.003717</td>\n",
       "      <td>2</td>\n",
       "      <td>0.756864</td>\n",
       "      <td>0.745054</td>\n",
       "      <td>0.746666</td>\n",
       "      <td>0.745915</td>\n",
       "      <td>0.751584</td>\n",
       "      <td>0.749217</td>\n",
       "      <td>0.004446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.295024</td>\n",
       "      <td>0.453398</td>\n",
       "      <td>0.622081</td>\n",
       "      <td>0.214608</td>\n",
       "      <td>1.0</td>\n",
       "      <td>log</td>\n",
       "      <td>1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'classifier__alpha': 1.0, 'classifier__loss':...</td>\n",
       "      <td>0.720581</td>\n",
       "      <td>...</td>\n",
       "      <td>0.722398</td>\n",
       "      <td>0.001533</td>\n",
       "      <td>3</td>\n",
       "      <td>0.721814</td>\n",
       "      <td>0.722815</td>\n",
       "      <td>0.722291</td>\n",
       "      <td>0.724871</td>\n",
       "      <td>0.727825</td>\n",
       "      <td>0.723923</td>\n",
       "      <td>0.002212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.970112</td>\n",
       "      <td>4.955132</td>\n",
       "      <td>0.694214</td>\n",
       "      <td>0.303806</td>\n",
       "      <td>1.0</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'classifier__alpha': 1.0, 'classifier__loss':...</td>\n",
       "      <td>0.754995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.720236</td>\n",
       "      <td>0.018813</td>\n",
       "      <td>4</td>\n",
       "      <td>0.760214</td>\n",
       "      <td>0.708963</td>\n",
       "      <td>0.708457</td>\n",
       "      <td>0.704915</td>\n",
       "      <td>0.729412</td>\n",
       "      <td>0.722392</td>\n",
       "      <td>0.020783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.162304</td>\n",
       "      <td>0.242792</td>\n",
       "      <td>0.402341</td>\n",
       "      <td>0.059074</td>\n",
       "      <td>100.0</td>\n",
       "      <td>log</td>\n",
       "      <td>1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'classifier__alpha': 100.0, 'classifier__loss...</td>\n",
       "      <td>0.703053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.702599</td>\n",
       "      <td>0.001612</td>\n",
       "      <td>5</td>\n",
       "      <td>0.703664</td>\n",
       "      <td>0.703395</td>\n",
       "      <td>0.703431</td>\n",
       "      <td>0.703678</td>\n",
       "      <td>0.704082</td>\n",
       "      <td>0.703650</td>\n",
       "      <td>0.000245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12.366454</td>\n",
       "      <td>2.819907</td>\n",
       "      <td>0.828855</td>\n",
       "      <td>0.732299</td>\n",
       "      <td>100.0</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'classifier__alpha': 100.0, 'classifier__loss...</td>\n",
       "      <td>0.702055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.701638</td>\n",
       "      <td>0.001611</td>\n",
       "      <td>6</td>\n",
       "      <td>0.702657</td>\n",
       "      <td>0.702442</td>\n",
       "      <td>0.702441</td>\n",
       "      <td>0.702716</td>\n",
       "      <td>0.703096</td>\n",
       "      <td>0.702671</td>\n",
       "      <td>0.000240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.294172</td>\n",
       "      <td>14.536203</td>\n",
       "      <td>0.524458</td>\n",
       "      <td>0.195153</td>\n",
       "      <td>0.01</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'classifier__alpha': 0.01, 'classifier__loss'...</td>\n",
       "      <td>0.688977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.690103</td>\n",
       "      <td>0.033700</td>\n",
       "      <td>7</td>\n",
       "      <td>0.691822</td>\n",
       "      <td>0.759005</td>\n",
       "      <td>0.682961</td>\n",
       "      <td>0.666758</td>\n",
       "      <td>0.667529</td>\n",
       "      <td>0.693615</td>\n",
       "      <td>0.034042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.766879</td>\n",
       "      <td>3.293911</td>\n",
       "      <td>1.579971</td>\n",
       "      <td>2.132744</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'classifier__alpha': 0.0001, 'classifier__los...</td>\n",
       "      <td>0.646323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.660054</td>\n",
       "      <td>0.014147</td>\n",
       "      <td>8</td>\n",
       "      <td>0.644515</td>\n",
       "      <td>0.688343</td>\n",
       "      <td>0.667357</td>\n",
       "      <td>0.658472</td>\n",
       "      <td>0.657350</td>\n",
       "      <td>0.663207</td>\n",
       "      <td>0.014527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "3      21.769146      9.813351         0.465238        0.152395   \n",
       "1      19.686957      3.812885         0.418668        0.075504   \n",
       "5       8.295024      0.453398         0.622081        0.214608   \n",
       "4      14.970112      4.955132         0.694214        0.303806   \n",
       "7       7.162304      0.242792         0.402341        0.059074   \n",
       "6      12.366454      2.819907         0.828855        0.732299   \n",
       "2      24.294172     14.536203         0.524458        0.195153   \n",
       "0      21.766879      3.293911         1.579971        2.132744   \n",
       "\n",
       "  param_classifier__alpha param_classifier__loss param_classifier__max_iter  \\\n",
       "3                    0.01                    log                       1000   \n",
       "1                  0.0001                    log                       1000   \n",
       "5                     1.0                    log                       1000   \n",
       "4                     1.0                  hinge                       1000   \n",
       "7                   100.0                    log                       1000   \n",
       "6                   100.0                  hinge                       1000   \n",
       "2                    0.01                  hinge                       1000   \n",
       "0                  0.0001                  hinge                       1000   \n",
       "\n",
       "  param_classifier__penalty  \\\n",
       "3                        l2   \n",
       "1                        l2   \n",
       "5                        l2   \n",
       "4                        l2   \n",
       "7                        l2   \n",
       "6                        l2   \n",
       "2                        l2   \n",
       "0                        l2   \n",
       "\n",
       "                                              params  split0_test_score  ...  \\\n",
       "3  {'classifier__alpha': 0.01, 'classifier__loss'...           0.764517  ...   \n",
       "1  {'classifier__alpha': 0.0001, 'classifier__los...           0.751428  ...   \n",
       "5  {'classifier__alpha': 1.0, 'classifier__loss':...           0.720581  ...   \n",
       "4  {'classifier__alpha': 1.0, 'classifier__loss':...           0.754995  ...   \n",
       "7  {'classifier__alpha': 100.0, 'classifier__loss...           0.703053  ...   \n",
       "6  {'classifier__alpha': 100.0, 'classifier__loss...           0.702055  ...   \n",
       "2  {'classifier__alpha': 0.01, 'classifier__loss'...           0.688977  ...   \n",
       "0  {'classifier__alpha': 0.0001, 'classifier__los...           0.646323  ...   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "3         0.763364        0.001704                1            0.769062   \n",
       "1         0.744100        0.003717                2            0.756864   \n",
       "5         0.722398        0.001533                3            0.721814   \n",
       "4         0.720236        0.018813                4            0.760214   \n",
       "7         0.702599        0.001612                5            0.703664   \n",
       "6         0.701638        0.001611                6            0.702657   \n",
       "2         0.690103        0.033700                7            0.691822   \n",
       "0         0.660054        0.014147                8            0.644515   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "3            0.768191            0.767918            0.768153   \n",
       "1            0.745054            0.746666            0.745915   \n",
       "5            0.722815            0.722291            0.724871   \n",
       "4            0.708963            0.708457            0.704915   \n",
       "7            0.703395            0.703431            0.703678   \n",
       "6            0.702442            0.702441            0.702716   \n",
       "2            0.759005            0.682961            0.666758   \n",
       "0            0.688343            0.667357            0.658472   \n",
       "\n",
       "   split4_train_score  mean_train_score  std_train_score  \n",
       "3            0.768259          0.768316         0.000390  \n",
       "1            0.751584          0.749217         0.004446  \n",
       "5            0.727825          0.723923         0.002212  \n",
       "4            0.729412          0.722392         0.020783  \n",
       "7            0.704082          0.703650         0.000245  \n",
       "6            0.703096          0.702671         0.000240  \n",
       "2            0.667529          0.693615         0.034042  \n",
       "0            0.657350          0.663207         0.014527  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort results by mean_test_score in df_sgdc\n",
    "df_sgdc.sort_values(by = 'mean_test_score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0303d923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__alpha': 0.01,\n",
       " 'classifier__loss': 'log',\n",
       " 'classifier__max_iter': 1000,\n",
       " 'classifier__penalty': 'l2'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the best parameters\n",
    "gs_sgdc.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9895d347",
   "metadata": {},
   "source": [
    "-> Those parameters will be used with SMOTE oversampling in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b3d66b0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END classifier__alpha=0.01, classifier__loss=log, classifier__max_iter=1000, classifier__penalty=l2, smote__sampling_strategy=0.25;, score=(train=0.755, test=0.751) total time=  36.0s\n",
      "[CV 2/5] END classifier__alpha=0.01, classifier__loss=log, classifier__max_iter=1000, classifier__penalty=l2, smote__sampling_strategy=0.25;, score=(train=0.755, test=0.753) total time=  36.8s\n",
      "[CV 3/5] END classifier__alpha=0.01, classifier__loss=log, classifier__max_iter=1000, classifier__penalty=l2, smote__sampling_strategy=0.25;, score=(train=0.755, test=0.752) total time=  35.2s\n",
      "[CV 4/5] END classifier__alpha=0.01, classifier__loss=log, classifier__max_iter=1000, classifier__penalty=l2, smote__sampling_strategy=0.25;, score=(train=0.756, test=0.749) total time=  33.9s\n",
      "[CV 5/5] END classifier__alpha=0.01, classifier__loss=log, classifier__max_iter=1000, classifier__penalty=l2, smote__sampling_strategy=0.25;, score=(train=0.757, test=0.751) total time=  34.6s\n",
      "[CV 1/5] END classifier__alpha=0.01, classifier__loss=log, classifier__max_iter=1000, classifier__penalty=l2, smote__sampling_strategy=0.5;, score=(train=0.748, test=0.744) total time=  35.3s\n",
      "[CV 2/5] END classifier__alpha=0.01, classifier__loss=log, classifier__max_iter=1000, classifier__penalty=l2, smote__sampling_strategy=0.5;, score=(train=0.747, test=0.746) total time=  47.0s\n",
      "[CV 3/5] END classifier__alpha=0.01, classifier__loss=log, classifier__max_iter=1000, classifier__penalty=l2, smote__sampling_strategy=0.5;, score=(train=0.748, test=0.743) total time=  38.4s\n",
      "[CV 4/5] END classifier__alpha=0.01, classifier__loss=log, classifier__max_iter=1000, classifier__penalty=l2, smote__sampling_strategy=0.5;, score=(train=0.748, test=0.741) total time=  36.0s\n",
      "[CV 5/5] END classifier__alpha=0.01, classifier__loss=log, classifier__max_iter=1000, classifier__penalty=l2, smote__sampling_strategy=0.5;, score=(train=0.748, test=0.742) total time=  37.3s\n",
      "[CV 1/5] END classifier__alpha=0.01, classifier__loss=log, classifier__max_iter=1000, classifier__penalty=l2, smote__sampling_strategy=1;, score=(train=0.737, test=0.734) total time=  56.4s\n",
      "[CV 2/5] END classifier__alpha=0.01, classifier__loss=log, classifier__max_iter=1000, classifier__penalty=l2, smote__sampling_strategy=1;, score=(train=0.735, test=0.733) total time=  51.7s\n",
      "[CV 3/5] END classifier__alpha=0.01, classifier__loss=log, classifier__max_iter=1000, classifier__penalty=l2, smote__sampling_strategy=1;, score=(train=0.738, test=0.733) total time=  45.1s\n",
      "[CV 4/5] END classifier__alpha=0.01, classifier__loss=log, classifier__max_iter=1000, classifier__penalty=l2, smote__sampling_strategy=1;, score=(train=0.737, test=0.731) total time=  58.5s\n",
      "[CV 5/5] END classifier__alpha=0.01, classifier__loss=log, classifier__max_iter=1000, classifier__penalty=l2, smote__sampling_strategy=1;, score=(train=0.737, test=0.731) total time=  51.2s\n",
      "cv_score_sgdc_smote: 0.751239622373773\n",
      "Execution time in seconds: 717.4766738414764\n",
      "Execution time in minutes: 11.957944564024608\n"
     ]
    }
   ],
   "source": [
    "# SGD Classifier with smote/scaler/classifier pipeline (oversampling)\n",
    "# Testing smote parameters with gridsearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "startFitTime = time.time()\n",
    "\n",
    "# Create pipeline (imbpipeline) with smote, scaler and classifier steps\n",
    "# imbpipeline automatically skip the sampling method (smote) when predict is called\n",
    "# -> Consequently, there is no data leakage\n",
    "pipeline = Pipeline(steps = [['smote', SMOTE(random_state = 11)],\n",
    "                             ['scaler', StandardScaler()],\n",
    "                             ['classifier', SGDClassifier()]])\n",
    "\n",
    "# Define stratifiedKfold\n",
    "stratified_kfold = StratifiedKFold(n_splits = 5,\n",
    "                                   shuffle = True,\n",
    "                                   random_state = 11)\n",
    "\n",
    "# Testing different parameters\n",
    "param_grid = {'smote__sampling_strategy' : [0.25, 0.5, 1],\n",
    "              'classifier__alpha': [1e-2], # learning rate\n",
    "              'classifier__max_iter': [1000], # number of epochs,\n",
    "              'classifier__loss': ['log'], # linear SVM or logistic regression,\n",
    "              'classifier__penalty': ['l2']}\n",
    "\n",
    "gs_sgdc_smote = GridSearchCV(estimator = pipeline,\n",
    "                             param_grid = param_grid,\n",
    "                             scoring = 'roc_auc',\n",
    "                             cv = stratified_kfold,\n",
    "                             verbose = 5,\n",
    "                             return_train_score = True)\n",
    "\n",
    "gs_sgdc_smote.fit(X, y)\n",
    "\n",
    "cv_score_sgdc_smote = gs_sgdc_smote.best_score_\n",
    "print('cv_score_sgdc_smote:', cv_score_sgdc_smote)\n",
    "\n",
    "cv_results_sgdc_smote = gs_sgdc_smote.cv_results_\n",
    "df_sgdc_smote = pd.DataFrame(cv_results_sgdc_smote)\n",
    "\n",
    "executionFitTime = (time.time() - startFitTime)\n",
    "print('Execution time in seconds: ' + str(executionFitTime))\n",
    "print('Execution time in minutes: ' + str(executionFitTime / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "17a3dcfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__alpha</th>\n",
       "      <th>param_classifier__loss</th>\n",
       "      <th>param_classifier__max_iter</th>\n",
       "      <th>param_classifier__penalty</th>\n",
       "      <th>param_smote__sampling_strategy</th>\n",
       "      <th>params</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.792451</td>\n",
       "      <td>1.001144</td>\n",
       "      <td>0.616272</td>\n",
       "      <td>0.124436</td>\n",
       "      <td>0.01</td>\n",
       "      <td>log</td>\n",
       "      <td>1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'classifier__alpha': 0.01, 'classifier__loss'...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751240</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>1</td>\n",
       "      <td>0.755331</td>\n",
       "      <td>0.755175</td>\n",
       "      <td>0.755476</td>\n",
       "      <td>0.755935</td>\n",
       "      <td>0.756684</td>\n",
       "      <td>0.755720</td>\n",
       "      <td>0.000545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.165315</td>\n",
       "      <td>3.879312</td>\n",
       "      <td>0.749596</td>\n",
       "      <td>0.343286</td>\n",
       "      <td>0.01</td>\n",
       "      <td>log</td>\n",
       "      <td>1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'classifier__alpha': 0.01, 'classifier__loss'...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743208</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>2</td>\n",
       "      <td>0.747575</td>\n",
       "      <td>0.747377</td>\n",
       "      <td>0.747551</td>\n",
       "      <td>0.747856</td>\n",
       "      <td>0.747710</td>\n",
       "      <td>0.747614</td>\n",
       "      <td>0.000161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51.489682</td>\n",
       "      <td>4.364350</td>\n",
       "      <td>1.192805</td>\n",
       "      <td>0.339977</td>\n",
       "      <td>0.01</td>\n",
       "      <td>log</td>\n",
       "      <td>1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>1</td>\n",
       "      <td>{'classifier__alpha': 0.01, 'classifier__loss'...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.732377</td>\n",
       "      <td>0.001276</td>\n",
       "      <td>3</td>\n",
       "      <td>0.737048</td>\n",
       "      <td>0.734762</td>\n",
       "      <td>0.737636</td>\n",
       "      <td>0.737287</td>\n",
       "      <td>0.736520</td>\n",
       "      <td>0.736650</td>\n",
       "      <td>0.001012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      34.792451      1.001144         0.616272        0.124436   \n",
       "1      38.165315      3.879312         0.749596        0.343286   \n",
       "2      51.489682      4.364350         1.192805        0.339977   \n",
       "\n",
       "  param_classifier__alpha param_classifier__loss param_classifier__max_iter  \\\n",
       "0                    0.01                    log                       1000   \n",
       "1                    0.01                    log                       1000   \n",
       "2                    0.01                    log                       1000   \n",
       "\n",
       "  param_classifier__penalty param_smote__sampling_strategy  \\\n",
       "0                        l2                           0.25   \n",
       "1                        l2                            0.5   \n",
       "2                        l2                              1   \n",
       "\n",
       "                                              params  ...  mean_test_score  \\\n",
       "0  {'classifier__alpha': 0.01, 'classifier__loss'...  ...         0.751240   \n",
       "1  {'classifier__alpha': 0.01, 'classifier__loss'...  ...         0.743208   \n",
       "2  {'classifier__alpha': 0.01, 'classifier__loss'...  ...         0.732377   \n",
       "\n",
       "   std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0        0.001264                1            0.755331            0.755175   \n",
       "1        0.001667                2            0.747575            0.747377   \n",
       "2        0.001276                3            0.737048            0.734762   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0            0.755476            0.755935            0.756684   \n",
       "1            0.747551            0.747856            0.747710   \n",
       "2            0.737636            0.737287            0.736520   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0          0.755720         0.000545  \n",
       "1          0.747614         0.000161  \n",
       "2          0.736650         0.001012  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort results by mean_test_score in df_sgdc_smote\n",
    "df_sgdc_smote.sort_values(by = 'mean_test_score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "61c14719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only best results in df_sgdc\n",
    "df_sgdc_best_results = df_sgdc.sort_values(by = 'mean_test_score', ascending = False).head(1)\n",
    "\n",
    "# Concatenate df_sgdc_smote with best results in df_sgdc (without smote)\n",
    "df_sgdc_smote = pd.concat([df_sgdc_smote, df_sgdc_best_results], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2c9aac94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__alpha</th>\n",
       "      <th>param_classifier__loss</th>\n",
       "      <th>param_classifier__max_iter</th>\n",
       "      <th>param_classifier__penalty</th>\n",
       "      <th>param_smote__sampling_strategy</th>\n",
       "      <th>params</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.769146</td>\n",
       "      <td>9.813351</td>\n",
       "      <td>0.465238</td>\n",
       "      <td>0.152395</td>\n",
       "      <td>0.01</td>\n",
       "      <td>log</td>\n",
       "      <td>1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'classifier__alpha': 0.01, 'classifier__loss'...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.763364</td>\n",
       "      <td>0.001704</td>\n",
       "      <td>1</td>\n",
       "      <td>0.769062</td>\n",
       "      <td>0.768191</td>\n",
       "      <td>0.767918</td>\n",
       "      <td>0.768153</td>\n",
       "      <td>0.768259</td>\n",
       "      <td>0.768316</td>\n",
       "      <td>0.000390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.792451</td>\n",
       "      <td>1.001144</td>\n",
       "      <td>0.616272</td>\n",
       "      <td>0.124436</td>\n",
       "      <td>0.01</td>\n",
       "      <td>log</td>\n",
       "      <td>1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'classifier__alpha': 0.01, 'classifier__loss'...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751240</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>1</td>\n",
       "      <td>0.755331</td>\n",
       "      <td>0.755175</td>\n",
       "      <td>0.755476</td>\n",
       "      <td>0.755935</td>\n",
       "      <td>0.756684</td>\n",
       "      <td>0.755720</td>\n",
       "      <td>0.000545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.165315</td>\n",
       "      <td>3.879312</td>\n",
       "      <td>0.749596</td>\n",
       "      <td>0.343286</td>\n",
       "      <td>0.01</td>\n",
       "      <td>log</td>\n",
       "      <td>1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'classifier__alpha': 0.01, 'classifier__loss'...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743208</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>2</td>\n",
       "      <td>0.747575</td>\n",
       "      <td>0.747377</td>\n",
       "      <td>0.747551</td>\n",
       "      <td>0.747856</td>\n",
       "      <td>0.747710</td>\n",
       "      <td>0.747614</td>\n",
       "      <td>0.000161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51.489682</td>\n",
       "      <td>4.364350</td>\n",
       "      <td>1.192805</td>\n",
       "      <td>0.339977</td>\n",
       "      <td>0.01</td>\n",
       "      <td>log</td>\n",
       "      <td>1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>1</td>\n",
       "      <td>{'classifier__alpha': 0.01, 'classifier__loss'...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.732377</td>\n",
       "      <td>0.001276</td>\n",
       "      <td>3</td>\n",
       "      <td>0.737048</td>\n",
       "      <td>0.734762</td>\n",
       "      <td>0.737636</td>\n",
       "      <td>0.737287</td>\n",
       "      <td>0.736520</td>\n",
       "      <td>0.736650</td>\n",
       "      <td>0.001012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "3      21.769146      9.813351         0.465238        0.152395   \n",
       "0      34.792451      1.001144         0.616272        0.124436   \n",
       "1      38.165315      3.879312         0.749596        0.343286   \n",
       "2      51.489682      4.364350         1.192805        0.339977   \n",
       "\n",
       "  param_classifier__alpha param_classifier__loss param_classifier__max_iter  \\\n",
       "3                    0.01                    log                       1000   \n",
       "0                    0.01                    log                       1000   \n",
       "1                    0.01                    log                       1000   \n",
       "2                    0.01                    log                       1000   \n",
       "\n",
       "  param_classifier__penalty param_smote__sampling_strategy  \\\n",
       "3                        l2                            NaN   \n",
       "0                        l2                           0.25   \n",
       "1                        l2                            0.5   \n",
       "2                        l2                              1   \n",
       "\n",
       "                                              params  ...  mean_test_score  \\\n",
       "3  {'classifier__alpha': 0.01, 'classifier__loss'...  ...         0.763364   \n",
       "0  {'classifier__alpha': 0.01, 'classifier__loss'...  ...         0.751240   \n",
       "1  {'classifier__alpha': 0.01, 'classifier__loss'...  ...         0.743208   \n",
       "2  {'classifier__alpha': 0.01, 'classifier__loss'...  ...         0.732377   \n",
       "\n",
       "   std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "3        0.001704                1            0.769062            0.768191   \n",
       "0        0.001264                1            0.755331            0.755175   \n",
       "1        0.001667                2            0.747575            0.747377   \n",
       "2        0.001276                3            0.737048            0.734762   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "3            0.767918            0.768153            0.768259   \n",
       "0            0.755476            0.755935            0.756684   \n",
       "1            0.747551            0.747856            0.747710   \n",
       "2            0.737636            0.737287            0.736520   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "3          0.768316         0.000390  \n",
       "0          0.755720         0.000545  \n",
       "1          0.747614         0.000161  \n",
       "2          0.736650         0.001012  \n",
       "\n",
       "[4 rows x 25 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort by 'mean_test_score'\n",
    "df_sgdc_smote.sort_values(by = 'mean_test_score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "632cf7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sgdc_smote['param_smote__sampling_strategy'] = df_sgdc_smote['param_smote__sampling_strategy'].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c3be9777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__alpha</th>\n",
       "      <th>param_classifier__loss</th>\n",
       "      <th>param_classifier__max_iter</th>\n",
       "      <th>param_classifier__penalty</th>\n",
       "      <th>param_smote__sampling_strategy</th>\n",
       "      <th>params</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.792451</td>\n",
       "      <td>1.001144</td>\n",
       "      <td>0.616272</td>\n",
       "      <td>0.124436</td>\n",
       "      <td>0.01</td>\n",
       "      <td>log</td>\n",
       "      <td>1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'classifier__alpha': 0.01, 'classifier__loss'...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751240</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>1</td>\n",
       "      <td>0.755331</td>\n",
       "      <td>0.755175</td>\n",
       "      <td>0.755476</td>\n",
       "      <td>0.755935</td>\n",
       "      <td>0.756684</td>\n",
       "      <td>0.755720</td>\n",
       "      <td>0.000545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.165315</td>\n",
       "      <td>3.879312</td>\n",
       "      <td>0.749596</td>\n",
       "      <td>0.343286</td>\n",
       "      <td>0.01</td>\n",
       "      <td>log</td>\n",
       "      <td>1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'classifier__alpha': 0.01, 'classifier__loss'...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743208</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>2</td>\n",
       "      <td>0.747575</td>\n",
       "      <td>0.747377</td>\n",
       "      <td>0.747551</td>\n",
       "      <td>0.747856</td>\n",
       "      <td>0.747710</td>\n",
       "      <td>0.747614</td>\n",
       "      <td>0.000161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51.489682</td>\n",
       "      <td>4.364350</td>\n",
       "      <td>1.192805</td>\n",
       "      <td>0.339977</td>\n",
       "      <td>0.01</td>\n",
       "      <td>log</td>\n",
       "      <td>1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>1</td>\n",
       "      <td>{'classifier__alpha': 0.01, 'classifier__loss'...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.732377</td>\n",
       "      <td>0.001276</td>\n",
       "      <td>3</td>\n",
       "      <td>0.737048</td>\n",
       "      <td>0.734762</td>\n",
       "      <td>0.737636</td>\n",
       "      <td>0.737287</td>\n",
       "      <td>0.736520</td>\n",
       "      <td>0.736650</td>\n",
       "      <td>0.001012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.769146</td>\n",
       "      <td>9.813351</td>\n",
       "      <td>0.465238</td>\n",
       "      <td>0.152395</td>\n",
       "      <td>0.01</td>\n",
       "      <td>log</td>\n",
       "      <td>1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>None</td>\n",
       "      <td>{'classifier__alpha': 0.01, 'classifier__loss'...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.763364</td>\n",
       "      <td>0.001704</td>\n",
       "      <td>1</td>\n",
       "      <td>0.769062</td>\n",
       "      <td>0.768191</td>\n",
       "      <td>0.767918</td>\n",
       "      <td>0.768153</td>\n",
       "      <td>0.768259</td>\n",
       "      <td>0.768316</td>\n",
       "      <td>0.000390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      34.792451      1.001144         0.616272        0.124436   \n",
       "1      38.165315      3.879312         0.749596        0.343286   \n",
       "2      51.489682      4.364350         1.192805        0.339977   \n",
       "3      21.769146      9.813351         0.465238        0.152395   \n",
       "\n",
       "  param_classifier__alpha param_classifier__loss param_classifier__max_iter  \\\n",
       "0                    0.01                    log                       1000   \n",
       "1                    0.01                    log                       1000   \n",
       "2                    0.01                    log                       1000   \n",
       "3                    0.01                    log                       1000   \n",
       "\n",
       "  param_classifier__penalty param_smote__sampling_strategy  \\\n",
       "0                        l2                           0.25   \n",
       "1                        l2                            0.5   \n",
       "2                        l2                              1   \n",
       "3                        l2                           None   \n",
       "\n",
       "                                              params  ...  mean_test_score  \\\n",
       "0  {'classifier__alpha': 0.01, 'classifier__loss'...  ...         0.751240   \n",
       "1  {'classifier__alpha': 0.01, 'classifier__loss'...  ...         0.743208   \n",
       "2  {'classifier__alpha': 0.01, 'classifier__loss'...  ...         0.732377   \n",
       "3  {'classifier__alpha': 0.01, 'classifier__loss'...  ...         0.763364   \n",
       "\n",
       "   std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0        0.001264                1            0.755331            0.755175   \n",
       "1        0.001667                2            0.747575            0.747377   \n",
       "2        0.001276                3            0.737048            0.734762   \n",
       "3        0.001704                1            0.769062            0.768191   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0            0.755476            0.755935            0.756684   \n",
       "1            0.747551            0.747856            0.747710   \n",
       "2            0.737636            0.737287            0.736520   \n",
       "3            0.767918            0.768153            0.768259   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0          0.755720         0.000545  \n",
       "1          0.747614         0.000161  \n",
       "2          0.736650         0.001012  \n",
       "3          0.768316         0.000390  \n",
       "\n",
       "[4 rows x 25 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sgdc_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7ffc21a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot mean test scores by param_smote__sampling_strategy\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "g = sns.barplot(x = 'param_smote__sampling_strategy',\n",
    "                y = 'mean_test_score',\n",
    "                data = df_sgdc_smote,\n",
    "                order = ['None', 0.25, 0.5, 1])\n",
    "\n",
    "# Show exact mean_test_score for each sampling strategy\n",
    "for i in g.containers:\n",
    "    g.bar_label(i,)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504e9dce",
   "metadata": {},
   "source": [
    "### Conclusions for SGD Classifier\n",
    "- best parameters found by GridSearchCV are alpha = 0.01 and loss = log\n",
    "- oversampling the minority class with SMOTE disimproves the mean test scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0188acb",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4fd13b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END ..............., score=(train=0.773, test=0.768) total time=  41.0s\n",
      "[CV 2/5] END ..............., score=(train=0.773, test=0.769) total time=  43.9s\n",
      "[CV 3/5] END ..............., score=(train=0.773, test=0.768) total time=  34.2s\n",
      "[CV 4/5] END ..............., score=(train=0.773, test=0.766) total time=  31.7s\n",
      "[CV 5/5] END ..............., score=(train=0.773, test=0.765) total time=  29.6s\n",
      "cv_score_lr_default: 0.7671036824949046\n",
      "Execution time in seconds: 239.43307614326477\n",
      "Execution time in minutes: 3.990551269054413\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with scaler/classifier pipeline (no oversampling)\n",
    "# Using default parameters\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "startFitTime = time.time()\n",
    "\n",
    "# Create pipeline (imbpipeline)\n",
    "pipeline = Pipeline(steps = [['scaler', StandardScaler()],\n",
    "                             ['classifier', LogisticRegression(random_state = 11)]])\n",
    "\n",
    "# Define stratifiedKfold\n",
    "stratified_kfold = StratifiedKFold(n_splits = 5,\n",
    "                                   shuffle = True,\n",
    "                                   random_state = 11)\n",
    "\n",
    "# Using default parameters\n",
    "param_grid = {}\n",
    "\n",
    "gs_lr_default = GridSearchCV(estimator = pipeline,\n",
    "                             param_grid = param_grid,\n",
    "                             scoring = 'roc_auc',\n",
    "                             cv = stratified_kfold,\n",
    "                             verbose = 5,\n",
    "                             return_train_score = True)\n",
    "\n",
    "\n",
    "gs_lr_default.fit(X, y)\n",
    "\n",
    "cv_score_lr_default = gs_lr_default.best_score_\n",
    "print('cv_score_lr_default:', cv_score_lr_default)\n",
    "\n",
    "cv_results_lr_default = gs_lr_default.cv_results_\n",
    "df_lr_default = pd.DataFrame(cv_results_lr_default)\n",
    "\n",
    "executionFitTime = (time.time() - startFitTime)\n",
    "print('Execution time in seconds: ' + str(executionFitTime))\n",
    "print('Execution time in minutes: ' + str(executionFitTime / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c90aff3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression with scaler/classifier pipeline (no oversampling)\n",
    "# Testing different parameters with gridsearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "startFitTime = time.time()\n",
    "\n",
    "# Create pipeline (imbpipeline)\n",
    "pipeline = Pipeline(steps = [['scaler', StandardScaler()],\n",
    "                             ['classifier', LogisticRegression(random_state = 11)]])\n",
    "\n",
    "# Define stratifiedKfold\n",
    "stratified_kfold = StratifiedKFold(n_splits = 5,\n",
    "                                   shuffle = True,\n",
    "                                   random_state = 11)\n",
    "\n",
    "# Using default parameters\n",
    "param_grid = {'classifier__penalty': ['l2', 'none'],\n",
    "              'classifier__C': [0.1, 1, 10],\n",
    "              'classifier__solver': ['lbfgs']}\n",
    "\n",
    "gs_lr = GridSearchCV(estimator = pipeline,\n",
    "                             param_grid = param_grid,\n",
    "                             scoring = 'roc_auc',\n",
    "                             cv = stratified_kfold,\n",
    "                             verbose = 5,\n",
    "                             return_train_score = True)\n",
    "\n",
    "\n",
    "gs_lr.fit(X, y)\n",
    "\n",
    "cv_score_lr = gs_lr.best_score_\n",
    "print('cv_score_lr:', cv_score_lr)\n",
    "\n",
    "cv_results_lr = gs_lr.cv_results_\n",
    "df_lr = pd.DataFrame(cv_results_lr)\n",
    "\n",
    "executionFitTime = (time.time() - startFitTime)\n",
    "print('Execution time in seconds: ' + str(executionFitTime))\n",
    "print('Execution time in minutes: ' + str(executionFitTime / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8900af33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99195df5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1eba48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d86b680",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Create pipeline (imbpipeline) with smote, scaler and classifier steps\n",
    "# imbpipeline automatically skip the sampling method (smote) when predict is called\n",
    "# -> Consequently, there is no data leakage\n",
    "pipeline = Pipeline(steps = [['smote', SMOTE(random_state = 11)],\n",
    "                             ['scaler', StandardScaler()],\n",
    "                             ['classifier', LGBMClassifier(random_state = 11)]])\n",
    "\n",
    "# Define stratifiedKfold\n",
    "stratified_kfold = StratifiedKFold(n_splits = 5,\n",
    "                                   shuffle = True,\n",
    "                                   random_state = 11)\n",
    "\n",
    "param_grid = {'smote__sampling_strategy' : [1],\n",
    "              'classifier__n_estimators' : [500]}\n",
    "\n",
    "gs_lgbm = GridSearchCV(estimator = pipeline,\n",
    "                       param_grid = param_grid,\n",
    "                       scoring = 'roc_auc',\n",
    "                       cv = stratified_kfold,\n",
    "                       verbose = 5,\n",
    "                       return_train_score = True)\n",
    "\n",
    "startFitTime = time.time()\n",
    "gs_lgbm.fit(X, y)\n",
    "executionFitTime = (time.time() - startFitTime)\n",
    "print('Execution time in seconds: ' + str(executionFitTime))\n",
    "print('Execution time in minutes: ' + str(executionFitTime / 60))\n",
    "\n",
    "cv_score_lgbm = gs_lgbm.best_score_\n",
    "print('cv_score_lgbm:', cv_score_lgbm)\n",
    "\n",
    "cv_results_lgbm = gs_lgbm.cv_results_\n",
    "df_lgbmc = pd.DataFrame(cv_results_lgbm)\n",
    "df_lgbmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3b30c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fa2c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1d2d9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f69127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd6c7a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6c37db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3eb94e77",
   "metadata": {},
   "source": [
    "### Evaluate lgbm Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "627ea4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END classifier__n_estimators=500, smote__sampling_strategy=1;, score=(train=0.921, test=0.772) total time= 1.9min\n",
      "[CV 2/5] END classifier__n_estimators=500, smote__sampling_strategy=1;, score=(train=0.919, test=0.775) total time= 1.7min\n",
      "[CV 3/5] END classifier__n_estimators=500, smote__sampling_strategy=1;, score=(train=0.920, test=0.774) total time= 1.6min\n",
      "[CV 4/5] END classifier__n_estimators=500, smote__sampling_strategy=1;, score=(train=0.919, test=0.769) total time= 1.9min\n",
      "[CV 5/5] END classifier__n_estimators=500, smote__sampling_strategy=1;, score=(train=0.922, test=0.769) total time= 1.8min\n",
      "Execution time in seconds: 691.981338262558\n",
      "Execution time in minutes: 11.533022304375967\n",
      "cv_score_lgbm: 0.7717708530587315\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__n_estimators</th>\n",
       "      <th>param_smote__sampling_strategy</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105.695742</td>\n",
       "      <td>5.148001</td>\n",
       "      <td>1.168862</td>\n",
       "      <td>0.03488</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>{'classifier__n_estimators': 500, 'smote__sampling_strategy': 1}</td>\n",
       "      <td>0.771805</td>\n",
       "      <td>0.774772</td>\n",
       "      <td>0.774437</td>\n",
       "      <td>0.768953</td>\n",
       "      <td>0.768888</td>\n",
       "      <td>0.771771</td>\n",
       "      <td>0.002544</td>\n",
       "      <td>1</td>\n",
       "      <td>0.921223</td>\n",
       "      <td>0.91914</td>\n",
       "      <td>0.920365</td>\n",
       "      <td>0.919276</td>\n",
       "      <td>0.922141</td>\n",
       "      <td>0.920429</td>\n",
       "      <td>0.001145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0     105.695742      5.148001         1.168862         0.03488   \n",
       "\n",
       "  param_classifier__n_estimators param_smote__sampling_strategy  \\\n",
       "0                            500                              1   \n",
       "\n",
       "                                                             params  \\\n",
       "0  {'classifier__n_estimators': 500, 'smote__sampling_strategy': 1}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.771805           0.774772           0.774437           0.768953   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0           0.768888         0.771771        0.002544                1   \n",
       "\n",
       "   split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0            0.921223             0.91914            0.920365   \n",
       "\n",
       "   split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.919276            0.922141          0.920429         0.001145  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Create pipeline (imbpipeline) with smote, scaler and classifier steps\n",
    "# imbpipeline automatically skip the sampling method (smote) when predict is called\n",
    "# -> Consequently, there is no data leakage\n",
    "pipeline = Pipeline(steps = [['smote', SMOTE(random_state = 11)],\n",
    "                             ['scaler', StandardScaler()],\n",
    "                             ['classifier', LGBMClassifier(random_state = 11)]])\n",
    "\n",
    "# Define stratifiedKfold\n",
    "stratified_kfold = StratifiedKFold(n_splits = 5,\n",
    "                                   shuffle = True,\n",
    "                                   random_state = 11)\n",
    "\n",
    "param_grid = {'smote__sampling_strategy' : [1],\n",
    "              'classifier__n_estimators' : [500]}\n",
    "\n",
    "gs_lgbm = GridSearchCV(estimator = pipeline,\n",
    "                       param_grid = param_grid,\n",
    "                       scoring = 'roc_auc',\n",
    "                       cv = stratified_kfold,\n",
    "                       verbose = 5,\n",
    "                       return_train_score = True)\n",
    "\n",
    "startFitTime = time.time()\n",
    "gs_lgbm.fit(X, y)\n",
    "executionFitTime = (time.time() - startFitTime)\n",
    "print('Execution time in seconds: ' + str(executionFitTime))\n",
    "print('Execution time in minutes: ' + str(executionFitTime / 60))\n",
    "\n",
    "cv_score_lgbm = gs_lgbm.best_score_\n",
    "print('cv_score_lgbm:', cv_score_lgbm)\n",
    "\n",
    "cv_results_lgbm = gs_lgbm.cv_results_\n",
    "df_lgbmc = pd.DataFrame(cv_results_lgbm)\n",
    "df_lgbmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e6be1322",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV 1/5] END classifier__n_estimators=500, classifier__num_leaves=31, smote__sampling_strategy=0.25;, score=(train=0.924, test=0.773) total time= 1.1min\n",
      "[CV 2/5] END classifier__n_estimators=500, classifier__num_leaves=31, smote__sampling_strategy=0.25;, score=(train=0.923, test=0.776) total time= 1.2min\n",
      "[CV 3/5] END classifier__n_estimators=500, classifier__num_leaves=31, smote__sampling_strategy=0.25;, score=(train=0.925, test=0.777) total time= 1.1min\n",
      "[CV 4/5] END classifier__n_estimators=500, classifier__num_leaves=31, smote__sampling_strategy=0.25;, score=(train=0.924, test=0.772) total time= 1.1min\n",
      "[CV 5/5] END classifier__n_estimators=500, classifier__num_leaves=31, smote__sampling_strategy=0.25;, score=(train=0.925, test=0.771) total time= 1.1min\n",
      "[CV 1/5] END classifier__n_estimators=500, classifier__num_leaves=31, smote__sampling_strategy=0.5;, score=(train=0.924, test=0.773) total time= 1.2min\n",
      "[CV 2/5] END classifier__n_estimators=500, classifier__num_leaves=31, smote__sampling_strategy=0.5;, score=(train=0.922, test=0.776) total time= 1.2min\n",
      "[CV 3/5] END classifier__n_estimators=500, classifier__num_leaves=31, smote__sampling_strategy=0.5;, score=(train=0.922, test=0.776) total time= 1.3min\n",
      "[CV 4/5] END classifier__n_estimators=500, classifier__num_leaves=31, smote__sampling_strategy=0.5;, score=(train=0.922, test=0.771) total time= 1.2min\n",
      "[CV 5/5] END classifier__n_estimators=500, classifier__num_leaves=31, smote__sampling_strategy=0.5;, score=(train=0.923, test=0.770) total time= 1.3min\n",
      "[CV 1/5] END classifier__n_estimators=500, classifier__num_leaves=31, smote__sampling_strategy=1;, score=(train=0.921, test=0.772) total time= 1.8min\n",
      "[CV 2/5] END classifier__n_estimators=500, classifier__num_leaves=31, smote__sampling_strategy=1;, score=(train=0.919, test=0.775) total time= 1.7min\n",
      "[CV 3/5] END classifier__n_estimators=500, classifier__num_leaves=31, smote__sampling_strategy=1;, score=(train=0.920, test=0.774) total time= 1.6min\n",
      "[CV 4/5] END classifier__n_estimators=500, classifier__num_leaves=31, smote__sampling_strategy=1;, score=(train=0.919, test=0.769) total time= 1.5min\n",
      "[CV 5/5] END classifier__n_estimators=500, classifier__num_leaves=31, smote__sampling_strategy=1;, score=(train=0.922, test=0.769) total time= 1.5min\n",
      "[CV 1/5] END classifier__n_estimators=500, classifier__num_leaves=50, smote__sampling_strategy=0.25;, score=(train=0.967, test=0.774) total time= 1.2min\n",
      "[CV 2/5] END classifier__n_estimators=500, classifier__num_leaves=50, smote__sampling_strategy=0.25;, score=(train=0.968, test=0.777) total time= 1.2min\n",
      "[CV 3/5] END classifier__n_estimators=500, classifier__num_leaves=50, smote__sampling_strategy=0.25;, score=(train=0.965, test=0.777) total time= 1.2min\n",
      "[CV 4/5] END classifier__n_estimators=500, classifier__num_leaves=50, smote__sampling_strategy=0.25;, score=(train=0.965, test=0.773) total time= 1.2min\n",
      "[CV 5/5] END classifier__n_estimators=500, classifier__num_leaves=50, smote__sampling_strategy=0.25;, score=(train=0.967, test=0.771) total time= 1.2min\n",
      "[CV 1/5] END classifier__n_estimators=500, classifier__num_leaves=50, smote__sampling_strategy=0.5;, score=(train=0.965, test=0.771) total time= 1.4min\n",
      "[CV 2/5] END classifier__n_estimators=500, classifier__num_leaves=50, smote__sampling_strategy=0.5;, score=(train=0.964, test=0.774) total time= 1.4min\n",
      "[CV 3/5] END classifier__n_estimators=500, classifier__num_leaves=50, smote__sampling_strategy=0.5;, score=(train=0.964, test=0.771) total time= 1.4min\n",
      "[CV 4/5] END classifier__n_estimators=500, classifier__num_leaves=50, smote__sampling_strategy=0.5;, score=(train=0.963, test=0.767) total time= 1.4min\n",
      "[CV 5/5] END classifier__n_estimators=500, classifier__num_leaves=50, smote__sampling_strategy=0.5;, score=(train=0.965, test=0.768) total time= 1.4min\n",
      "[CV 1/5] END classifier__n_estimators=500, classifier__num_leaves=50, smote__sampling_strategy=1;, score=(train=0.964, test=0.770) total time= 1.7min\n",
      "[CV 2/5] END classifier__n_estimators=500, classifier__num_leaves=50, smote__sampling_strategy=1;, score=(train=0.964, test=0.774) total time= 1.9min\n",
      "[CV 3/5] END classifier__n_estimators=500, classifier__num_leaves=50, smote__sampling_strategy=1;, score=(train=0.964, test=0.774) total time= 2.0min\n",
      "[CV 4/5] END classifier__n_estimators=500, classifier__num_leaves=50, smote__sampling_strategy=1;, score=(train=0.962, test=0.768) total time= 1.9min\n",
      "[CV 5/5] END classifier__n_estimators=500, classifier__num_leaves=50, smote__sampling_strategy=1;, score=(train=0.964, test=0.767) total time= 1.9min\n",
      "[CV 1/5] END classifier__n_estimators=1000, classifier__num_leaves=31, smote__sampling_strategy=0.25;, score=(train=0.977, test=0.772) total time= 1.5min\n",
      "[CV 2/5] END classifier__n_estimators=1000, classifier__num_leaves=31, smote__sampling_strategy=0.25;, score=(train=0.976, test=0.774) total time= 1.5min\n",
      "[CV 3/5] END classifier__n_estimators=1000, classifier__num_leaves=31, smote__sampling_strategy=0.25;, score=(train=0.976, test=0.775) total time= 1.5min\n",
      "[CV 4/5] END classifier__n_estimators=1000, classifier__num_leaves=31, smote__sampling_strategy=0.25;, score=(train=0.976, test=0.770) total time= 1.5min\n",
      "[CV 5/5] END classifier__n_estimators=1000, classifier__num_leaves=31, smote__sampling_strategy=0.25;, score=(train=0.976, test=0.768) total time= 1.6min\n",
      "[CV 1/5] END classifier__n_estimators=1000, classifier__num_leaves=31, smote__sampling_strategy=0.5;, score=(train=0.977, test=0.771) total time= 1.8min\n",
      "[CV 2/5] END classifier__n_estimators=1000, classifier__num_leaves=31, smote__sampling_strategy=0.5;, score=(train=0.976, test=0.773) total time= 1.8min\n",
      "[CV 3/5] END classifier__n_estimators=1000, classifier__num_leaves=31, smote__sampling_strategy=0.5;, score=(train=0.976, test=0.773) total time= 1.7min\n",
      "[CV 4/5] END classifier__n_estimators=1000, classifier__num_leaves=31, smote__sampling_strategy=0.5;, score=(train=0.975, test=0.767) total time= 1.9min\n",
      "[CV 5/5] END classifier__n_estimators=1000, classifier__num_leaves=31, smote__sampling_strategy=0.5;, score=(train=0.977, test=0.768) total time= 1.8min\n",
      "[CV 1/5] END classifier__n_estimators=1000, classifier__num_leaves=31, smote__sampling_strategy=1;, score=(train=0.976, test=0.771) total time= 2.2min\n",
      "[CV 2/5] END classifier__n_estimators=1000, classifier__num_leaves=31, smote__sampling_strategy=1;, score=(train=0.974, test=0.773) total time= 2.2min\n",
      "[CV 3/5] END classifier__n_estimators=1000, classifier__num_leaves=31, smote__sampling_strategy=1;, score=(train=0.975, test=0.772) total time= 2.1min\n",
      "[CV 4/5] END classifier__n_estimators=1000, classifier__num_leaves=31, smote__sampling_strategy=1;, score=(train=0.974, test=0.766) total time= 2.1min\n",
      "[CV 5/5] END classifier__n_estimators=1000, classifier__num_leaves=31, smote__sampling_strategy=1;, score=(train=0.976, test=0.766) total time= 2.3min\n",
      "[CV 1/5] END classifier__n_estimators=1000, classifier__num_leaves=50, smote__sampling_strategy=0.25;, score=(train=0.996, test=0.770) total time= 1.7min\n",
      "[CV 2/5] END classifier__n_estimators=1000, classifier__num_leaves=50, smote__sampling_strategy=0.25;, score=(train=0.996, test=0.771) total time=35.2min\n",
      "[CV 3/5] END classifier__n_estimators=1000, classifier__num_leaves=50, smote__sampling_strategy=0.25;, score=(train=0.996, test=0.774) total time= 1.9min\n",
      "[CV 4/5] END classifier__n_estimators=1000, classifier__num_leaves=50, smote__sampling_strategy=0.25;, score=(train=0.996, test=0.768) total time= 1.7min\n",
      "[CV 5/5] END classifier__n_estimators=1000, classifier__num_leaves=50, smote__sampling_strategy=0.25;, score=(train=0.996, test=0.766) total time= 1.7min\n",
      "[CV 1/5] END classifier__n_estimators=1000, classifier__num_leaves=50, smote__sampling_strategy=0.5;, score=(train=0.996, test=0.768) total time= 1.9min\n",
      "[CV 2/5] END classifier__n_estimators=1000, classifier__num_leaves=50, smote__sampling_strategy=0.5;, score=(train=0.996, test=0.768) total time= 1.9min\n",
      "[CV 3/5] END classifier__n_estimators=1000, classifier__num_leaves=50, smote__sampling_strategy=0.5;, score=(train=0.996, test=0.769) total time= 2.0min\n",
      "[CV 4/5] END classifier__n_estimators=1000, classifier__num_leaves=50, smote__sampling_strategy=0.5;, score=(train=0.995, test=0.764) total time= 2.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END classifier__n_estimators=1000, classifier__num_leaves=50, smote__sampling_strategy=0.5;, score=(train=0.996, test=0.763) total time= 2.1min\n",
      "[CV 1/5] END classifier__n_estimators=1000, classifier__num_leaves=50, smote__sampling_strategy=1;, score=(train=0.996, test=0.768) total time= 2.7min\n",
      "[CV 2/5] END classifier__n_estimators=1000, classifier__num_leaves=50, smote__sampling_strategy=1;, score=(train=0.996, test=0.771) total time= 2.6min\n",
      "[CV 3/5] END classifier__n_estimators=1000, classifier__num_leaves=50, smote__sampling_strategy=1;, score=(train=0.996, test=0.770) total time= 2.6min\n",
      "[CV 4/5] END classifier__n_estimators=1000, classifier__num_leaves=50, smote__sampling_strategy=1;, score=(train=0.995, test=0.766) total time= 2.7min\n",
      "[CV 5/5] END classifier__n_estimators=1000, classifier__num_leaves=50, smote__sampling_strategy=1;, score=(train=0.996, test=0.763) total time= 2.6min\n",
      "[CV 1/5] END classifier__n_estimators=2000, classifier__num_leaves=31, smote__sampling_strategy=0.25;, score=(train=0.998, test=0.768) total time= 2.3min\n",
      "[CV 2/5] END classifier__n_estimators=2000, classifier__num_leaves=31, smote__sampling_strategy=0.25;, score=(train=0.998, test=0.767) total time= 2.4min\n",
      "[CV 3/5] END classifier__n_estimators=2000, classifier__num_leaves=31, smote__sampling_strategy=0.25;, score=(train=0.998, test=0.770) total time= 2.2min\n",
      "[CV 4/5] END classifier__n_estimators=2000, classifier__num_leaves=31, smote__sampling_strategy=0.25;, score=(train=0.998, test=0.762) total time= 2.3min\n",
      "[CV 5/5] END classifier__n_estimators=2000, classifier__num_leaves=31, smote__sampling_strategy=0.25;, score=(train=0.998, test=0.762) total time= 2.3min\n",
      "[CV 1/5] END classifier__n_estimators=2000, classifier__num_leaves=31, smote__sampling_strategy=0.5;, score=(train=0.998, test=0.766) total time= 2.6min\n",
      "[CV 2/5] END classifier__n_estimators=2000, classifier__num_leaves=31, smote__sampling_strategy=0.5;, score=(train=0.998, test=0.768) total time= 2.7min\n",
      "[CV 3/5] END classifier__n_estimators=2000, classifier__num_leaves=31, smote__sampling_strategy=0.5;, score=(train=0.998, test=0.768) total time= 2.6min\n",
      "[CV 4/5] END classifier__n_estimators=2000, classifier__num_leaves=31, smote__sampling_strategy=0.5;, score=(train=0.998, test=0.764) total time= 2.6min\n",
      "[CV 5/5] END classifier__n_estimators=2000, classifier__num_leaves=31, smote__sampling_strategy=0.5;, score=(train=0.998, test=0.763) total time= 2.6min\n",
      "[CV 1/5] END classifier__n_estimators=2000, classifier__num_leaves=31, smote__sampling_strategy=1;, score=(train=0.998, test=0.767) total time= 3.4min\n",
      "[CV 2/5] END classifier__n_estimators=2000, classifier__num_leaves=31, smote__sampling_strategy=1;, score=(train=0.998, test=0.768) total time= 3.3min\n",
      "[CV 3/5] END classifier__n_estimators=2000, classifier__num_leaves=31, smote__sampling_strategy=1;, score=(train=0.998, test=0.768) total time= 3.6min\n",
      "[CV 4/5] END classifier__n_estimators=2000, classifier__num_leaves=31, smote__sampling_strategy=1;, score=(train=0.998, test=0.762) total time= 3.3min\n",
      "[CV 5/5] END classifier__n_estimators=2000, classifier__num_leaves=31, smote__sampling_strategy=1;, score=(train=0.998, test=0.763) total time= 3.4min\n",
      "[CV 1/5] END classifier__n_estimators=2000, classifier__num_leaves=50, smote__sampling_strategy=0.25;, score=(train=1.000, test=0.762) total time= 2.8min\n",
      "[CV 2/5] END classifier__n_estimators=2000, classifier__num_leaves=50, smote__sampling_strategy=0.25;, score=(train=1.000, test=0.762) total time= 2.7min\n",
      "[CV 3/5] END classifier__n_estimators=2000, classifier__num_leaves=50, smote__sampling_strategy=0.25;, score=(train=1.000, test=0.766) total time= 2.7min\n",
      "[CV 4/5] END classifier__n_estimators=2000, classifier__num_leaves=50, smote__sampling_strategy=0.25;, score=(train=1.000, test=0.760) total time= 2.7min\n",
      "[CV 5/5] END classifier__n_estimators=2000, classifier__num_leaves=50, smote__sampling_strategy=0.25;, score=(train=1.000, test=0.757) total time= 2.7min\n",
      "[CV 1/5] END classifier__n_estimators=2000, classifier__num_leaves=50, smote__sampling_strategy=0.5;, score=(train=1.000, test=0.761) total time=76.2min\n",
      "[CV 2/5] END classifier__n_estimators=2000, classifier__num_leaves=50, smote__sampling_strategy=0.5;, score=(train=1.000, test=0.761) total time= 3.6min\n",
      "[CV 3/5] END classifier__n_estimators=2000, classifier__num_leaves=50, smote__sampling_strategy=0.5;, score=(train=1.000, test=0.761) total time= 3.4min\n",
      "[CV 4/5] END classifier__n_estimators=2000, classifier__num_leaves=50, smote__sampling_strategy=0.5;, score=(train=1.000, test=0.758) total time= 3.5min\n",
      "[CV 5/5] END classifier__n_estimators=2000, classifier__num_leaves=50, smote__sampling_strategy=0.5;, score=(train=1.000, test=0.757) total time= 3.2min\n",
      "[CV 1/5] END classifier__n_estimators=2000, classifier__num_leaves=50, smote__sampling_strategy=1;, score=(train=1.000, test=0.762) total time= 4.2min\n",
      "[CV 2/5] END classifier__n_estimators=2000, classifier__num_leaves=50, smote__sampling_strategy=1;, score=(train=1.000, test=0.765) total time= 4.2min\n",
      "[CV 3/5] END classifier__n_estimators=2000, classifier__num_leaves=50, smote__sampling_strategy=1;, score=(train=1.000, test=0.763) total time= 4.1min\n",
      "[CV 4/5] END classifier__n_estimators=2000, classifier__num_leaves=50, smote__sampling_strategy=1;, score=(train=1.000, test=0.761) total time= 4.0min\n",
      "[CV 5/5] END classifier__n_estimators=2000, classifier__num_leaves=50, smote__sampling_strategy=1;, score=(train=1.000, test=0.757) total time= 4.1min\n",
      "Execution time in seconds: 18726.246804475784\n",
      "Execution time in minutes: 312.10411340792973\n",
      "cv_score_lgbm: 0.7742137000488987\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__n_estimators</th>\n",
       "      <th>param_classifier__num_leaves</th>\n",
       "      <th>param_smote__sampling_strategy</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66.618199</td>\n",
       "      <td>2.164613</td>\n",
       "      <td>0.971173</td>\n",
       "      <td>0.020688</td>\n",
       "      <td>500</td>\n",
       "      <td>31</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'classifier__n_estimators': 500, 'classifier__num_leaves': 31, 'smote__sampling_strategy': 0.25}</td>\n",
       "      <td>0.773227</td>\n",
       "      <td>0.776018</td>\n",
       "      <td>0.777333</td>\n",
       "      <td>0.771847</td>\n",
       "      <td>0.771023</td>\n",
       "      <td>0.773890</td>\n",
       "      <td>0.002417</td>\n",
       "      <td>2</td>\n",
       "      <td>0.924462</td>\n",
       "      <td>0.923076</td>\n",
       "      <td>0.924853</td>\n",
       "      <td>0.923508</td>\n",
       "      <td>0.924685</td>\n",
       "      <td>0.924117</td>\n",
       "      <td>0.000698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74.674002</td>\n",
       "      <td>2.528774</td>\n",
       "      <td>0.990418</td>\n",
       "      <td>0.052328</td>\n",
       "      <td>500</td>\n",
       "      <td>31</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'classifier__n_estimators': 500, 'classifier__num_leaves': 31, 'smote__sampling_strategy': 0.5}</td>\n",
       "      <td>0.772564</td>\n",
       "      <td>0.775833</td>\n",
       "      <td>0.775728</td>\n",
       "      <td>0.770592</td>\n",
       "      <td>0.770485</td>\n",
       "      <td>0.773040</td>\n",
       "      <td>0.002357</td>\n",
       "      <td>3</td>\n",
       "      <td>0.924251</td>\n",
       "      <td>0.922251</td>\n",
       "      <td>0.922456</td>\n",
       "      <td>0.921741</td>\n",
       "      <td>0.922822</td>\n",
       "      <td>0.922704</td>\n",
       "      <td>0.000849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96.838054</td>\n",
       "      <td>5.120298</td>\n",
       "      <td>1.140891</td>\n",
       "      <td>0.040570</td>\n",
       "      <td>500</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>{'classifier__n_estimators': 500, 'classifier__num_leaves': 31, 'smote__sampling_strategy': 1}</td>\n",
       "      <td>0.771805</td>\n",
       "      <td>0.774772</td>\n",
       "      <td>0.774437</td>\n",
       "      <td>0.768953</td>\n",
       "      <td>0.768888</td>\n",
       "      <td>0.771771</td>\n",
       "      <td>0.002544</td>\n",
       "      <td>4</td>\n",
       "      <td>0.921223</td>\n",
       "      <td>0.919140</td>\n",
       "      <td>0.920365</td>\n",
       "      <td>0.919276</td>\n",
       "      <td>0.922141</td>\n",
       "      <td>0.920429</td>\n",
       "      <td>0.001145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72.202773</td>\n",
       "      <td>1.297574</td>\n",
       "      <td>1.110056</td>\n",
       "      <td>0.079992</td>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'classifier__n_estimators': 500, 'classifier__num_leaves': 50, 'smote__sampling_strategy': 0.25}</td>\n",
       "      <td>0.773792</td>\n",
       "      <td>0.777035</td>\n",
       "      <td>0.776821</td>\n",
       "      <td>0.772643</td>\n",
       "      <td>0.770777</td>\n",
       "      <td>0.774214</td>\n",
       "      <td>0.002417</td>\n",
       "      <td>1</td>\n",
       "      <td>0.966982</td>\n",
       "      <td>0.967604</td>\n",
       "      <td>0.965449</td>\n",
       "      <td>0.964916</td>\n",
       "      <td>0.967215</td>\n",
       "      <td>0.966433</td>\n",
       "      <td>0.001054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82.702158</td>\n",
       "      <td>1.752617</td>\n",
       "      <td>1.116846</td>\n",
       "      <td>0.103315</td>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'classifier__n_estimators': 500, 'classifier__num_leaves': 50, 'smote__sampling_strategy': 0.5}</td>\n",
       "      <td>0.770817</td>\n",
       "      <td>0.773637</td>\n",
       "      <td>0.771191</td>\n",
       "      <td>0.766868</td>\n",
       "      <td>0.767513</td>\n",
       "      <td>0.770005</td>\n",
       "      <td>0.002502</td>\n",
       "      <td>8</td>\n",
       "      <td>0.965464</td>\n",
       "      <td>0.963829</td>\n",
       "      <td>0.963960</td>\n",
       "      <td>0.963458</td>\n",
       "      <td>0.964823</td>\n",
       "      <td>0.964307</td>\n",
       "      <td>0.000731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>111.616324</td>\n",
       "      <td>5.811772</td>\n",
       "      <td>1.298354</td>\n",
       "      <td>0.047061</td>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'classifier__n_estimators': 500, 'classifier__num_leaves': 50, 'smote__sampling_strategy': 1}</td>\n",
       "      <td>0.769581</td>\n",
       "      <td>0.774225</td>\n",
       "      <td>0.773546</td>\n",
       "      <td>0.768355</td>\n",
       "      <td>0.767114</td>\n",
       "      <td>0.770564</td>\n",
       "      <td>0.002830</td>\n",
       "      <td>6</td>\n",
       "      <td>0.963926</td>\n",
       "      <td>0.963878</td>\n",
       "      <td>0.963547</td>\n",
       "      <td>0.962341</td>\n",
       "      <td>0.964346</td>\n",
       "      <td>0.963608</td>\n",
       "      <td>0.000682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>89.646433</td>\n",
       "      <td>2.136310</td>\n",
       "      <td>1.278153</td>\n",
       "      <td>0.081086</td>\n",
       "      <td>1000</td>\n",
       "      <td>31</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'classifier__n_estimators': 1000, 'classifier__num_leaves': 31, 'smote__sampling_strategy': 0.25}</td>\n",
       "      <td>0.772308</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.774872</td>\n",
       "      <td>0.769631</td>\n",
       "      <td>0.768025</td>\n",
       "      <td>0.771712</td>\n",
       "      <td>0.002542</td>\n",
       "      <td>5</td>\n",
       "      <td>0.976790</td>\n",
       "      <td>0.975762</td>\n",
       "      <td>0.976489</td>\n",
       "      <td>0.976124</td>\n",
       "      <td>0.976244</td>\n",
       "      <td>0.976282</td>\n",
       "      <td>0.000346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>106.547439</td>\n",
       "      <td>2.476292</td>\n",
       "      <td>1.380771</td>\n",
       "      <td>0.111980</td>\n",
       "      <td>1000</td>\n",
       "      <td>31</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'classifier__n_estimators': 1000, 'classifier__num_leaves': 31, 'smote__sampling_strategy': 0.5}</td>\n",
       "      <td>0.770759</td>\n",
       "      <td>0.772584</td>\n",
       "      <td>0.773297</td>\n",
       "      <td>0.767388</td>\n",
       "      <td>0.767811</td>\n",
       "      <td>0.770368</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>7</td>\n",
       "      <td>0.976743</td>\n",
       "      <td>0.975768</td>\n",
       "      <td>0.976403</td>\n",
       "      <td>0.974750</td>\n",
       "      <td>0.976726</td>\n",
       "      <td>0.976078</td>\n",
       "      <td>0.000752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>129.871383</td>\n",
       "      <td>3.644784</td>\n",
       "      <td>1.476653</td>\n",
       "      <td>0.047398</td>\n",
       "      <td>1000</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>{'classifier__n_estimators': 1000, 'classifier__num_leaves': 31, 'smote__sampling_strategy': 1}</td>\n",
       "      <td>0.770956</td>\n",
       "      <td>0.772990</td>\n",
       "      <td>0.771966</td>\n",
       "      <td>0.765887</td>\n",
       "      <td>0.766391</td>\n",
       "      <td>0.769638</td>\n",
       "      <td>0.002933</td>\n",
       "      <td>10</td>\n",
       "      <td>0.975636</td>\n",
       "      <td>0.974493</td>\n",
       "      <td>0.975060</td>\n",
       "      <td>0.973956</td>\n",
       "      <td>0.975727</td>\n",
       "      <td>0.974975</td>\n",
       "      <td>0.000675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>506.298771</td>\n",
       "      <td>802.695461</td>\n",
       "      <td>1.427299</td>\n",
       "      <td>0.133539</td>\n",
       "      <td>1000</td>\n",
       "      <td>50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'classifier__n_estimators': 1000, 'classifier__num_leaves': 50, 'smote__sampling_strategy': 0.25}</td>\n",
       "      <td>0.769700</td>\n",
       "      <td>0.771081</td>\n",
       "      <td>0.773512</td>\n",
       "      <td>0.768467</td>\n",
       "      <td>0.765936</td>\n",
       "      <td>0.769739</td>\n",
       "      <td>0.002535</td>\n",
       "      <td>9</td>\n",
       "      <td>0.996418</td>\n",
       "      <td>0.995811</td>\n",
       "      <td>0.996073</td>\n",
       "      <td>0.995826</td>\n",
       "      <td>0.996420</td>\n",
       "      <td>0.996110</td>\n",
       "      <td>0.000269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>119.287371</td>\n",
       "      <td>6.977810</td>\n",
       "      <td>1.398691</td>\n",
       "      <td>0.184278</td>\n",
       "      <td>1000</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'classifier__n_estimators': 1000, 'classifier__num_leaves': 50, 'smote__sampling_strategy': 0.5}</td>\n",
       "      <td>0.767694</td>\n",
       "      <td>0.767706</td>\n",
       "      <td>0.768633</td>\n",
       "      <td>0.763547</td>\n",
       "      <td>0.762692</td>\n",
       "      <td>0.766054</td>\n",
       "      <td>0.002435</td>\n",
       "      <td>12</td>\n",
       "      <td>0.996258</td>\n",
       "      <td>0.995801</td>\n",
       "      <td>0.995876</td>\n",
       "      <td>0.995346</td>\n",
       "      <td>0.995898</td>\n",
       "      <td>0.995836</td>\n",
       "      <td>0.000291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>156.976225</td>\n",
       "      <td>3.011446</td>\n",
       "      <td>1.594004</td>\n",
       "      <td>0.071475</td>\n",
       "      <td>1000</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'classifier__n_estimators': 1000, 'classifier__num_leaves': 50, 'smote__sampling_strategy': 1}</td>\n",
       "      <td>0.767533</td>\n",
       "      <td>0.770786</td>\n",
       "      <td>0.770408</td>\n",
       "      <td>0.765597</td>\n",
       "      <td>0.763423</td>\n",
       "      <td>0.767550</td>\n",
       "      <td>0.002810</td>\n",
       "      <td>11</td>\n",
       "      <td>0.995842</td>\n",
       "      <td>0.995958</td>\n",
       "      <td>0.995556</td>\n",
       "      <td>0.995458</td>\n",
       "      <td>0.995859</td>\n",
       "      <td>0.995735</td>\n",
       "      <td>0.000193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>135.803819</td>\n",
       "      <td>2.633541</td>\n",
       "      <td>1.812112</td>\n",
       "      <td>0.079965</td>\n",
       "      <td>2000</td>\n",
       "      <td>31</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'classifier__n_estimators': 2000, 'classifier__num_leaves': 31, 'smote__sampling_strategy': 0.25}</td>\n",
       "      <td>0.767505</td>\n",
       "      <td>0.767431</td>\n",
       "      <td>0.769675</td>\n",
       "      <td>0.761750</td>\n",
       "      <td>0.762333</td>\n",
       "      <td>0.765739</td>\n",
       "      <td>0.003130</td>\n",
       "      <td>14</td>\n",
       "      <td>0.998148</td>\n",
       "      <td>0.997946</td>\n",
       "      <td>0.998090</td>\n",
       "      <td>0.997924</td>\n",
       "      <td>0.998218</td>\n",
       "      <td>0.998065</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>155.771564</td>\n",
       "      <td>1.190012</td>\n",
       "      <td>1.777720</td>\n",
       "      <td>0.073876</td>\n",
       "      <td>2000</td>\n",
       "      <td>31</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'classifier__n_estimators': 2000, 'classifier__num_leaves': 31, 'smote__sampling_strategy': 0.5}</td>\n",
       "      <td>0.766102</td>\n",
       "      <td>0.768289</td>\n",
       "      <td>0.768154</td>\n",
       "      <td>0.764340</td>\n",
       "      <td>0.762802</td>\n",
       "      <td>0.765937</td>\n",
       "      <td>0.002138</td>\n",
       "      <td>13</td>\n",
       "      <td>0.998402</td>\n",
       "      <td>0.997982</td>\n",
       "      <td>0.998221</td>\n",
       "      <td>0.997713</td>\n",
       "      <td>0.998197</td>\n",
       "      <td>0.998103</td>\n",
       "      <td>0.000236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>202.123518</td>\n",
       "      <td>5.364779</td>\n",
       "      <td>1.943548</td>\n",
       "      <td>0.049401</td>\n",
       "      <td>2000</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>{'classifier__n_estimators': 2000, 'classifier__num_leaves': 31, 'smote__sampling_strategy': 1}</td>\n",
       "      <td>0.767424</td>\n",
       "      <td>0.768283</td>\n",
       "      <td>0.767646</td>\n",
       "      <td>0.762108</td>\n",
       "      <td>0.762599</td>\n",
       "      <td>0.765612</td>\n",
       "      <td>0.002680</td>\n",
       "      <td>15</td>\n",
       "      <td>0.998167</td>\n",
       "      <td>0.998119</td>\n",
       "      <td>0.998071</td>\n",
       "      <td>0.997906</td>\n",
       "      <td>0.998132</td>\n",
       "      <td>0.998079</td>\n",
       "      <td>0.000092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>161.333142</td>\n",
       "      <td>1.647390</td>\n",
       "      <td>1.916926</td>\n",
       "      <td>0.092329</td>\n",
       "      <td>2000</td>\n",
       "      <td>50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'classifier__n_estimators': 2000, 'classifier__num_leaves': 50, 'smote__sampling_strategy': 0.25}</td>\n",
       "      <td>0.761853</td>\n",
       "      <td>0.762484</td>\n",
       "      <td>0.766186</td>\n",
       "      <td>0.759603</td>\n",
       "      <td>0.757452</td>\n",
       "      <td>0.761516</td>\n",
       "      <td>0.002934</td>\n",
       "      <td>17</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.999933</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.999956</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1076.818812</td>\n",
       "      <td>1745.760954</td>\n",
       "      <td>2.206945</td>\n",
       "      <td>0.165852</td>\n",
       "      <td>2000</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'classifier__n_estimators': 2000, 'classifier__num_leaves': 50, 'smote__sampling_strategy': 0.5}</td>\n",
       "      <td>0.761433</td>\n",
       "      <td>0.760600</td>\n",
       "      <td>0.761021</td>\n",
       "      <td>0.758173</td>\n",
       "      <td>0.756578</td>\n",
       "      <td>0.759561</td>\n",
       "      <td>0.001873</td>\n",
       "      <td>18</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.999938</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>245.254930</td>\n",
       "      <td>5.509639</td>\n",
       "      <td>2.254425</td>\n",
       "      <td>0.110777</td>\n",
       "      <td>2000</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'classifier__n_estimators': 2000, 'classifier__num_leaves': 50, 'smote__sampling_strategy': 1}</td>\n",
       "      <td>0.761995</td>\n",
       "      <td>0.764898</td>\n",
       "      <td>0.763323</td>\n",
       "      <td>0.761062</td>\n",
       "      <td>0.756572</td>\n",
       "      <td>0.761570</td>\n",
       "      <td>0.002813</td>\n",
       "      <td>16</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.999956</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       66.618199      2.164613         0.971173        0.020688   \n",
       "1       74.674002      2.528774         0.990418        0.052328   \n",
       "2       96.838054      5.120298         1.140891        0.040570   \n",
       "3       72.202773      1.297574         1.110056        0.079992   \n",
       "4       82.702158      1.752617         1.116846        0.103315   \n",
       "5      111.616324      5.811772         1.298354        0.047061   \n",
       "6       89.646433      2.136310         1.278153        0.081086   \n",
       "7      106.547439      2.476292         1.380771        0.111980   \n",
       "8      129.871383      3.644784         1.476653        0.047398   \n",
       "9      506.298771    802.695461         1.427299        0.133539   \n",
       "10     119.287371      6.977810         1.398691        0.184278   \n",
       "11     156.976225      3.011446         1.594004        0.071475   \n",
       "12     135.803819      2.633541         1.812112        0.079965   \n",
       "13     155.771564      1.190012         1.777720        0.073876   \n",
       "14     202.123518      5.364779         1.943548        0.049401   \n",
       "15     161.333142      1.647390         1.916926        0.092329   \n",
       "16    1076.818812   1745.760954         2.206945        0.165852   \n",
       "17     245.254930      5.509639         2.254425        0.110777   \n",
       "\n",
       "   param_classifier__n_estimators param_classifier__num_leaves  \\\n",
       "0                             500                           31   \n",
       "1                             500                           31   \n",
       "2                             500                           31   \n",
       "3                             500                           50   \n",
       "4                             500                           50   \n",
       "5                             500                           50   \n",
       "6                            1000                           31   \n",
       "7                            1000                           31   \n",
       "8                            1000                           31   \n",
       "9                            1000                           50   \n",
       "10                           1000                           50   \n",
       "11                           1000                           50   \n",
       "12                           2000                           31   \n",
       "13                           2000                           31   \n",
       "14                           2000                           31   \n",
       "15                           2000                           50   \n",
       "16                           2000                           50   \n",
       "17                           2000                           50   \n",
       "\n",
       "   param_smote__sampling_strategy  \\\n",
       "0                            0.25   \n",
       "1                             0.5   \n",
       "2                               1   \n",
       "3                            0.25   \n",
       "4                             0.5   \n",
       "5                               1   \n",
       "6                            0.25   \n",
       "7                             0.5   \n",
       "8                               1   \n",
       "9                            0.25   \n",
       "10                            0.5   \n",
       "11                              1   \n",
       "12                           0.25   \n",
       "13                            0.5   \n",
       "14                              1   \n",
       "15                           0.25   \n",
       "16                            0.5   \n",
       "17                              1   \n",
       "\n",
       "                                                                                                params  \\\n",
       "0    {'classifier__n_estimators': 500, 'classifier__num_leaves': 31, 'smote__sampling_strategy': 0.25}   \n",
       "1     {'classifier__n_estimators': 500, 'classifier__num_leaves': 31, 'smote__sampling_strategy': 0.5}   \n",
       "2       {'classifier__n_estimators': 500, 'classifier__num_leaves': 31, 'smote__sampling_strategy': 1}   \n",
       "3    {'classifier__n_estimators': 500, 'classifier__num_leaves': 50, 'smote__sampling_strategy': 0.25}   \n",
       "4     {'classifier__n_estimators': 500, 'classifier__num_leaves': 50, 'smote__sampling_strategy': 0.5}   \n",
       "5       {'classifier__n_estimators': 500, 'classifier__num_leaves': 50, 'smote__sampling_strategy': 1}   \n",
       "6   {'classifier__n_estimators': 1000, 'classifier__num_leaves': 31, 'smote__sampling_strategy': 0.25}   \n",
       "7    {'classifier__n_estimators': 1000, 'classifier__num_leaves': 31, 'smote__sampling_strategy': 0.5}   \n",
       "8      {'classifier__n_estimators': 1000, 'classifier__num_leaves': 31, 'smote__sampling_strategy': 1}   \n",
       "9   {'classifier__n_estimators': 1000, 'classifier__num_leaves': 50, 'smote__sampling_strategy': 0.25}   \n",
       "10   {'classifier__n_estimators': 1000, 'classifier__num_leaves': 50, 'smote__sampling_strategy': 0.5}   \n",
       "11     {'classifier__n_estimators': 1000, 'classifier__num_leaves': 50, 'smote__sampling_strategy': 1}   \n",
       "12  {'classifier__n_estimators': 2000, 'classifier__num_leaves': 31, 'smote__sampling_strategy': 0.25}   \n",
       "13   {'classifier__n_estimators': 2000, 'classifier__num_leaves': 31, 'smote__sampling_strategy': 0.5}   \n",
       "14     {'classifier__n_estimators': 2000, 'classifier__num_leaves': 31, 'smote__sampling_strategy': 1}   \n",
       "15  {'classifier__n_estimators': 2000, 'classifier__num_leaves': 50, 'smote__sampling_strategy': 0.25}   \n",
       "16   {'classifier__n_estimators': 2000, 'classifier__num_leaves': 50, 'smote__sampling_strategy': 0.5}   \n",
       "17     {'classifier__n_estimators': 2000, 'classifier__num_leaves': 50, 'smote__sampling_strategy': 1}   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0            0.773227           0.776018           0.777333   \n",
       "1            0.772564           0.775833           0.775728   \n",
       "2            0.771805           0.774772           0.774437   \n",
       "3            0.773792           0.777035           0.776821   \n",
       "4            0.770817           0.773637           0.771191   \n",
       "5            0.769581           0.774225           0.773546   \n",
       "6            0.772308           0.773723           0.774872   \n",
       "7            0.770759           0.772584           0.773297   \n",
       "8            0.770956           0.772990           0.771966   \n",
       "9            0.769700           0.771081           0.773512   \n",
       "10           0.767694           0.767706           0.768633   \n",
       "11           0.767533           0.770786           0.770408   \n",
       "12           0.767505           0.767431           0.769675   \n",
       "13           0.766102           0.768289           0.768154   \n",
       "14           0.767424           0.768283           0.767646   \n",
       "15           0.761853           0.762484           0.766186   \n",
       "16           0.761433           0.760600           0.761021   \n",
       "17           0.761995           0.764898           0.763323   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.771847           0.771023         0.773890        0.002417   \n",
       "1            0.770592           0.770485         0.773040        0.002357   \n",
       "2            0.768953           0.768888         0.771771        0.002544   \n",
       "3            0.772643           0.770777         0.774214        0.002417   \n",
       "4            0.766868           0.767513         0.770005        0.002502   \n",
       "5            0.768355           0.767114         0.770564        0.002830   \n",
       "6            0.769631           0.768025         0.771712        0.002542   \n",
       "7            0.767388           0.767811         0.770368        0.002411   \n",
       "8            0.765887           0.766391         0.769638        0.002933   \n",
       "9            0.768467           0.765936         0.769739        0.002535   \n",
       "10           0.763547           0.762692         0.766054        0.002435   \n",
       "11           0.765597           0.763423         0.767550        0.002810   \n",
       "12           0.761750           0.762333         0.765739        0.003130   \n",
       "13           0.764340           0.762802         0.765937        0.002138   \n",
       "14           0.762108           0.762599         0.765612        0.002680   \n",
       "15           0.759603           0.757452         0.761516        0.002934   \n",
       "16           0.758173           0.756578         0.759561        0.001873   \n",
       "17           0.761062           0.756572         0.761570        0.002813   \n",
       "\n",
       "    rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                 2            0.924462            0.923076   \n",
       "1                 3            0.924251            0.922251   \n",
       "2                 4            0.921223            0.919140   \n",
       "3                 1            0.966982            0.967604   \n",
       "4                 8            0.965464            0.963829   \n",
       "5                 6            0.963926            0.963878   \n",
       "6                 5            0.976790            0.975762   \n",
       "7                 7            0.976743            0.975768   \n",
       "8                10            0.975636            0.974493   \n",
       "9                 9            0.996418            0.995811   \n",
       "10               12            0.996258            0.995801   \n",
       "11               11            0.995842            0.995958   \n",
       "12               14            0.998148            0.997946   \n",
       "13               13            0.998402            0.997982   \n",
       "14               15            0.998167            0.998119   \n",
       "15               17            0.999968            0.999969   \n",
       "16               18            0.999957            0.999971   \n",
       "17               16            0.999969            0.999969   \n",
       "\n",
       "    split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0             0.924853            0.923508            0.924685   \n",
       "1             0.922456            0.921741            0.922822   \n",
       "2             0.920365            0.919276            0.922141   \n",
       "3             0.965449            0.964916            0.967215   \n",
       "4             0.963960            0.963458            0.964823   \n",
       "5             0.963547            0.962341            0.964346   \n",
       "6             0.976489            0.976124            0.976244   \n",
       "7             0.976403            0.974750            0.976726   \n",
       "8             0.975060            0.973956            0.975727   \n",
       "9             0.996073            0.995826            0.996420   \n",
       "10            0.995876            0.995346            0.995898   \n",
       "11            0.995556            0.995458            0.995859   \n",
       "12            0.998090            0.997924            0.998218   \n",
       "13            0.998221            0.997713            0.998197   \n",
       "14            0.998071            0.997906            0.998132   \n",
       "15            0.999948            0.999933            0.999962   \n",
       "16            0.999951            0.999938            0.999959   \n",
       "17            0.999956            0.999943            0.999949   \n",
       "\n",
       "    mean_train_score  std_train_score  \n",
       "0           0.924117         0.000698  \n",
       "1           0.922704         0.000849  \n",
       "2           0.920429         0.001145  \n",
       "3           0.966433         0.001054  \n",
       "4           0.964307         0.000731  \n",
       "5           0.963608         0.000682  \n",
       "6           0.976282         0.000346  \n",
       "7           0.976078         0.000752  \n",
       "8           0.974975         0.000675  \n",
       "9           0.996110         0.000269  \n",
       "10          0.995836         0.000291  \n",
       "11          0.995735         0.000193  \n",
       "12          0.998065         0.000114  \n",
       "13          0.998103         0.000236  \n",
       "14          0.998079         0.000092  \n",
       "15          0.999956         0.000014  \n",
       "16          0.999955         0.000011  \n",
       "17          0.999957         0.000010  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "import collections\n",
    "\n",
    "# Create pipeline (imbpipeline) with smote, scaler and classifier steps\n",
    "# imbpipeline automatically skip the sampling method (smote) when predict is called\n",
    "# -> Consequently, there is no data leakage\n",
    "pipeline = Pipeline(steps = [['smote', SMOTE(random_state = 11)],\n",
    "                             ['scaler', StandardScaler()],\n",
    "                             ['classifier', LGBMClassifier(random_state = 11)]])\n",
    "\n",
    "# Define stratifiedKfold\n",
    "stratified_kfold = StratifiedKFold(n_splits = 5,\n",
    "                                   shuffle = True,\n",
    "                                   random_state = 11)\n",
    "\n",
    "# Define param_grid for GridSearchCV\n",
    "param_grid = {'smote__sampling_strategy' : [0.25, 0.5, 1],\n",
    "              'classifier__n_estimators' : [500, 1000, 2000],\n",
    "              'classifier__num_leaves': [31, 50]}\n",
    "\n",
    "# Create GridSearchCV model\n",
    "gs_lgbm = GridSearchCV(estimator = pipeline,\n",
    "                       param_grid = param_grid,\n",
    "                       scoring = 'roc_auc',\n",
    "                       cv = stratified_kfold,\n",
    "                       verbose = 5,\n",
    "                       return_train_score = True)\n",
    "\n",
    "startTime = time.time()\n",
    "gs_lgbm.fit(X, y)\n",
    "executionTime = (time.time() - startTime)\n",
    "print('Execution time in seconds: ' + str(executionTime))\n",
    "print('Execution time in minutes: ' + str(executionTime / 60))\n",
    "\n",
    "cv_score_lgbm = gs_lgbm.best_score_\n",
    "print('cv_score_lgbm:', cv_score_lgbm)\n",
    "\n",
    "cv_results_lgbm = gs_lgbm.cv_results_\n",
    "df_lgbmc = pd.DataFrame(cv_results_lgbm)\n",
    "df_lgbmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a1a16c67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__n_estimators</th>\n",
       "      <th>param_classifier__num_leaves</th>\n",
       "      <th>param_smote__sampling_strategy</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72.202773</td>\n",
       "      <td>1.297574</td>\n",
       "      <td>1.110056</td>\n",
       "      <td>0.079992</td>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'classifier__n_estimators': 500, 'classifier__num_leaves': 50, 'smote__sampling_strategy': 0.25}</td>\n",
       "      <td>0.773792</td>\n",
       "      <td>0.777035</td>\n",
       "      <td>0.776821</td>\n",
       "      <td>0.772643</td>\n",
       "      <td>0.770777</td>\n",
       "      <td>0.774214</td>\n",
       "      <td>0.002417</td>\n",
       "      <td>1</td>\n",
       "      <td>0.966982</td>\n",
       "      <td>0.967604</td>\n",
       "      <td>0.965449</td>\n",
       "      <td>0.964916</td>\n",
       "      <td>0.967215</td>\n",
       "      <td>0.966433</td>\n",
       "      <td>0.001054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66.618199</td>\n",
       "      <td>2.164613</td>\n",
       "      <td>0.971173</td>\n",
       "      <td>0.020688</td>\n",
       "      <td>500</td>\n",
       "      <td>31</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'classifier__n_estimators': 500, 'classifier__num_leaves': 31, 'smote__sampling_strategy': 0.25}</td>\n",
       "      <td>0.773227</td>\n",
       "      <td>0.776018</td>\n",
       "      <td>0.777333</td>\n",
       "      <td>0.771847</td>\n",
       "      <td>0.771023</td>\n",
       "      <td>0.773890</td>\n",
       "      <td>0.002417</td>\n",
       "      <td>2</td>\n",
       "      <td>0.924462</td>\n",
       "      <td>0.923076</td>\n",
       "      <td>0.924853</td>\n",
       "      <td>0.923508</td>\n",
       "      <td>0.924685</td>\n",
       "      <td>0.924117</td>\n",
       "      <td>0.000698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74.674002</td>\n",
       "      <td>2.528774</td>\n",
       "      <td>0.990418</td>\n",
       "      <td>0.052328</td>\n",
       "      <td>500</td>\n",
       "      <td>31</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'classifier__n_estimators': 500, 'classifier__num_leaves': 31, 'smote__sampling_strategy': 0.5}</td>\n",
       "      <td>0.772564</td>\n",
       "      <td>0.775833</td>\n",
       "      <td>0.775728</td>\n",
       "      <td>0.770592</td>\n",
       "      <td>0.770485</td>\n",
       "      <td>0.773040</td>\n",
       "      <td>0.002357</td>\n",
       "      <td>3</td>\n",
       "      <td>0.924251</td>\n",
       "      <td>0.922251</td>\n",
       "      <td>0.922456</td>\n",
       "      <td>0.921741</td>\n",
       "      <td>0.922822</td>\n",
       "      <td>0.922704</td>\n",
       "      <td>0.000849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96.838054</td>\n",
       "      <td>5.120298</td>\n",
       "      <td>1.140891</td>\n",
       "      <td>0.040570</td>\n",
       "      <td>500</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>{'classifier__n_estimators': 500, 'classifier__num_leaves': 31, 'smote__sampling_strategy': 1}</td>\n",
       "      <td>0.771805</td>\n",
       "      <td>0.774772</td>\n",
       "      <td>0.774437</td>\n",
       "      <td>0.768953</td>\n",
       "      <td>0.768888</td>\n",
       "      <td>0.771771</td>\n",
       "      <td>0.002544</td>\n",
       "      <td>4</td>\n",
       "      <td>0.921223</td>\n",
       "      <td>0.919140</td>\n",
       "      <td>0.920365</td>\n",
       "      <td>0.919276</td>\n",
       "      <td>0.922141</td>\n",
       "      <td>0.920429</td>\n",
       "      <td>0.001145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>89.646433</td>\n",
       "      <td>2.136310</td>\n",
       "      <td>1.278153</td>\n",
       "      <td>0.081086</td>\n",
       "      <td>1000</td>\n",
       "      <td>31</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'classifier__n_estimators': 1000, 'classifier__num_leaves': 31, 'smote__sampling_strategy': 0.25}</td>\n",
       "      <td>0.772308</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.774872</td>\n",
       "      <td>0.769631</td>\n",
       "      <td>0.768025</td>\n",
       "      <td>0.771712</td>\n",
       "      <td>0.002542</td>\n",
       "      <td>5</td>\n",
       "      <td>0.976790</td>\n",
       "      <td>0.975762</td>\n",
       "      <td>0.976489</td>\n",
       "      <td>0.976124</td>\n",
       "      <td>0.976244</td>\n",
       "      <td>0.976282</td>\n",
       "      <td>0.000346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>111.616324</td>\n",
       "      <td>5.811772</td>\n",
       "      <td>1.298354</td>\n",
       "      <td>0.047061</td>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'classifier__n_estimators': 500, 'classifier__num_leaves': 50, 'smote__sampling_strategy': 1}</td>\n",
       "      <td>0.769581</td>\n",
       "      <td>0.774225</td>\n",
       "      <td>0.773546</td>\n",
       "      <td>0.768355</td>\n",
       "      <td>0.767114</td>\n",
       "      <td>0.770564</td>\n",
       "      <td>0.002830</td>\n",
       "      <td>6</td>\n",
       "      <td>0.963926</td>\n",
       "      <td>0.963878</td>\n",
       "      <td>0.963547</td>\n",
       "      <td>0.962341</td>\n",
       "      <td>0.964346</td>\n",
       "      <td>0.963608</td>\n",
       "      <td>0.000682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>106.547439</td>\n",
       "      <td>2.476292</td>\n",
       "      <td>1.380771</td>\n",
       "      <td>0.111980</td>\n",
       "      <td>1000</td>\n",
       "      <td>31</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'classifier__n_estimators': 1000, 'classifier__num_leaves': 31, 'smote__sampling_strategy': 0.5}</td>\n",
       "      <td>0.770759</td>\n",
       "      <td>0.772584</td>\n",
       "      <td>0.773297</td>\n",
       "      <td>0.767388</td>\n",
       "      <td>0.767811</td>\n",
       "      <td>0.770368</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>7</td>\n",
       "      <td>0.976743</td>\n",
       "      <td>0.975768</td>\n",
       "      <td>0.976403</td>\n",
       "      <td>0.974750</td>\n",
       "      <td>0.976726</td>\n",
       "      <td>0.976078</td>\n",
       "      <td>0.000752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82.702158</td>\n",
       "      <td>1.752617</td>\n",
       "      <td>1.116846</td>\n",
       "      <td>0.103315</td>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'classifier__n_estimators': 500, 'classifier__num_leaves': 50, 'smote__sampling_strategy': 0.5}</td>\n",
       "      <td>0.770817</td>\n",
       "      <td>0.773637</td>\n",
       "      <td>0.771191</td>\n",
       "      <td>0.766868</td>\n",
       "      <td>0.767513</td>\n",
       "      <td>0.770005</td>\n",
       "      <td>0.002502</td>\n",
       "      <td>8</td>\n",
       "      <td>0.965464</td>\n",
       "      <td>0.963829</td>\n",
       "      <td>0.963960</td>\n",
       "      <td>0.963458</td>\n",
       "      <td>0.964823</td>\n",
       "      <td>0.964307</td>\n",
       "      <td>0.000731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>506.298771</td>\n",
       "      <td>802.695461</td>\n",
       "      <td>1.427299</td>\n",
       "      <td>0.133539</td>\n",
       "      <td>1000</td>\n",
       "      <td>50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'classifier__n_estimators': 1000, 'classifier__num_leaves': 50, 'smote__sampling_strategy': 0.25}</td>\n",
       "      <td>0.769700</td>\n",
       "      <td>0.771081</td>\n",
       "      <td>0.773512</td>\n",
       "      <td>0.768467</td>\n",
       "      <td>0.765936</td>\n",
       "      <td>0.769739</td>\n",
       "      <td>0.002535</td>\n",
       "      <td>9</td>\n",
       "      <td>0.996418</td>\n",
       "      <td>0.995811</td>\n",
       "      <td>0.996073</td>\n",
       "      <td>0.995826</td>\n",
       "      <td>0.996420</td>\n",
       "      <td>0.996110</td>\n",
       "      <td>0.000269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>129.871383</td>\n",
       "      <td>3.644784</td>\n",
       "      <td>1.476653</td>\n",
       "      <td>0.047398</td>\n",
       "      <td>1000</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>{'classifier__n_estimators': 1000, 'classifier__num_leaves': 31, 'smote__sampling_strategy': 1}</td>\n",
       "      <td>0.770956</td>\n",
       "      <td>0.772990</td>\n",
       "      <td>0.771966</td>\n",
       "      <td>0.765887</td>\n",
       "      <td>0.766391</td>\n",
       "      <td>0.769638</td>\n",
       "      <td>0.002933</td>\n",
       "      <td>10</td>\n",
       "      <td>0.975636</td>\n",
       "      <td>0.974493</td>\n",
       "      <td>0.975060</td>\n",
       "      <td>0.973956</td>\n",
       "      <td>0.975727</td>\n",
       "      <td>0.974975</td>\n",
       "      <td>0.000675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>156.976225</td>\n",
       "      <td>3.011446</td>\n",
       "      <td>1.594004</td>\n",
       "      <td>0.071475</td>\n",
       "      <td>1000</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'classifier__n_estimators': 1000, 'classifier__num_leaves': 50, 'smote__sampling_strategy': 1}</td>\n",
       "      <td>0.767533</td>\n",
       "      <td>0.770786</td>\n",
       "      <td>0.770408</td>\n",
       "      <td>0.765597</td>\n",
       "      <td>0.763423</td>\n",
       "      <td>0.767550</td>\n",
       "      <td>0.002810</td>\n",
       "      <td>11</td>\n",
       "      <td>0.995842</td>\n",
       "      <td>0.995958</td>\n",
       "      <td>0.995556</td>\n",
       "      <td>0.995458</td>\n",
       "      <td>0.995859</td>\n",
       "      <td>0.995735</td>\n",
       "      <td>0.000193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>119.287371</td>\n",
       "      <td>6.977810</td>\n",
       "      <td>1.398691</td>\n",
       "      <td>0.184278</td>\n",
       "      <td>1000</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'classifier__n_estimators': 1000, 'classifier__num_leaves': 50, 'smote__sampling_strategy': 0.5}</td>\n",
       "      <td>0.767694</td>\n",
       "      <td>0.767706</td>\n",
       "      <td>0.768633</td>\n",
       "      <td>0.763547</td>\n",
       "      <td>0.762692</td>\n",
       "      <td>0.766054</td>\n",
       "      <td>0.002435</td>\n",
       "      <td>12</td>\n",
       "      <td>0.996258</td>\n",
       "      <td>0.995801</td>\n",
       "      <td>0.995876</td>\n",
       "      <td>0.995346</td>\n",
       "      <td>0.995898</td>\n",
       "      <td>0.995836</td>\n",
       "      <td>0.000291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>155.771564</td>\n",
       "      <td>1.190012</td>\n",
       "      <td>1.777720</td>\n",
       "      <td>0.073876</td>\n",
       "      <td>2000</td>\n",
       "      <td>31</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'classifier__n_estimators': 2000, 'classifier__num_leaves': 31, 'smote__sampling_strategy': 0.5}</td>\n",
       "      <td>0.766102</td>\n",
       "      <td>0.768289</td>\n",
       "      <td>0.768154</td>\n",
       "      <td>0.764340</td>\n",
       "      <td>0.762802</td>\n",
       "      <td>0.765937</td>\n",
       "      <td>0.002138</td>\n",
       "      <td>13</td>\n",
       "      <td>0.998402</td>\n",
       "      <td>0.997982</td>\n",
       "      <td>0.998221</td>\n",
       "      <td>0.997713</td>\n",
       "      <td>0.998197</td>\n",
       "      <td>0.998103</td>\n",
       "      <td>0.000236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>135.803819</td>\n",
       "      <td>2.633541</td>\n",
       "      <td>1.812112</td>\n",
       "      <td>0.079965</td>\n",
       "      <td>2000</td>\n",
       "      <td>31</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'classifier__n_estimators': 2000, 'classifier__num_leaves': 31, 'smote__sampling_strategy': 0.25}</td>\n",
       "      <td>0.767505</td>\n",
       "      <td>0.767431</td>\n",
       "      <td>0.769675</td>\n",
       "      <td>0.761750</td>\n",
       "      <td>0.762333</td>\n",
       "      <td>0.765739</td>\n",
       "      <td>0.003130</td>\n",
       "      <td>14</td>\n",
       "      <td>0.998148</td>\n",
       "      <td>0.997946</td>\n",
       "      <td>0.998090</td>\n",
       "      <td>0.997924</td>\n",
       "      <td>0.998218</td>\n",
       "      <td>0.998065</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>202.123518</td>\n",
       "      <td>5.364779</td>\n",
       "      <td>1.943548</td>\n",
       "      <td>0.049401</td>\n",
       "      <td>2000</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>{'classifier__n_estimators': 2000, 'classifier__num_leaves': 31, 'smote__sampling_strategy': 1}</td>\n",
       "      <td>0.767424</td>\n",
       "      <td>0.768283</td>\n",
       "      <td>0.767646</td>\n",
       "      <td>0.762108</td>\n",
       "      <td>0.762599</td>\n",
       "      <td>0.765612</td>\n",
       "      <td>0.002680</td>\n",
       "      <td>15</td>\n",
       "      <td>0.998167</td>\n",
       "      <td>0.998119</td>\n",
       "      <td>0.998071</td>\n",
       "      <td>0.997906</td>\n",
       "      <td>0.998132</td>\n",
       "      <td>0.998079</td>\n",
       "      <td>0.000092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>245.254930</td>\n",
       "      <td>5.509639</td>\n",
       "      <td>2.254425</td>\n",
       "      <td>0.110777</td>\n",
       "      <td>2000</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'classifier__n_estimators': 2000, 'classifier__num_leaves': 50, 'smote__sampling_strategy': 1}</td>\n",
       "      <td>0.761995</td>\n",
       "      <td>0.764898</td>\n",
       "      <td>0.763323</td>\n",
       "      <td>0.761062</td>\n",
       "      <td>0.756572</td>\n",
       "      <td>0.761570</td>\n",
       "      <td>0.002813</td>\n",
       "      <td>16</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.999956</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>161.333142</td>\n",
       "      <td>1.647390</td>\n",
       "      <td>1.916926</td>\n",
       "      <td>0.092329</td>\n",
       "      <td>2000</td>\n",
       "      <td>50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'classifier__n_estimators': 2000, 'classifier__num_leaves': 50, 'smote__sampling_strategy': 0.25}</td>\n",
       "      <td>0.761853</td>\n",
       "      <td>0.762484</td>\n",
       "      <td>0.766186</td>\n",
       "      <td>0.759603</td>\n",
       "      <td>0.757452</td>\n",
       "      <td>0.761516</td>\n",
       "      <td>0.002934</td>\n",
       "      <td>17</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.999933</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.999956</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1076.818812</td>\n",
       "      <td>1745.760954</td>\n",
       "      <td>2.206945</td>\n",
       "      <td>0.165852</td>\n",
       "      <td>2000</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'classifier__n_estimators': 2000, 'classifier__num_leaves': 50, 'smote__sampling_strategy': 0.5}</td>\n",
       "      <td>0.761433</td>\n",
       "      <td>0.760600</td>\n",
       "      <td>0.761021</td>\n",
       "      <td>0.758173</td>\n",
       "      <td>0.756578</td>\n",
       "      <td>0.759561</td>\n",
       "      <td>0.001873</td>\n",
       "      <td>18</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.999938</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "3       72.202773      1.297574         1.110056        0.079992   \n",
       "0       66.618199      2.164613         0.971173        0.020688   \n",
       "1       74.674002      2.528774         0.990418        0.052328   \n",
       "2       96.838054      5.120298         1.140891        0.040570   \n",
       "6       89.646433      2.136310         1.278153        0.081086   \n",
       "5      111.616324      5.811772         1.298354        0.047061   \n",
       "7      106.547439      2.476292         1.380771        0.111980   \n",
       "4       82.702158      1.752617         1.116846        0.103315   \n",
       "9      506.298771    802.695461         1.427299        0.133539   \n",
       "8      129.871383      3.644784         1.476653        0.047398   \n",
       "11     156.976225      3.011446         1.594004        0.071475   \n",
       "10     119.287371      6.977810         1.398691        0.184278   \n",
       "13     155.771564      1.190012         1.777720        0.073876   \n",
       "12     135.803819      2.633541         1.812112        0.079965   \n",
       "14     202.123518      5.364779         1.943548        0.049401   \n",
       "17     245.254930      5.509639         2.254425        0.110777   \n",
       "15     161.333142      1.647390         1.916926        0.092329   \n",
       "16    1076.818812   1745.760954         2.206945        0.165852   \n",
       "\n",
       "   param_classifier__n_estimators param_classifier__num_leaves  \\\n",
       "3                             500                           50   \n",
       "0                             500                           31   \n",
       "1                             500                           31   \n",
       "2                             500                           31   \n",
       "6                            1000                           31   \n",
       "5                             500                           50   \n",
       "7                            1000                           31   \n",
       "4                             500                           50   \n",
       "9                            1000                           50   \n",
       "8                            1000                           31   \n",
       "11                           1000                           50   \n",
       "10                           1000                           50   \n",
       "13                           2000                           31   \n",
       "12                           2000                           31   \n",
       "14                           2000                           31   \n",
       "17                           2000                           50   \n",
       "15                           2000                           50   \n",
       "16                           2000                           50   \n",
       "\n",
       "   param_smote__sampling_strategy  \\\n",
       "3                            0.25   \n",
       "0                            0.25   \n",
       "1                             0.5   \n",
       "2                               1   \n",
       "6                            0.25   \n",
       "5                               1   \n",
       "7                             0.5   \n",
       "4                             0.5   \n",
       "9                            0.25   \n",
       "8                               1   \n",
       "11                              1   \n",
       "10                            0.5   \n",
       "13                            0.5   \n",
       "12                           0.25   \n",
       "14                              1   \n",
       "17                              1   \n",
       "15                           0.25   \n",
       "16                            0.5   \n",
       "\n",
       "                                                                                                params  \\\n",
       "3    {'classifier__n_estimators': 500, 'classifier__num_leaves': 50, 'smote__sampling_strategy': 0.25}   \n",
       "0    {'classifier__n_estimators': 500, 'classifier__num_leaves': 31, 'smote__sampling_strategy': 0.25}   \n",
       "1     {'classifier__n_estimators': 500, 'classifier__num_leaves': 31, 'smote__sampling_strategy': 0.5}   \n",
       "2       {'classifier__n_estimators': 500, 'classifier__num_leaves': 31, 'smote__sampling_strategy': 1}   \n",
       "6   {'classifier__n_estimators': 1000, 'classifier__num_leaves': 31, 'smote__sampling_strategy': 0.25}   \n",
       "5       {'classifier__n_estimators': 500, 'classifier__num_leaves': 50, 'smote__sampling_strategy': 1}   \n",
       "7    {'classifier__n_estimators': 1000, 'classifier__num_leaves': 31, 'smote__sampling_strategy': 0.5}   \n",
       "4     {'classifier__n_estimators': 500, 'classifier__num_leaves': 50, 'smote__sampling_strategy': 0.5}   \n",
       "9   {'classifier__n_estimators': 1000, 'classifier__num_leaves': 50, 'smote__sampling_strategy': 0.25}   \n",
       "8      {'classifier__n_estimators': 1000, 'classifier__num_leaves': 31, 'smote__sampling_strategy': 1}   \n",
       "11     {'classifier__n_estimators': 1000, 'classifier__num_leaves': 50, 'smote__sampling_strategy': 1}   \n",
       "10   {'classifier__n_estimators': 1000, 'classifier__num_leaves': 50, 'smote__sampling_strategy': 0.5}   \n",
       "13   {'classifier__n_estimators': 2000, 'classifier__num_leaves': 31, 'smote__sampling_strategy': 0.5}   \n",
       "12  {'classifier__n_estimators': 2000, 'classifier__num_leaves': 31, 'smote__sampling_strategy': 0.25}   \n",
       "14     {'classifier__n_estimators': 2000, 'classifier__num_leaves': 31, 'smote__sampling_strategy': 1}   \n",
       "17     {'classifier__n_estimators': 2000, 'classifier__num_leaves': 50, 'smote__sampling_strategy': 1}   \n",
       "15  {'classifier__n_estimators': 2000, 'classifier__num_leaves': 50, 'smote__sampling_strategy': 0.25}   \n",
       "16   {'classifier__n_estimators': 2000, 'classifier__num_leaves': 50, 'smote__sampling_strategy': 0.5}   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "3            0.773792           0.777035           0.776821   \n",
       "0            0.773227           0.776018           0.777333   \n",
       "1            0.772564           0.775833           0.775728   \n",
       "2            0.771805           0.774772           0.774437   \n",
       "6            0.772308           0.773723           0.774872   \n",
       "5            0.769581           0.774225           0.773546   \n",
       "7            0.770759           0.772584           0.773297   \n",
       "4            0.770817           0.773637           0.771191   \n",
       "9            0.769700           0.771081           0.773512   \n",
       "8            0.770956           0.772990           0.771966   \n",
       "11           0.767533           0.770786           0.770408   \n",
       "10           0.767694           0.767706           0.768633   \n",
       "13           0.766102           0.768289           0.768154   \n",
       "12           0.767505           0.767431           0.769675   \n",
       "14           0.767424           0.768283           0.767646   \n",
       "17           0.761995           0.764898           0.763323   \n",
       "15           0.761853           0.762484           0.766186   \n",
       "16           0.761433           0.760600           0.761021   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "3            0.772643           0.770777         0.774214        0.002417   \n",
       "0            0.771847           0.771023         0.773890        0.002417   \n",
       "1            0.770592           0.770485         0.773040        0.002357   \n",
       "2            0.768953           0.768888         0.771771        0.002544   \n",
       "6            0.769631           0.768025         0.771712        0.002542   \n",
       "5            0.768355           0.767114         0.770564        0.002830   \n",
       "7            0.767388           0.767811         0.770368        0.002411   \n",
       "4            0.766868           0.767513         0.770005        0.002502   \n",
       "9            0.768467           0.765936         0.769739        0.002535   \n",
       "8            0.765887           0.766391         0.769638        0.002933   \n",
       "11           0.765597           0.763423         0.767550        0.002810   \n",
       "10           0.763547           0.762692         0.766054        0.002435   \n",
       "13           0.764340           0.762802         0.765937        0.002138   \n",
       "12           0.761750           0.762333         0.765739        0.003130   \n",
       "14           0.762108           0.762599         0.765612        0.002680   \n",
       "17           0.761062           0.756572         0.761570        0.002813   \n",
       "15           0.759603           0.757452         0.761516        0.002934   \n",
       "16           0.758173           0.756578         0.759561        0.001873   \n",
       "\n",
       "    rank_test_score  split0_train_score  split1_train_score  \\\n",
       "3                 1            0.966982            0.967604   \n",
       "0                 2            0.924462            0.923076   \n",
       "1                 3            0.924251            0.922251   \n",
       "2                 4            0.921223            0.919140   \n",
       "6                 5            0.976790            0.975762   \n",
       "5                 6            0.963926            0.963878   \n",
       "7                 7            0.976743            0.975768   \n",
       "4                 8            0.965464            0.963829   \n",
       "9                 9            0.996418            0.995811   \n",
       "8                10            0.975636            0.974493   \n",
       "11               11            0.995842            0.995958   \n",
       "10               12            0.996258            0.995801   \n",
       "13               13            0.998402            0.997982   \n",
       "12               14            0.998148            0.997946   \n",
       "14               15            0.998167            0.998119   \n",
       "17               16            0.999969            0.999969   \n",
       "15               17            0.999968            0.999969   \n",
       "16               18            0.999957            0.999971   \n",
       "\n",
       "    split2_train_score  split3_train_score  split4_train_score  \\\n",
       "3             0.965449            0.964916            0.967215   \n",
       "0             0.924853            0.923508            0.924685   \n",
       "1             0.922456            0.921741            0.922822   \n",
       "2             0.920365            0.919276            0.922141   \n",
       "6             0.976489            0.976124            0.976244   \n",
       "5             0.963547            0.962341            0.964346   \n",
       "7             0.976403            0.974750            0.976726   \n",
       "4             0.963960            0.963458            0.964823   \n",
       "9             0.996073            0.995826            0.996420   \n",
       "8             0.975060            0.973956            0.975727   \n",
       "11            0.995556            0.995458            0.995859   \n",
       "10            0.995876            0.995346            0.995898   \n",
       "13            0.998221            0.997713            0.998197   \n",
       "12            0.998090            0.997924            0.998218   \n",
       "14            0.998071            0.997906            0.998132   \n",
       "17            0.999956            0.999943            0.999949   \n",
       "15            0.999948            0.999933            0.999962   \n",
       "16            0.999951            0.999938            0.999959   \n",
       "\n",
       "    mean_train_score  std_train_score  \n",
       "3           0.966433         0.001054  \n",
       "0           0.924117         0.000698  \n",
       "1           0.922704         0.000849  \n",
       "2           0.920429         0.001145  \n",
       "6           0.976282         0.000346  \n",
       "5           0.963608         0.000682  \n",
       "7           0.976078         0.000752  \n",
       "4           0.964307         0.000731  \n",
       "9           0.996110         0.000269  \n",
       "8           0.974975         0.000675  \n",
       "11          0.995735         0.000193  \n",
       "10          0.995836         0.000291  \n",
       "13          0.998103         0.000236  \n",
       "12          0.998065         0.000114  \n",
       "14          0.998079         0.000092  \n",
       "17          0.999957         0.000010  \n",
       "15          0.999956         0.000014  \n",
       "16          0.999955         0.000011  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lgbmc.sort_values(by = 'rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c99ec4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END classifier__n_estimators=500, classifier__num_leaves=50, smote__sampling_strategy=0.25;, score=(train=0.979, test=0.764) total time= 1.1min\n",
      "[CV 2/5] END classifier__n_estimators=500, classifier__num_leaves=50, smote__sampling_strategy=0.25;, score=(train=0.979, test=0.762) total time= 1.0min\n",
      "[CV 3/5] END classifier__n_estimators=500, classifier__num_leaves=50, smote__sampling_strategy=0.25;, score=(train=0.979, test=0.773) total time= 1.0min\n",
      "[CV 4/5] END classifier__n_estimators=500, classifier__num_leaves=50, smote__sampling_strategy=0.25;, score=(train=0.979, test=0.770) total time=  59.8s\n",
      "[CV 5/5] END classifier__n_estimators=500, classifier__num_leaves=50, smote__sampling_strategy=0.25;, score=(train=0.979, test=0.770) total time= 1.0min\n",
      "Execution time in seconds: 390.32668566703796\n",
      "Execution time in minutes: 6.5054447611173\n",
      "cv_score_lgbm: 0.7742137000488987\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__n_estimators</th>\n",
       "      <th>param_classifier__num_leaves</th>\n",
       "      <th>param_smote__sampling_strategy</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60.682744</td>\n",
       "      <td>1.799231</td>\n",
       "      <td>0.86197</td>\n",
       "      <td>0.054159</td>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'classifier__n_estimators': 500, 'classifier__num_leaves': 50, 'smote__sampling_strategy': 0.25}</td>\n",
       "      <td>0.764262</td>\n",
       "      <td>0.76155</td>\n",
       "      <td>0.773186</td>\n",
       "      <td>0.769894</td>\n",
       "      <td>0.769627</td>\n",
       "      <td>0.767704</td>\n",
       "      <td>0.004202</td>\n",
       "      <td>1</td>\n",
       "      <td>0.979037</td>\n",
       "      <td>0.979121</td>\n",
       "      <td>0.978824</td>\n",
       "      <td>0.978613</td>\n",
       "      <td>0.978892</td>\n",
       "      <td>0.978897</td>\n",
       "      <td>0.000176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      60.682744      1.799231          0.86197        0.054159   \n",
       "\n",
       "  param_classifier__n_estimators param_classifier__num_leaves  \\\n",
       "0                            500                           50   \n",
       "\n",
       "  param_smote__sampling_strategy  \\\n",
       "0                           0.25   \n",
       "\n",
       "                                                                                              params  \\\n",
       "0  {'classifier__n_estimators': 500, 'classifier__num_leaves': 50, 'smote__sampling_strategy': 0.25}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.764262            0.76155           0.773186           0.769894   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0           0.769627         0.767704        0.004202                1   \n",
       "\n",
       "   split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0            0.979037            0.979121            0.978824   \n",
       "\n",
       "   split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.978613            0.978892          0.978897         0.000176  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import collections\n",
    "\n",
    "# Train_test_split 80/20 with stratify\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size = 0.2,\n",
    "                                                    stratify = y,\n",
    "                                                    random_state = 42)\n",
    "\n",
    "# Create pipeline (imbpipeline) with smote, scaler and classifier steps\n",
    "# imbpipeline automatically skip the sampling method (smote) when predict is called\n",
    "# -> Consequently, there is no data leakage\n",
    "pipeline = Pipeline(steps = [['smote', SMOTE(random_state = 11)],\n",
    "                             ['scaler', StandardScaler()],\n",
    "                             ['classifier', LGBMClassifier(random_state = 11)]])\n",
    "\n",
    "# Define stratifiedKfold\n",
    "stratified_kfold = StratifiedKFold(n_splits = 5,\n",
    "                                   shuffle = True,\n",
    "                                   random_state = 11)\n",
    "\n",
    "# Define param_grid for GridSearchCV\n",
    "param_grid = {'smote__sampling_strategy' : [0.25],\n",
    "              'classifier__n_estimators' : [500],\n",
    "              'classifier__num_leaves': [50]}\n",
    "\n",
    "# Create GridSearchCV model\n",
    "gs_lgbm = GridSearchCV(estimator = pipeline,\n",
    "                       param_grid = param_grid,\n",
    "                       scoring = 'roc_auc',\n",
    "                       cv = stratified_kfold,\n",
    "                       verbose = 5,\n",
    "                       return_train_score = True)\n",
    "\n",
    "startTime = time.time()\n",
    "gs_lgbm.fit(X_train, y_train)\n",
    "executionTime = (time.time() - startTime)\n",
    "print('Execution time in seconds: ' + str(executionTime))\n",
    "print('Execution time in minutes: ' + str(executionTime / 60))\n",
    "\n",
    "cv_score_lgbm_split = gs_lgbm.best_score_\n",
    "print('cv_score_lgbm:', cv_score_lgbm_split)\n",
    "\n",
    "cv_score_lgbm_split = gs_lgbm.cv_results_\n",
    "df_lgbmc_split = pd.DataFrame(cv_score_lgbm_split)\n",
    "df_lgbmc_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4f7895be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_score_lgbm: 0.767703866930104\n"
     ]
    }
   ],
   "source": [
    "cv_score_lgbm_split = gs_lgbm.best_score_\n",
    "print('cv_score_lgbm:', cv_score_lgbm_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5ab4d2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score = 0.7736628764583242\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model with best parameters on X_test using predict_proba to calculate AUC\n",
    "y_pred = gs_lgbm.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Calculate and print roc_auc score\n",
    "print('roc_auc_score =', roc_auc_score(y_test, y_pred))\n",
    "print('----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "29f19497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report :\n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      1.00      0.96     56537\n",
      "         1.0       0.52      0.06      0.10      4965\n",
      "\n",
      "    accuracy                           0.92     61502\n",
      "   macro avg       0.72      0.53      0.53     61502\n",
      "weighted avg       0.89      0.92      0.89     61502\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 33.0, 'predicted label'),\n",
       " Text(51.0, 0.5, 'true label'),\n",
       " Text(0.5, 1.0, 'Confusion Matrix test data')]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate model with best parameters on X_test using predict to calculate precision, recall and f1 score\n",
    "y_pred_binary = gs_lgbm.predict(X_test)\n",
    "\n",
    "# Print classification report with precision, recall and f1-score for each class\n",
    "from sklearn.metrics import classification_report\n",
    "print('classification_report :')\n",
    "print(' ')\n",
    "print(classification_report(y_test, y_pred_binary))\n",
    "\n",
    "# Print Confusion Matrix on Test data\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(y_test, y_pred_binary)\n",
    "data_cm = pd.DataFrame(conf_mat,\n",
    "                       index = ['can repay', 'can not repay'],\n",
    "                       columns = ['can repay', 'can not repay'])\n",
    "\n",
    "plt.figure(figsize = (8,6))\n",
    "cmap = 'YlOrBr'\n",
    "colormap = sns.heatmap(data_cm, \n",
    "                        annot=True, \n",
    "                        annot_kws ={'size':14}, \n",
    "                        cmap=cmap, \n",
    "                        fmt='.3g')\n",
    "colormap.set_xticklabels(colormap.get_xmajorticklabels(), size = 16)\n",
    "colormap.set_yticklabels(colormap.get_ymajorticklabels(), size = 16)\n",
    "    \n",
    "colormap.set(xlabel = 'predicted label',\n",
    "             ylabel = 'true label',\n",
    "             title = 'Confusion Matrix test data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8f0b8eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END classifier__n_estimators=500, classifier__num_leaves=50;, score=(train=0.974, test=0.775) total time= 2.4min\n",
      "[CV 2/5] END classifier__n_estimators=500, classifier__num_leaves=50;, score=(train=0.972, test=0.776) total time= 1.7min\n",
      "[CV 3/5] END classifier__n_estimators=500, classifier__num_leaves=50;, score=(train=0.973, test=0.775) total time= 1.3min\n",
      "[CV 4/5] END classifier__n_estimators=500, classifier__num_leaves=50;, score=(train=0.972, test=0.770) total time= 1.3min\n",
      "[CV 5/5] END classifier__n_estimators=500, classifier__num_leaves=50;, score=(train=0.974, test=0.771) total time= 1.2min\n",
      "Execution time in seconds: 592.7277464866638\n",
      "Execution time in minutes: 9.87879577477773\n",
      "cv_score_lgbm_nosmote: 0.7731350577713559\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__n_estimators</th>\n",
       "      <th>param_classifier__num_leaves</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94.241932</td>\n",
       "      <td>25.16736</td>\n",
       "      <td>1.628635</td>\n",
       "      <td>0.160443</td>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>{'classifier__n_estimators': 500, 'classifier__num_leaves': 50}</td>\n",
       "      <td>0.774763</td>\n",
       "      <td>0.775686</td>\n",
       "      <td>0.774952</td>\n",
       "      <td>0.769568</td>\n",
       "      <td>0.770706</td>\n",
       "      <td>0.773135</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>1</td>\n",
       "      <td>0.974429</td>\n",
       "      <td>0.972027</td>\n",
       "      <td>0.973428</td>\n",
       "      <td>0.971909</td>\n",
       "      <td>0.974448</td>\n",
       "      <td>0.973248</td>\n",
       "      <td>0.001109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      94.241932      25.16736         1.628635        0.160443   \n",
       "\n",
       "  param_classifier__n_estimators param_classifier__num_leaves  \\\n",
       "0                            500                           50   \n",
       "\n",
       "                                                            params  \\\n",
       "0  {'classifier__n_estimators': 500, 'classifier__num_leaves': 50}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.774763           0.775686           0.774952           0.769568   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0           0.770706         0.773135        0.002493                1   \n",
       "\n",
       "   split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0            0.974429            0.972027            0.973428   \n",
       "\n",
       "   split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.971909            0.974448          0.973248         0.001109  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Without SMOTE\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.pipeline import Pipeline\n",
    "import collections\n",
    "\n",
    "# Create pipeline (imbpipeline) with smote, scaler and classifier steps\n",
    "# imbpipeline automatically skip the sampling method (smote) when predict is called\n",
    "# -> Consequently, there is no data leakage\n",
    "pipeline = Pipeline(steps = [['scaler', StandardScaler()],\n",
    "                             ['classifier', LGBMClassifier(random_state = 11)]])\n",
    "\n",
    "# Define stratifiedKfold\n",
    "stratified_kfold = StratifiedKFold(n_splits = 5,\n",
    "                                   shuffle = True,\n",
    "                                   random_state = 11)\n",
    "\n",
    "# Define param_grid for GridSearchCV\n",
    "param_grid = {'classifier__n_estimators' : [500],\n",
    "              'classifier__num_leaves': [50]}\n",
    "\n",
    "# Create GridSearchCV model\n",
    "gs_lgbm_nosmote = GridSearchCV(estimator = pipeline,\n",
    "                       param_grid = param_grid,\n",
    "                       scoring = 'roc_auc',\n",
    "                       cv = stratified_kfold,\n",
    "                       verbose = 5,\n",
    "                       return_train_score = True)\n",
    "\n",
    "startTime = time.time()\n",
    "gs_lgbm_nosmote.fit(X, y)\n",
    "executionTime = (time.time() - startTime)\n",
    "print('Execution time in seconds: ' + str(executionTime))\n",
    "print('Execution time in minutes: ' + str(executionTime / 60))\n",
    "\n",
    "cv_score_lgbm_nosmote = gs_lgbm_nosmote.best_score_\n",
    "print('cv_score_lgbm_nosmote:', cv_score_lgbm_nosmote)\n",
    "\n",
    "cv_results_lgbm_nosmote = gs_lgbm_nosmote.cv_results_\n",
    "df_lgbmc_nosmote = pd.DataFrame(cv_results_lgbm_nosmote)\n",
    "df_lgbmc_nosmote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a314527e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END classifier__n_estimators=500, classifier__num_leaves=50, smote__sampling_strategy=1;, score=(train=0.978, test=0.764) total time= 1.5min\n",
      "[CV 2/5] END classifier__n_estimators=500, classifier__num_leaves=50, smote__sampling_strategy=1;, score=(train=0.978, test=0.762) total time= 1.3min\n",
      "[CV 3/5] END classifier__n_estimators=500, classifier__num_leaves=50, smote__sampling_strategy=1;, score=(train=0.977, test=0.767) total time= 1.4min\n",
      "[CV 4/5] END classifier__n_estimators=500, classifier__num_leaves=50, smote__sampling_strategy=1;, score=(train=0.977, test=0.770) total time= 1.4min\n",
      "[CV 5/5] END classifier__n_estimators=500, classifier__num_leaves=50, smote__sampling_strategy=1;, score=(train=0.976, test=0.770) total time= 1.4min\n",
      "Execution time in seconds: 544.1259362697601\n",
      "Execution time in minutes: 9.068765604496003\n",
      "cv_score_lgbm: 0.7667568611401436\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__n_estimators</th>\n",
       "      <th>param_classifier__num_leaves</th>\n",
       "      <th>param_smote__sampling_strategy</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83.841846</td>\n",
       "      <td>4.374064</td>\n",
       "      <td>0.862647</td>\n",
       "      <td>0.035596</td>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'classifier__n_estimators': 500, 'classifier__num_leaves': 50, 'smote__sampling_strategy': 1}</td>\n",
       "      <td>0.76389</td>\n",
       "      <td>0.762356</td>\n",
       "      <td>0.767387</td>\n",
       "      <td>0.769783</td>\n",
       "      <td>0.770368</td>\n",
       "      <td>0.766757</td>\n",
       "      <td>0.003168</td>\n",
       "      <td>1</td>\n",
       "      <td>0.978311</td>\n",
       "      <td>0.977937</td>\n",
       "      <td>0.977408</td>\n",
       "      <td>0.976799</td>\n",
       "      <td>0.976158</td>\n",
       "      <td>0.977323</td>\n",
       "      <td>0.000773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      83.841846      4.374064         0.862647        0.035596   \n",
       "\n",
       "  param_classifier__n_estimators param_classifier__num_leaves  \\\n",
       "0                            500                           50   \n",
       "\n",
       "  param_smote__sampling_strategy  \\\n",
       "0                              1   \n",
       "\n",
       "                                                                                           params  \\\n",
       "0  {'classifier__n_estimators': 500, 'classifier__num_leaves': 50, 'smote__sampling_strategy': 1}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.76389           0.762356           0.767387           0.769783   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0           0.770368         0.766757        0.003168                1   \n",
       "\n",
       "   split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0            0.978311            0.977937            0.977408   \n",
       "\n",
       "   split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.976799            0.976158          0.977323         0.000773  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import collections\n",
    "\n",
    "# Train_test_split 80/20 with stratify\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size = 0.2,\n",
    "                                                    stratify = y,\n",
    "                                                    random_state = 42)\n",
    "\n",
    "# Create pipeline (imbpipeline) with smote, scaler and classifier steps\n",
    "# imbpipeline automatically skip the sampling method (smote) when predict is called\n",
    "# -> Consequently, there is no data leakage\n",
    "pipeline = Pipeline(steps = [['smote', SMOTE(random_state = 11)],\n",
    "                             ['scaler', StandardScaler()],\n",
    "                             ['classifier', LGBMClassifier(random_state = 11)]])\n",
    "\n",
    "# Define stratifiedKfold\n",
    "stratified_kfold = StratifiedKFold(n_splits = 5,\n",
    "                                   shuffle = True,\n",
    "                                   random_state = 11)\n",
    "\n",
    "# Define param_grid for GridSearchCV\n",
    "param_grid = {'smote__sampling_strategy' : [1],\n",
    "              'classifier__n_estimators' : [500],\n",
    "              'classifier__num_leaves': [50]}\n",
    "\n",
    "# Create GridSearchCV model\n",
    "gs_lgbm = GridSearchCV(estimator = pipeline,\n",
    "                       param_grid = param_grid,\n",
    "                       scoring = 'roc_auc',\n",
    "                       cv = stratified_kfold,\n",
    "                       verbose = 5,\n",
    "                       return_train_score = True)\n",
    "\n",
    "startTime = time.time()\n",
    "gs_lgbm.fit(X_train, y_train)\n",
    "executionTime = (time.time() - startTime)\n",
    "print('Execution time in seconds: ' + str(executionTime))\n",
    "print('Execution time in minutes: ' + str(executionTime / 60))\n",
    "\n",
    "cv_score_lgbm_split = gs_lgbm.best_score_\n",
    "print('cv_score_lgbm:', cv_score_lgbm_split)\n",
    "\n",
    "cv_score_lgbm_split = gs_lgbm.cv_results_\n",
    "df_lgbmc_split = pd.DataFrame(cv_score_lgbm_split)\n",
    "df_lgbmc_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a1b81e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score = 0.7728170918060041\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model with best parameters on X_test using predict_proba to calculate AUC\n",
    "y_pred = gs_lgbm.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Calculate and print roc_auc score\n",
    "print('roc_auc_score =', roc_auc_score(y_test, y_pred))\n",
    "print('----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3c261964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report :\n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.99      0.96     56537\n",
      "         1.0       0.48      0.06      0.10      4965\n",
      "\n",
      "    accuracy                           0.92     61502\n",
      "   macro avg       0.70      0.53      0.53     61502\n",
      "weighted avg       0.89      0.92      0.89     61502\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 33.0, 'predicted label'),\n",
       " Text(51.0, 0.5, 'true label'),\n",
       " Text(0.5, 1.0, 'Confusion Matrix test data')]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate model with best parameters on X_test using predict to calculate precision, recall and f1 score\n",
    "y_pred_binary = gs_lgbm.predict(X_test)\n",
    "\n",
    "# Print classification report with precision, recall and f1-score for each class\n",
    "from sklearn.metrics import classification_report\n",
    "print('classification_report :')\n",
    "print(' ')\n",
    "print(classification_report(y_test, y_pred_binary))\n",
    "\n",
    "# Print Confusion Matrix on Test data\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(y_test, y_pred_binary)\n",
    "data_cm = pd.DataFrame(conf_mat,\n",
    "                       index = ['can repay', 'can not repay'],\n",
    "                       columns = ['can repay', 'can not repay'])\n",
    "\n",
    "plt.figure(figsize = (8,6))\n",
    "cmap = 'YlOrBr'\n",
    "colormap = sns.heatmap(data_cm, \n",
    "                        annot=True, \n",
    "                        annot_kws ={'size':14}, \n",
    "                        cmap=cmap, \n",
    "                        fmt='.3g')\n",
    "colormap.set_xticklabels(colormap.get_xmajorticklabels(), size = 16)\n",
    "colormap.set_yticklabels(colormap.get_ymajorticklabels(), size = 16)\n",
    "    \n",
    "colormap.set(xlabel = 'predicted label',\n",
    "             ylabel = 'true label',\n",
    "             title = 'Confusion Matrix test data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a876691",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "abcb39f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM GBDT with KFold or Stratified KFold\n",
    "# Parameters from Tilii kernel: https://www.kaggle.com/tilii7/olivier-lightgbm-parameters-by-bayesian-opt/code\n",
    "def kfold_lightgbm_noopt(df, num_folds, stratified = False, debug= False):\n",
    "\n",
    "    # Cross validation model\n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(n_splits = num_folds, shuffle = True, random_state = 1001)\n",
    "    else:\n",
    "        folds = KFold(n_splits = num_folds, shuffle = True, random_state = 1001)\n",
    "    # Create arrays and dataframes to store results\n",
    "    oof_preds = np.zeros(train_df.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
    "        train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
    "        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n",
    "\n",
    "        # LightGBM parameters\n",
    "        clf = LGBMClassifier(n_estimators = 1000)\n",
    "\n",
    "        clf.fit(train_x, train_y, eval_set = [(train_x, train_y), (valid_x, valid_y)], \n",
    "            eval_metric = 'auc', verbose = 200, early_stopping_rounds = 200)\n",
    "\n",
    "        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n",
    "\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feats\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "        fold_importance_df[\"fold\"] = n_fold + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n",
    "        del clf, train_x, train_y, valid_x, valid_y\n",
    "\n",
    "    print('Full AUC score %.6f' % roc_auc_score(train_df['TARGET'], oof_preds))\n",
    "    # plot feature importance\n",
    "    display_importances(feature_importance_df)\n",
    "    return feature_importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0fbdf9",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a075fb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV 1/5] END classifier__C=0.1, classifier__max_iter=1000, classifier__solver=lbfgs, smote__sampling_strategy=0.25;, score=(train=0.773, test=0.764) total time= 2.1min\n",
      "[CV 2/5] END classifier__C=0.1, classifier__max_iter=1000, classifier__solver=lbfgs, smote__sampling_strategy=0.25;, score=(train=0.775, test=0.758) total time= 1.6min\n",
      "[CV 3/5] END classifier__C=0.1, classifier__max_iter=1000, classifier__solver=lbfgs, smote__sampling_strategy=0.25;, score=(train=0.773, test=0.767) total time= 2.0min\n",
      "[CV 4/5] END classifier__C=0.1, classifier__max_iter=1000, classifier__solver=lbfgs, smote__sampling_strategy=0.25;, score=(train=0.772, test=0.771) total time= 3.0min\n",
      "[CV 5/5] END classifier__C=0.1, classifier__max_iter=1000, classifier__solver=lbfgs, smote__sampling_strategy=0.25;, score=(train=0.773, test=0.768) total time= 2.2min\n",
      "[CV 1/5] END classifier__C=0.1, classifier__max_iter=1000, classifier__solver=lbfgs, smote__sampling_strategy=0.5;, score=(train=0.773, test=0.764) total time= 1.7min\n",
      "[CV 2/5] END classifier__C=0.1, classifier__max_iter=1000, classifier__solver=lbfgs, smote__sampling_strategy=0.5;, score=(train=0.774, test=0.757) total time= 2.0min\n",
      "[CV 3/5] END classifier__C=0.1, classifier__max_iter=1000, classifier__solver=lbfgs, smote__sampling_strategy=0.5;, score=(train=0.773, test=0.767) total time= 1.7min\n",
      "[CV 4/5] END classifier__C=0.1, classifier__max_iter=1000, classifier__solver=lbfgs, smote__sampling_strategy=0.5;, score=(train=0.771, test=0.771) total time= 1.8min\n",
      "[CV 5/5] END classifier__C=0.1, classifier__max_iter=1000, classifier__solver=lbfgs, smote__sampling_strategy=0.5;, score=(train=0.772, test=0.768) total time= 1.8min\n",
      "[CV 1/5] END classifier__C=0.1, classifier__max_iter=1000, classifier__solver=lbfgs, smote__sampling_strategy=1;, score=(train=0.772, test=0.763) total time= 2.3min\n",
      "[CV 2/5] END classifier__C=0.1, classifier__max_iter=1000, classifier__solver=lbfgs, smote__sampling_strategy=1;, score=(train=0.773, test=0.756) total time= 3.6min\n",
      "[CV 3/5] END classifier__C=0.1, classifier__max_iter=1000, classifier__solver=lbfgs, smote__sampling_strategy=1;, score=(train=0.772, test=0.767) total time= 3.6min\n",
      "[CV 4/5] END classifier__C=0.1, classifier__max_iter=1000, classifier__solver=lbfgs, smote__sampling_strategy=1;, score=(train=0.770, test=0.770) total time= 3.8min\n",
      "[CV 5/5] END classifier__C=0.1, classifier__max_iter=1000, classifier__solver=lbfgs, smote__sampling_strategy=1;, score=(train=0.771, test=0.767) total time= 4.3min\n",
      "[CV 1/5] END classifier__C=0.1, classifier__max_iter=5000, classifier__solver=lbfgs, smote__sampling_strategy=0.25;, score=(train=0.773, test=0.764) total time= 3.0min\n",
      "[CV 2/5] END classifier__C=0.1, classifier__max_iter=5000, classifier__solver=lbfgs, smote__sampling_strategy=0.25;, score=(train=0.775, test=0.758) total time= 1.6min\n",
      "[CV 3/5] END classifier__C=0.1, classifier__max_iter=5000, classifier__solver=lbfgs, smote__sampling_strategy=0.25;, score=(train=0.773, test=0.767) total time= 1.6min\n",
      "[CV 4/5] END classifier__C=0.1, classifier__max_iter=5000, classifier__solver=lbfgs, smote__sampling_strategy=0.25;, score=(train=0.772, test=0.771) total time= 1.4min\n",
      "[CV 5/5] END classifier__C=0.1, classifier__max_iter=5000, classifier__solver=lbfgs, smote__sampling_strategy=0.25;, score=(train=0.773, test=0.768) total time= 2.1min\n",
      "[CV 1/5] END classifier__C=0.1, classifier__max_iter=5000, classifier__solver=lbfgs, smote__sampling_strategy=0.5;, score=(train=0.773, test=0.764) total time= 1.6min\n",
      "[CV 2/5] END classifier__C=0.1, classifier__max_iter=5000, classifier__solver=lbfgs, smote__sampling_strategy=0.5;, score=(train=0.774, test=0.757) total time= 2.1min\n",
      "[CV 3/5] END classifier__C=0.1, classifier__max_iter=5000, classifier__solver=lbfgs, smote__sampling_strategy=0.5;, score=(train=0.773, test=0.767) total time= 1.6min\n",
      "[CV 4/5] END classifier__C=0.1, classifier__max_iter=5000, classifier__solver=lbfgs, smote__sampling_strategy=0.5;, score=(train=0.771, test=0.771) total time= 2.0min\n",
      "[CV 5/5] END classifier__C=0.1, classifier__max_iter=5000, classifier__solver=lbfgs, smote__sampling_strategy=0.5;, score=(train=0.772, test=0.768) total time= 1.7min\n",
      "[CV 1/5] END classifier__C=0.1, classifier__max_iter=5000, classifier__solver=lbfgs, smote__sampling_strategy=1;, score=(train=0.772, test=0.763) total time= 2.6min\n",
      "[CV 2/5] END classifier__C=0.1, classifier__max_iter=5000, classifier__solver=lbfgs, smote__sampling_strategy=1;, score=(train=0.773, test=0.756) total time= 5.4min\n",
      "[CV 3/5] END classifier__C=0.1, classifier__max_iter=5000, classifier__solver=lbfgs, smote__sampling_strategy=1;, score=(train=0.772, test=0.767) total time= 4.8min\n",
      "[CV 4/5] END classifier__C=0.1, classifier__max_iter=5000, classifier__solver=lbfgs, smote__sampling_strategy=1;, score=(train=0.770, test=0.770) total time= 4.4min\n",
      "[CV 5/5] END classifier__C=0.1, classifier__max_iter=5000, classifier__solver=lbfgs, smote__sampling_strategy=1;, score=(train=0.771, test=0.767) total time= 4.7min\n",
      "[CV 1/5] END classifier__C=1, classifier__max_iter=1000, classifier__solver=lbfgs, smote__sampling_strategy=0.25;, score=(train=0.774, test=0.765) total time= 2.8min\n",
      "[CV 2/5] END classifier__C=1, classifier__max_iter=1000, classifier__solver=lbfgs, smote__sampling_strategy=0.25;, score=(train=0.775, test=0.758) total time= 2.6min\n",
      "[CV 3/5] END classifier__C=1, classifier__max_iter=1000, classifier__solver=lbfgs, smote__sampling_strategy=0.25;, score=(train=0.774, test=0.768) total time= 2.6min\n",
      "[CV 4/5] END classifier__C=1, classifier__max_iter=1000, classifier__solver=lbfgs, smote__sampling_strategy=0.25;, score=(train=0.772, test=0.772) total time= 2.3min\n",
      "[CV 5/5] END classifier__C=1, classifier__max_iter=1000, classifier__solver=lbfgs, smote__sampling_strategy=0.25;, score=(train=0.773, test=0.769) total time= 2.6min\n",
      "[CV 1/5] END classifier__C=1, classifier__max_iter=1000, classifier__solver=lbfgs, smote__sampling_strategy=0.5;, score=(train=0.774, test=0.765) total time= 3.1min\n",
      "[CV 2/5] END classifier__C=1, classifier__max_iter=1000, classifier__solver=lbfgs, smote__sampling_strategy=0.5;, score=(train=0.775, test=0.758) total time= 4.1min\n",
      "[CV 3/5] END classifier__C=1, classifier__max_iter=1000, classifier__solver=lbfgs, smote__sampling_strategy=0.5;, score=(train=0.773, test=0.767) total time= 3.2min\n",
      "[CV 4/5] END classifier__C=1, classifier__max_iter=1000, classifier__solver=lbfgs, smote__sampling_strategy=0.5;, score=(train=0.772, test=0.772) total time= 2.9min\n",
      "[CV 5/5] END classifier__C=1, classifier__max_iter=1000, classifier__solver=lbfgs, smote__sampling_strategy=0.5;, score=(train=0.773, test=0.769) total time= 3.5min\n",
      "[CV 1/5] END classifier__C=1, classifier__max_iter=1000, classifier__solver=lbfgs, smote__sampling_strategy=1;, score=(train=0.773, test=0.764) total time= 4.2min\n",
      "[CV 2/5] END classifier__C=1, classifier__max_iter=1000, classifier__solver=lbfgs, smote__sampling_strategy=1;, score=(train=0.774, test=0.757) total time= 4.3min\n",
      "[CV 3/5] END classifier__C=1, classifier__max_iter=1000, classifier__solver=lbfgs, smote__sampling_strategy=1;, score=(train=0.773, test=0.767) total time= 4.0min\n",
      "[CV 4/5] END classifier__C=1, classifier__max_iter=1000, classifier__solver=lbfgs, smote__sampling_strategy=1;, score=(train=0.771, test=0.771) total time= 5.9min\n",
      "[CV 5/5] END classifier__C=1, classifier__max_iter=1000, classifier__solver=lbfgs, smote__sampling_strategy=1;, score=(train=0.772, test=0.768) total time= 4.2min\n",
      "[CV 1/5] END classifier__C=1, classifier__max_iter=5000, classifier__solver=lbfgs, smote__sampling_strategy=0.25;, score=(train=0.774, test=0.765) total time= 2.6min\n",
      "[CV 2/5] END classifier__C=1, classifier__max_iter=5000, classifier__solver=lbfgs, smote__sampling_strategy=0.25;, score=(train=0.775, test=0.758) total time= 2.8min\n",
      "[CV 3/5] END classifier__C=1, classifier__max_iter=5000, classifier__solver=lbfgs, smote__sampling_strategy=0.25;, score=(train=0.774, test=0.768) total time= 2.7min\n",
      "[CV 4/5] END classifier__C=1, classifier__max_iter=5000, classifier__solver=lbfgs, smote__sampling_strategy=0.25;, score=(train=0.772, test=0.772) total time= 2.5min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9820/141304900.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mstartFitTime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mgs_lr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[0mexecutionFitTime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstartFitTime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Execution time in seconds: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexecutionFitTime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1392\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    836\u001b[0m                     )\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 838\u001b[1;33m                 out = parallel(\n\u001b[0m\u001b[0;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[0;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1046\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1047\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    678\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    270\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"passthrough\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 272\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1587\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1588\u001b[0m             \u001b[0mprefer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"processes\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1589\u001b[1;33m         fold_coefs_ = Parallel(\n\u001b[0m\u001b[0;32m   1590\u001b[0m             \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1591\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[0;32m    804\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    805\u001b[0m             ]\n\u001b[1;32m--> 806\u001b[1;33m             opt_res = optimize.minimize(\n\u001b[0m\u001b[0;32m    807\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    808\u001b[0m                 \u001b[0mw0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    621\u001b[0m                                   **options)\n\u001b[0;32m    622\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'l-bfgs-b'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 623\u001b[1;33m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[0;32m    624\u001b[0m                                 callback=callback, **options)\n\u001b[0;32m    625\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tnc'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    358\u001b[0m             \u001b[1;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m             \u001b[1;31m# Overwrite f and g:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb'NEW_X'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m             \u001b[1;31m# new iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    265\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    231\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[1;31m# Overwriting results in undefined behaviour because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[1;31m# fun(self.x) will change self.x, with the two no longer linked.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;34m\"\"\" returns the the function value \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m             \u001b[0mfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36m_logistic_loss_and_grad\u001b[1;34m(w, X, y, alpha, sample_weight)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m     \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_intercept_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36m_intercept_dot\u001b[1;34m(w, X, y)\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m     \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m     \u001b[0myz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m     if (\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline(steps = [['smote', SMOTE(random_state = 11)],\n",
    "                             ['scaler', StandardScaler()],\n",
    "                             ['classifier', LogisticRegression()]])\n",
    "\n",
    "# Define stratifiedKfold\n",
    "stratified_kfold = StratifiedKFold(n_splits = 5,\n",
    "                                   shuffle = True,\n",
    "                                   random_state = 11)\n",
    "\n",
    "param_grid = {'smote__sampling_strategy' : [0.25, 0.5, 1],\n",
    "              'classifier__C' : [0.1, 1, 10],\n",
    "              'classifier__solver' : ['lbfgs'],\n",
    "              'classifier__max_iter' : [1000, 5000]}\n",
    "\n",
    "gs_lr = GridSearchCV(estimator = pipeline,\n",
    "                           param_grid = param_grid,\n",
    "                           scoring = 'roc_auc',\n",
    "                           cv = stratified_kfold,\n",
    "                           verbose = 5,\n",
    "                           return_train_score = True)\n",
    "\n",
    "startFitTime = time.time()\n",
    "gs_lr.fit(X_train, y_train)\n",
    "executionFitTime = (time.time() - startFitTime)\n",
    "print('Execution time in seconds: ' + str(executionFitTime))\n",
    "print('Execution time in minutes: ' + str(executionFitTime / 60))\n",
    "\n",
    "cv_score_lr = gs_lr.best_score_\n",
    "print('cv_score_lr:', cv_score_lr)\n",
    "\n",
    "cv_results_lr = gs_lr.cv_results_\n",
    "df_lr = pd.DataFrame(cv_results_lr)\n",
    "df_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5a722af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END classifier__C=1, classifier__max_iter=1000, classifier__solver=lbfgs;, score=(train=0.773, test=0.768) total time= 2.6min\n",
      "[CV 2/5] END classifier__C=1, classifier__max_iter=1000, classifier__solver=lbfgs;, score=(train=0.773, test=0.769) total time= 2.9min\n",
      "[CV 3/5] END classifier__C=1, classifier__max_iter=1000, classifier__solver=lbfgs;, score=(train=0.774, test=0.768) total time= 2.5min\n",
      "[CV 4/5] END classifier__C=1, classifier__max_iter=1000, classifier__solver=lbfgs;, score=(train=0.774, test=0.767) total time= 3.0min\n",
      "[CV 5/5] END classifier__C=1, classifier__max_iter=1000, classifier__solver=lbfgs;, score=(train=0.774, test=0.766) total time= 2.7min\n",
      "Execution time in seconds: 1076.7124409675598\n",
      "Execution time in minutes: 17.94520734945933\n",
      "cv_score_lr_nosmote: 0.7676401492946174\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__C</th>\n",
       "      <th>param_classifier__max_iter</th>\n",
       "      <th>param_classifier__solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>163.596861</td>\n",
       "      <td>11.236769</td>\n",
       "      <td>0.598293</td>\n",
       "      <td>0.090444</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__max_iter': 1000, 'classifier__solver': 'lbfgs'}</td>\n",
       "      <td>0.76837</td>\n",
       "      <td>0.768809</td>\n",
       "      <td>0.768117</td>\n",
       "      <td>0.767209</td>\n",
       "      <td>0.765695</td>\n",
       "      <td>0.76764</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>1</td>\n",
       "      <td>0.773302</td>\n",
       "      <td>0.773151</td>\n",
       "      <td>0.773545</td>\n",
       "      <td>0.77366</td>\n",
       "      <td>0.77412</td>\n",
       "      <td>0.773556</td>\n",
       "      <td>0.000334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0     163.596861     11.236769         0.598293        0.090444   \n",
       "\n",
       "  param_classifier__C param_classifier__max_iter param_classifier__solver  \\\n",
       "0                   1                       1000                    lbfgs   \n",
       "\n",
       "                                                                              params  \\\n",
       "0  {'classifier__C': 1, 'classifier__max_iter': 1000, 'classifier__solver': 'lbfgs'}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.76837           0.768809           0.768117           0.767209   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0           0.765695          0.76764        0.001104                1   \n",
       "\n",
       "   split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0            0.773302            0.773151            0.773545   \n",
       "\n",
       "   split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "0             0.77366             0.77412          0.773556         0.000334  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Without SMOTE on X and y\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline(steps = [['scaler', StandardScaler()],\n",
    "                             ['classifier', LogisticRegression()]])\n",
    "\n",
    "# Define stratifiedKfold\n",
    "stratified_kfold = StratifiedKFold(n_splits = 5,\n",
    "                                   shuffle = True,\n",
    "                                   random_state = 11)\n",
    "\n",
    "param_grid = {'classifier__C' : [1],\n",
    "              'classifier__solver' : ['lbfgs'],\n",
    "              'classifier__max_iter' : [1000]}\n",
    "\n",
    "gs_lr_nosmote = GridSearchCV(estimator = pipeline,\n",
    "                           param_grid = param_grid,\n",
    "                           scoring = 'roc_auc',\n",
    "                           cv = stratified_kfold,\n",
    "                           verbose = 5,\n",
    "                           return_train_score = True)\n",
    "\n",
    "startFitTime = time.time()\n",
    "gs_lr_nosmote.fit(X, y)\n",
    "executionFitTime = (time.time() - startFitTime)\n",
    "print('Execution time in seconds: ' + str(executionFitTime))\n",
    "print('Execution time in minutes: ' + str(executionFitTime / 60))\n",
    "\n",
    "cv_score_lr_nosmote = gs_lr_nosmote.best_score_\n",
    "print('cv_score_lr_nosmote:', cv_score_lr_nosmote)\n",
    "\n",
    "cv_results_lr_nosmote = gs_lr_nosmote.cv_results_\n",
    "df_lr_nosmote = pd.DataFrame(cv_results_lr_nosmote)\n",
    "df_lr_nosmote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "81267a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END classifier__C=1, classifier__max_iter=1000, classifier__solver=lbfgs;, score=(train=0.774, test=0.765) total time= 2.3min\n",
      "[CV 2/5] END classifier__C=1, classifier__max_iter=1000, classifier__solver=lbfgs;, score=(train=0.775, test=0.758) total time= 1.5min\n",
      "[CV 3/5] END classifier__C=1, classifier__max_iter=1000, classifier__solver=lbfgs;, score=(train=0.774, test=0.768) total time= 1.6min\n",
      "[CV 4/5] END classifier__C=1, classifier__max_iter=1000, classifier__solver=lbfgs;, score=(train=0.772, test=0.772) total time= 1.6min\n",
      "[CV 5/5] END classifier__C=1, classifier__max_iter=1000, classifier__solver=lbfgs;, score=(train=0.773, test=0.769) total time= 1.4min\n",
      "Execution time in seconds: 643.7809603214264\n",
      "Execution time in minutes: 10.729682672023774\n",
      "cv_score_lr_nosmote: 0.7663652521151343\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__C</th>\n",
       "      <th>param_classifier__max_iter</th>\n",
       "      <th>param_classifier__solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.698241</td>\n",
       "      <td>18.378486</td>\n",
       "      <td>0.31871</td>\n",
       "      <td>0.031994</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__max_iter': 1000, 'classifier__solver': 'lbfgs'}</td>\n",
       "      <td>0.765013</td>\n",
       "      <td>0.758399</td>\n",
       "      <td>0.767535</td>\n",
       "      <td>0.771968</td>\n",
       "      <td>0.76891</td>\n",
       "      <td>0.766365</td>\n",
       "      <td>0.004572</td>\n",
       "      <td>1</td>\n",
       "      <td>0.77422</td>\n",
       "      <td>0.775352</td>\n",
       "      <td>0.773606</td>\n",
       "      <td>0.772409</td>\n",
       "      <td>0.773285</td>\n",
       "      <td>0.773774</td>\n",
       "      <td>0.000982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0     100.698241     18.378486          0.31871        0.031994   \n",
       "\n",
       "  param_classifier__C param_classifier__max_iter param_classifier__solver  \\\n",
       "0                   1                       1000                    lbfgs   \n",
       "\n",
       "                                                                              params  \\\n",
       "0  {'classifier__C': 1, 'classifier__max_iter': 1000, 'classifier__solver': 'lbfgs'}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.765013           0.758399           0.767535           0.771968   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0            0.76891         0.766365        0.004572                1   \n",
       "\n",
       "   split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0             0.77422            0.775352            0.773606   \n",
       "\n",
       "   split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.772409            0.773285          0.773774         0.000982  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Without SMOTE on X_train and y_train\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline(steps = [['scaler', StandardScaler()],\n",
    "                             ['classifier', LogisticRegression()]])\n",
    "\n",
    "# Define stratifiedKfold\n",
    "stratified_kfold = StratifiedKFold(n_splits = 5,\n",
    "                                   shuffle = True,\n",
    "                                   random_state = 11)\n",
    "\n",
    "param_grid = {'classifier__C' : [1],\n",
    "              'classifier__solver' : ['lbfgs'],\n",
    "              'classifier__max_iter' : [1000]}\n",
    "\n",
    "gs_lr_nosmote = GridSearchCV(estimator = pipeline,\n",
    "                           param_grid = param_grid,\n",
    "                           scoring = 'roc_auc',\n",
    "                           cv = stratified_kfold,\n",
    "                           verbose = 5,\n",
    "                           return_train_score = True)\n",
    "\n",
    "startFitTime = time.time()\n",
    "gs_lr_nosmote.fit(X_train, y_train)\n",
    "executionFitTime = (time.time() - startFitTime)\n",
    "print('Execution time in seconds: ' + str(executionFitTime))\n",
    "print('Execution time in minutes: ' + str(executionFitTime / 60))\n",
    "\n",
    "cv_score_lr_nosmote = gs_lr_nosmote.best_score_\n",
    "print('cv_score_lr_nosmote:', cv_score_lr_nosmote)\n",
    "\n",
    "cv_results_lr_nosmote = gs_lr_nosmote.cv_results_\n",
    "df_lr_nosmote = pd.DataFrame(cv_results_lr_nosmote)\n",
    "df_lr_nosmote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c02e113a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score = 0.7691044699207842\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model with best parameters on X_test\n",
    "y_pred = gs_lr_nosmote.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Calculate and print roc_auc score\n",
    "print('roc_auc_score =', roc_auc_score(y_test, y_pred))\n",
    "print('----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "be9f6d2e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report :\n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      1.00      0.96     56537\n",
      "         1.0       0.53      0.03      0.05      4965\n",
      "\n",
      "    accuracy                           0.92     61502\n",
      "   macro avg       0.73      0.51      0.51     61502\n",
      "weighted avg       0.89      0.92      0.88     61502\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 33.0, 'predicted label'),\n",
       " Text(51.0, 0.5, 'true label'),\n",
       " Text(0.5, 1.0, 'Confusion Matrix test data')]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate model with best parameters on X_test\n",
    "y_pred = gs_lr_nosmote.predict(X_test)\n",
    "\n",
    "# Print classification report with precision, recall and f1-score for each class\n",
    "from sklearn.metrics import classification_report\n",
    "print('classification_report :')\n",
    "print(' ')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print Confusion Matrix on Test data\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "data_cm = pd.DataFrame(conf_mat,\n",
    "                       index = ['can repay', 'can not repay'],\n",
    "                       columns = ['can repay', 'can not repay'])\n",
    "\n",
    "plt.figure(figsize = (8,6))\n",
    "cmap = 'YlOrBr'\n",
    "colormap = sns.heatmap(data_cm, \n",
    "                        annot=True, \n",
    "                        annot_kws ={'size':14}, \n",
    "                        cmap=cmap, \n",
    "                        fmt='.3g')\n",
    "colormap.set_xticklabels(colormap.get_xmajorticklabels(), size = 16)\n",
    "colormap.set_yticklabels(colormap.get_ymajorticklabels(), size = 16)\n",
    "    \n",
    "colormap.set(xlabel = 'predicted label',\n",
    "            ylabel = 'true label',\n",
    "            title = 'Confusion Matrix test data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d1e005ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END classifier__C=1, classifier__max_iter=1000, classifier__solver=lbfgs, smote__sampling_strategy=1;, score=(train=0.773, test=0.764) total time= 4.0min\n",
      "[CV 2/5] END classifier__C=1, classifier__max_iter=1000, classifier__solver=lbfgs, smote__sampling_strategy=1;, score=(train=0.774, test=0.757) total time= 3.9min\n",
      "[CV 3/5] END classifier__C=1, classifier__max_iter=1000, classifier__solver=lbfgs, smote__sampling_strategy=1;, score=(train=0.773, test=0.767) total time= 3.8min\n",
      "[CV 4/5] END classifier__C=1, classifier__max_iter=1000, classifier__solver=lbfgs, smote__sampling_strategy=1;, score=(train=0.771, test=0.771) total time= 3.9min\n",
      "[CV 5/5] END classifier__C=1, classifier__max_iter=1000, classifier__solver=lbfgs, smote__sampling_strategy=1;, score=(train=0.772, test=0.768) total time= 4.3min\n",
      "Execution time in seconds: 1521.027200460434\n",
      "Execution time in minutes: 25.35045334100723\n",
      "cv_score_lr: 0.7653771485409696\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__C</th>\n",
       "      <th>param_classifier__max_iter</th>\n",
       "      <th>param_classifier__solver</th>\n",
       "      <th>param_smote__sampling_strategy</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>238.285234</td>\n",
       "      <td>10.07973</td>\n",
       "      <td>0.472794</td>\n",
       "      <td>0.030021</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>1</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__max_iter': 1000, 'classifier__solver': 'lbfgs', 'smote__sampling_strategy': 1}</td>\n",
       "      <td>0.764238</td>\n",
       "      <td>0.75709</td>\n",
       "      <td>0.76705</td>\n",
       "      <td>0.770724</td>\n",
       "      <td>0.767784</td>\n",
       "      <td>0.765377</td>\n",
       "      <td>0.004629</td>\n",
       "      <td>1</td>\n",
       "      <td>0.773327</td>\n",
       "      <td>0.774295</td>\n",
       "      <td>0.772794</td>\n",
       "      <td>0.771241</td>\n",
       "      <td>0.772268</td>\n",
       "      <td>0.772785</td>\n",
       "      <td>0.001022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0     238.285234      10.07973         0.472794        0.030021   \n",
       "\n",
       "  param_classifier__C param_classifier__max_iter param_classifier__solver  \\\n",
       "0                   1                       1000                    lbfgs   \n",
       "\n",
       "  param_smote__sampling_strategy  \\\n",
       "0                              1   \n",
       "\n",
       "                                                                                                             params  \\\n",
       "0  {'classifier__C': 1, 'classifier__max_iter': 1000, 'classifier__solver': 'lbfgs', 'smote__sampling_strategy': 1}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.764238            0.75709            0.76705           0.770724   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0           0.767784         0.765377        0.004629                1   \n",
       "\n",
       "   split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0            0.773327            0.774295            0.772794   \n",
       "\n",
       "   split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.771241            0.772268          0.772785         0.001022  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline(steps = [['smote', SMOTE(random_state = 11)],\n",
    "                             ['scaler', StandardScaler()],\n",
    "                             ['classifier', LogisticRegression()]])\n",
    "\n",
    "# Define stratifiedKfold\n",
    "stratified_kfold = StratifiedKFold(n_splits = 5,\n",
    "                                   shuffle = True,\n",
    "                                   random_state = 11)\n",
    "\n",
    "param_grid = {'smote__sampling_strategy' : [1],\n",
    "              'classifier__C' : [1],\n",
    "              'classifier__solver' : ['lbfgs'],\n",
    "              'classifier__max_iter' : [1000]}\n",
    "\n",
    "gs_lr_smote = GridSearchCV(estimator = pipeline,\n",
    "                           param_grid = param_grid,\n",
    "                           scoring = 'roc_auc',\n",
    "                           cv = stratified_kfold,\n",
    "                           verbose = 5,\n",
    "                           return_train_score = True)\n",
    "\n",
    "startFitTime = time.time()\n",
    "gs_lr_smote.fit(X_train, y_train)\n",
    "executionFitTime = (time.time() - startFitTime)\n",
    "print('Execution time in seconds: ' + str(executionFitTime))\n",
    "print('Execution time in minutes: ' + str(executionFitTime / 60))\n",
    "\n",
    "cv_score_lr_smote = gs_lr_smote.best_score_\n",
    "print('cv_score_lr:', cv_score_lr_smote)\n",
    "\n",
    "cv_results_lr_smote = gs_lr_smote.cv_results_\n",
    "df_lr_smote = pd.DataFrame(cv_results_lr_smote)\n",
    "df_lr_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "80a3522d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score = 0.768679089227828\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model with best parameters on X_test\n",
    "y_pred = gs_lr_smote.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Calculate and print roc_auc score\n",
    "print('roc_auc_score =', roc_auc_score(y_test, y_pred))\n",
    "print('----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "73e760af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report :\n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      1.00      0.96     56537\n",
      "         1.0       0.51      0.03      0.05      4965\n",
      "\n",
      "    accuracy                           0.92     61502\n",
      "   macro avg       0.72      0.51      0.51     61502\n",
      "weighted avg       0.89      0.92      0.88     61502\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 24.0, 'predicted label'),\n",
       " Text(33.0, 0.5, 'true label'),\n",
       " Text(0.5, 1.0, 'Confusion Matrix test data')]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate model with best parameters on X_test\n",
    "y_pred = gs_lr_smote.predict(X_test)\n",
    "\n",
    "# Print classification report with precision, recall and f1-score for each class\n",
    "from sklearn.metrics import classification_report\n",
    "print('classification_report :')\n",
    "print(' ')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print Confusion Matrix on Test data\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "data_cm = pd.DataFrame(conf_mat,\n",
    "                       index = ['can repay', 'can not repay'],\n",
    "                       columns = ['can repay', 'can not repay'])\n",
    "\n",
    "plt.figure(figsize = (6,5))\n",
    "cmap = 'YlOrBr'\n",
    "colormap = sns.heatmap(data_cm, \n",
    "                        annot=True, \n",
    "                        annot_kws ={'size':14}, \n",
    "                        cmap=cmap, \n",
    "                        fmt='.3g')\n",
    "colormap.set_xticklabels(colormap.get_xmajorticklabels(), size = 16)\n",
    "colormap.set_yticklabels(colormap.get_ymajorticklabels(), size = 16)\n",
    "    \n",
    "colormap.set(xlabel = 'predicted label',\n",
    "            ylabel = 'true label',\n",
    "            title = 'Confusion Matrix test data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b044478f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ce92f039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define true positives, false positives, false negatives and true negatives\n",
    "TP = conf_mat[0][0]\n",
    "FP = conf_mat[0][1]\n",
    "FN = conf_mat[1][0]\n",
    "TN = conf_mat[1][1]\n",
    "\n",
    "# Define business cost function\n",
    "cost = 10 * FN + FP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6148ba1",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9cec164a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5] END classifier__var_smoothing=1e-10, smote__sampling_strategy=0.25;, score=(train=0.530, test=0.530) total time=  32.6s\n",
      "[CV 2/5] END classifier__var_smoothing=1e-10, smote__sampling_strategy=0.25;, score=(train=0.531, test=0.528) total time=  28.5s\n",
      "[CV 3/5] END classifier__var_smoothing=1e-10, smote__sampling_strategy=0.25;, score=(train=0.531, test=0.527) total time=  29.5s\n",
      "[CV 4/5] END classifier__var_smoothing=1e-10, smote__sampling_strategy=0.25;, score=(train=0.531, test=0.524) total time=  29.3s\n",
      "[CV 5/5] END classifier__var_smoothing=1e-10, smote__sampling_strategy=0.25;, score=(train=0.531, test=0.532) total time=  33.0s\n",
      "[CV 1/5] END classifier__var_smoothing=1e-10, smote__sampling_strategy=0.5;, score=(train=0.531, test=0.531) total time=  32.8s\n",
      "[CV 2/5] END classifier__var_smoothing=1e-10, smote__sampling_strategy=0.5;, score=(train=0.531, test=0.529) total time=  33.9s\n",
      "[CV 3/5] END classifier__var_smoothing=1e-10, smote__sampling_strategy=0.5;, score=(train=0.531, test=0.529) total time=  32.6s\n",
      "[CV 4/5] END classifier__var_smoothing=1e-10, smote__sampling_strategy=0.5;, score=(train=0.532, test=0.523) total time=  30.1s\n",
      "[CV 5/5] END classifier__var_smoothing=1e-10, smote__sampling_strategy=0.5;, score=(train=0.531, test=0.537) total time=  34.6s\n",
      "[CV 1/5] END classifier__var_smoothing=1e-10, smote__sampling_strategy=1;, score=(train=0.527, test=0.528) total time=  50.6s\n",
      "[CV 2/5] END classifier__var_smoothing=1e-10, smote__sampling_strategy=1;, score=(train=0.527, test=0.523) total time=  52.3s\n",
      "[CV 3/5] END classifier__var_smoothing=1e-10, smote__sampling_strategy=1;, score=(train=0.528, test=0.521) total time=  40.2s\n",
      "[CV 4/5] END classifier__var_smoothing=1e-10, smote__sampling_strategy=1;, score=(train=0.528, test=0.522) total time=  44.1s\n",
      "[CV 5/5] END classifier__var_smoothing=1e-10, smote__sampling_strategy=1;, score=(train=0.526, test=0.533) total time=  43.3s\n",
      "[CV 1/5] END classifier__var_smoothing=1e-09, smote__sampling_strategy=0.25;, score=(train=0.531, test=0.532) total time=  27.5s\n",
      "[CV 2/5] END classifier__var_smoothing=1e-09, smote__sampling_strategy=0.25;, score=(train=0.533, test=0.529) total time=  28.1s\n",
      "[CV 3/5] END classifier__var_smoothing=1e-09, smote__sampling_strategy=0.25;, score=(train=0.531, test=0.528) total time=  25.4s\n",
      "[CV 4/5] END classifier__var_smoothing=1e-09, smote__sampling_strategy=0.25;, score=(train=0.532, test=0.525) total time=  26.4s\n",
      "[CV 5/5] END classifier__var_smoothing=1e-09, smote__sampling_strategy=0.25;, score=(train=0.532, test=0.534) total time=  25.3s\n",
      "[CV 1/5] END classifier__var_smoothing=1e-09, smote__sampling_strategy=0.5;, score=(train=0.532, test=0.531) total time=  28.1s\n",
      "[CV 2/5] END classifier__var_smoothing=1e-09, smote__sampling_strategy=0.5;, score=(train=0.532, test=0.530) total time=  28.2s\n",
      "[CV 3/5] END classifier__var_smoothing=1e-09, smote__sampling_strategy=0.5;, score=(train=0.532, test=0.529) total time=  28.0s\n",
      "[CV 4/5] END classifier__var_smoothing=1e-09, smote__sampling_strategy=0.5;, score=(train=0.533, test=0.523) total time=  28.1s\n",
      "[CV 5/5] END classifier__var_smoothing=1e-09, smote__sampling_strategy=0.5;, score=(train=0.532, test=0.536) total time=  29.4s\n",
      "[CV 1/5] END classifier__var_smoothing=1e-09, smote__sampling_strategy=1;, score=(train=0.527, test=0.529) total time=  39.5s\n",
      "[CV 2/5] END classifier__var_smoothing=1e-09, smote__sampling_strategy=1;, score=(train=0.528, test=0.522) total time=  40.1s\n",
      "[CV 3/5] END classifier__var_smoothing=1e-09, smote__sampling_strategy=1;, score=(train=0.529, test=0.522) total time=  40.1s\n",
      "[CV 4/5] END classifier__var_smoothing=1e-09, smote__sampling_strategy=1;, score=(train=0.529, test=0.522) total time=  38.1s\n",
      "[CV 5/5] END classifier__var_smoothing=1e-09, smote__sampling_strategy=1;, score=(train=0.526, test=0.534) total time=  40.2s\n",
      "[CV 1/5] END classifier__var_smoothing=1e-08, smote__sampling_strategy=0.25;, score=(train=0.532, test=0.535) total time=  25.5s\n",
      "[CV 2/5] END classifier__var_smoothing=1e-08, smote__sampling_strategy=0.25;, score=(train=0.535, test=0.530) total time=  25.3s\n",
      "[CV 3/5] END classifier__var_smoothing=1e-08, smote__sampling_strategy=0.25;, score=(train=0.533, test=0.530) total time=  25.8s\n",
      "[CV 4/5] END classifier__var_smoothing=1e-08, smote__sampling_strategy=0.25;, score=(train=0.534, test=0.526) total time=  27.8s\n",
      "[CV 5/5] END classifier__var_smoothing=1e-08, smote__sampling_strategy=0.25;, score=(train=0.534, test=0.537) total time=  26.1s\n",
      "[CV 1/5] END classifier__var_smoothing=1e-08, smote__sampling_strategy=0.5;, score=(train=0.533, test=0.533) total time=  30.0s\n",
      "[CV 2/5] END classifier__var_smoothing=1e-08, smote__sampling_strategy=0.5;, score=(train=0.533, test=0.530) total time=  30.6s\n",
      "[CV 3/5] END classifier__var_smoothing=1e-08, smote__sampling_strategy=0.5;, score=(train=0.532, test=0.529) total time=  27.4s\n",
      "[CV 4/5] END classifier__var_smoothing=1e-08, smote__sampling_strategy=0.5;, score=(train=0.534, test=0.523) total time=  28.1s\n",
      "[CV 5/5] END classifier__var_smoothing=1e-08, smote__sampling_strategy=0.5;, score=(train=0.533, test=0.536) total time=  27.3s\n",
      "[CV 1/5] END classifier__var_smoothing=1e-08, smote__sampling_strategy=1;, score=(train=0.528, test=0.529) total time=  38.2s\n",
      "[CV 2/5] END classifier__var_smoothing=1e-08, smote__sampling_strategy=1;, score=(train=0.529, test=0.523) total time=  38.1s\n",
      "[CV 3/5] END classifier__var_smoothing=1e-08, smote__sampling_strategy=1;, score=(train=0.529, test=0.522) total time=  38.0s\n",
      "[CV 4/5] END classifier__var_smoothing=1e-08, smote__sampling_strategy=1;, score=(train=0.529, test=0.523) total time=  36.1s\n",
      "[CV 5/5] END classifier__var_smoothing=1e-08, smote__sampling_strategy=1;, score=(train=0.527, test=0.535) total time=  37.2s\n",
      "Execution time in seconds: 1714.7483413219452\n",
      "Execution time in minutes: 28.579139022032418\n",
      "cv_score_lr: 0.5315803274266127\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__var_smoothing</th>\n",
       "      <th>param_smote__sampling_strategy</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.542884</td>\n",
       "      <td>1.751076</td>\n",
       "      <td>1.165426</td>\n",
       "      <td>0.223057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'classifier__var_smoothing': 1e-10, 'smote__sampling_strategy': 0.25}</td>\n",
       "      <td>0.529743</td>\n",
       "      <td>0.528115</td>\n",
       "      <td>0.527000</td>\n",
       "      <td>0.523511</td>\n",
       "      <td>0.531563</td>\n",
       "      <td>0.527986</td>\n",
       "      <td>0.002716</td>\n",
       "      <td>6</td>\n",
       "      <td>0.529697</td>\n",
       "      <td>0.531089</td>\n",
       "      <td>0.530544</td>\n",
       "      <td>0.530520</td>\n",
       "      <td>0.530577</td>\n",
       "      <td>0.530486</td>\n",
       "      <td>0.000447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.679370</td>\n",
       "      <td>1.557167</td>\n",
       "      <td>1.220369</td>\n",
       "      <td>0.134651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'classifier__var_smoothing': 1e-10, 'smote__sampling_strategy': 0.5}</td>\n",
       "      <td>0.531387</td>\n",
       "      <td>0.528784</td>\n",
       "      <td>0.528729</td>\n",
       "      <td>0.522529</td>\n",
       "      <td>0.536513</td>\n",
       "      <td>0.529588</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>5</td>\n",
       "      <td>0.531283</td>\n",
       "      <td>0.531367</td>\n",
       "      <td>0.530981</td>\n",
       "      <td>0.532109</td>\n",
       "      <td>0.530923</td>\n",
       "      <td>0.531332</td>\n",
       "      <td>0.000424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.783925</td>\n",
       "      <td>4.592491</td>\n",
       "      <td>1.441373</td>\n",
       "      <td>0.073133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>{'classifier__var_smoothing': 1e-10, 'smote__sampling_strategy': 1}</td>\n",
       "      <td>0.527925</td>\n",
       "      <td>0.522573</td>\n",
       "      <td>0.520869</td>\n",
       "      <td>0.521779</td>\n",
       "      <td>0.533168</td>\n",
       "      <td>0.525263</td>\n",
       "      <td>0.004653</td>\n",
       "      <td>9</td>\n",
       "      <td>0.527182</td>\n",
       "      <td>0.527379</td>\n",
       "      <td>0.527799</td>\n",
       "      <td>0.528207</td>\n",
       "      <td>0.525987</td>\n",
       "      <td>0.527311</td>\n",
       "      <td>0.000750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.504206</td>\n",
       "      <td>1.120828</td>\n",
       "      <td>1.110065</td>\n",
       "      <td>0.052439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'classifier__var_smoothing': 1e-09, 'smote__sampling_strategy': 0.25}</td>\n",
       "      <td>0.532245</td>\n",
       "      <td>0.528900</td>\n",
       "      <td>0.527956</td>\n",
       "      <td>0.525329</td>\n",
       "      <td>0.534369</td>\n",
       "      <td>0.529760</td>\n",
       "      <td>0.003195</td>\n",
       "      <td>4</td>\n",
       "      <td>0.530596</td>\n",
       "      <td>0.532697</td>\n",
       "      <td>0.531385</td>\n",
       "      <td>0.531917</td>\n",
       "      <td>0.532067</td>\n",
       "      <td>0.531732</td>\n",
       "      <td>0.000706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.377073</td>\n",
       "      <td>0.557480</td>\n",
       "      <td>1.094078</td>\n",
       "      <td>0.037892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'classifier__var_smoothing': 1e-09, 'smote__sampling_strategy': 0.5}</td>\n",
       "      <td>0.531489</td>\n",
       "      <td>0.529800</td>\n",
       "      <td>0.528631</td>\n",
       "      <td>0.522580</td>\n",
       "      <td>0.536396</td>\n",
       "      <td>0.529779</td>\n",
       "      <td>0.004469</td>\n",
       "      <td>3</td>\n",
       "      <td>0.531920</td>\n",
       "      <td>0.531595</td>\n",
       "      <td>0.531728</td>\n",
       "      <td>0.533150</td>\n",
       "      <td>0.531578</td>\n",
       "      <td>0.531994</td>\n",
       "      <td>0.000591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>38.082590</td>\n",
       "      <td>1.065586</td>\n",
       "      <td>1.595274</td>\n",
       "      <td>0.667945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>{'classifier__var_smoothing': 1e-09, 'smote__sampling_strategy': 1}</td>\n",
       "      <td>0.529030</td>\n",
       "      <td>0.522451</td>\n",
       "      <td>0.521644</td>\n",
       "      <td>0.522114</td>\n",
       "      <td>0.534116</td>\n",
       "      <td>0.525871</td>\n",
       "      <td>0.004932</td>\n",
       "      <td>8</td>\n",
       "      <td>0.527429</td>\n",
       "      <td>0.527795</td>\n",
       "      <td>0.528716</td>\n",
       "      <td>0.528655</td>\n",
       "      <td>0.526227</td>\n",
       "      <td>0.527764</td>\n",
       "      <td>0.000914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25.151571</td>\n",
       "      <td>0.886764</td>\n",
       "      <td>1.074035</td>\n",
       "      <td>0.066415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'classifier__var_smoothing': 1e-08, 'smote__sampling_strategy': 0.25}</td>\n",
       "      <td>0.534600</td>\n",
       "      <td>0.530286</td>\n",
       "      <td>0.529826</td>\n",
       "      <td>0.526204</td>\n",
       "      <td>0.536987</td>\n",
       "      <td>0.531580</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>1</td>\n",
       "      <td>0.531948</td>\n",
       "      <td>0.534733</td>\n",
       "      <td>0.532732</td>\n",
       "      <td>0.533627</td>\n",
       "      <td>0.534015</td>\n",
       "      <td>0.533411</td>\n",
       "      <td>0.000976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>27.716515</td>\n",
       "      <td>1.361949</td>\n",
       "      <td>1.064037</td>\n",
       "      <td>0.023078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'classifier__var_smoothing': 1e-08, 'smote__sampling_strategy': 0.5}</td>\n",
       "      <td>0.532922</td>\n",
       "      <td>0.530282</td>\n",
       "      <td>0.529120</td>\n",
       "      <td>0.523191</td>\n",
       "      <td>0.536300</td>\n",
       "      <td>0.530363</td>\n",
       "      <td>0.004354</td>\n",
       "      <td>2</td>\n",
       "      <td>0.532842</td>\n",
       "      <td>0.532842</td>\n",
       "      <td>0.532224</td>\n",
       "      <td>0.533881</td>\n",
       "      <td>0.532517</td>\n",
       "      <td>0.532861</td>\n",
       "      <td>0.000560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36.281756</td>\n",
       "      <td>0.904808</td>\n",
       "      <td>1.323155</td>\n",
       "      <td>0.120614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>{'classifier__var_smoothing': 1e-08, 'smote__sampling_strategy': 1}</td>\n",
       "      <td>0.528520</td>\n",
       "      <td>0.523125</td>\n",
       "      <td>0.522471</td>\n",
       "      <td>0.522630</td>\n",
       "      <td>0.534938</td>\n",
       "      <td>0.526337</td>\n",
       "      <td>0.004853</td>\n",
       "      <td>7</td>\n",
       "      <td>0.528136</td>\n",
       "      <td>0.528843</td>\n",
       "      <td>0.529121</td>\n",
       "      <td>0.529118</td>\n",
       "      <td>0.527154</td>\n",
       "      <td>0.528475</td>\n",
       "      <td>0.000752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      29.542884      1.751076         1.165426        0.223057   \n",
       "1      31.679370      1.557167         1.220369        0.134651   \n",
       "2      44.783925      4.592491         1.441373        0.073133   \n",
       "3      25.504206      1.120828         1.110065        0.052439   \n",
       "4      27.377073      0.557480         1.094078        0.037892   \n",
       "5      38.082590      1.065586         1.595274        0.667945   \n",
       "6      25.151571      0.886764         1.074035        0.066415   \n",
       "7      27.716515      1.361949         1.064037        0.023078   \n",
       "8      36.281756      0.904808         1.323155        0.120614   \n",
       "\n",
       "  param_classifier__var_smoothing param_smote__sampling_strategy  \\\n",
       "0                             0.0                           0.25   \n",
       "1                             0.0                            0.5   \n",
       "2                             0.0                              1   \n",
       "3                             0.0                           0.25   \n",
       "4                             0.0                            0.5   \n",
       "5                             0.0                              1   \n",
       "6                             0.0                           0.25   \n",
       "7                             0.0                            0.5   \n",
       "8                             0.0                              1   \n",
       "\n",
       "                                                                   params  \\\n",
       "0  {'classifier__var_smoothing': 1e-10, 'smote__sampling_strategy': 0.25}   \n",
       "1   {'classifier__var_smoothing': 1e-10, 'smote__sampling_strategy': 0.5}   \n",
       "2     {'classifier__var_smoothing': 1e-10, 'smote__sampling_strategy': 1}   \n",
       "3  {'classifier__var_smoothing': 1e-09, 'smote__sampling_strategy': 0.25}   \n",
       "4   {'classifier__var_smoothing': 1e-09, 'smote__sampling_strategy': 0.5}   \n",
       "5     {'classifier__var_smoothing': 1e-09, 'smote__sampling_strategy': 1}   \n",
       "6  {'classifier__var_smoothing': 1e-08, 'smote__sampling_strategy': 0.25}   \n",
       "7   {'classifier__var_smoothing': 1e-08, 'smote__sampling_strategy': 0.5}   \n",
       "8     {'classifier__var_smoothing': 1e-08, 'smote__sampling_strategy': 1}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.529743           0.528115           0.527000           0.523511   \n",
       "1           0.531387           0.528784           0.528729           0.522529   \n",
       "2           0.527925           0.522573           0.520869           0.521779   \n",
       "3           0.532245           0.528900           0.527956           0.525329   \n",
       "4           0.531489           0.529800           0.528631           0.522580   \n",
       "5           0.529030           0.522451           0.521644           0.522114   \n",
       "6           0.534600           0.530286           0.529826           0.526204   \n",
       "7           0.532922           0.530282           0.529120           0.523191   \n",
       "8           0.528520           0.523125           0.522471           0.522630   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0           0.531563         0.527986        0.002716                6   \n",
       "1           0.536513         0.529588        0.004525                5   \n",
       "2           0.533168         0.525263        0.004653                9   \n",
       "3           0.534369         0.529760        0.003195                4   \n",
       "4           0.536396         0.529779        0.004469                3   \n",
       "5           0.534116         0.525871        0.004932                8   \n",
       "6           0.536987         0.531580        0.003795                1   \n",
       "7           0.536300         0.530363        0.004354                2   \n",
       "8           0.534938         0.526337        0.004853                7   \n",
       "\n",
       "   split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0            0.529697            0.531089            0.530544   \n",
       "1            0.531283            0.531367            0.530981   \n",
       "2            0.527182            0.527379            0.527799   \n",
       "3            0.530596            0.532697            0.531385   \n",
       "4            0.531920            0.531595            0.531728   \n",
       "5            0.527429            0.527795            0.528716   \n",
       "6            0.531948            0.534733            0.532732   \n",
       "7            0.532842            0.532842            0.532224   \n",
       "8            0.528136            0.528843            0.529121   \n",
       "\n",
       "   split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.530520            0.530577          0.530486         0.000447  \n",
       "1            0.532109            0.530923          0.531332         0.000424  \n",
       "2            0.528207            0.525987          0.527311         0.000750  \n",
       "3            0.531917            0.532067          0.531732         0.000706  \n",
       "4            0.533150            0.531578          0.531994         0.000591  \n",
       "5            0.528655            0.526227          0.527764         0.000914  \n",
       "6            0.533627            0.534015          0.533411         0.000976  \n",
       "7            0.533881            0.532517          0.532861         0.000560  \n",
       "8            0.529118            0.527154          0.528475         0.000752  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline(steps = [['smote', SMOTE(random_state = 11)],\n",
    "                             ['scaler', StandardScaler()],\n",
    "                             ['classifier', GaussianNB()]])\n",
    "\n",
    "# Define stratifiedKfold\n",
    "stratified_kfold = StratifiedKFold(n_splits = 5,\n",
    "                                   shuffle = True,\n",
    "                                   random_state = 11)\n",
    "\n",
    "param_grid = {'smote__sampling_strategy' : [0.25, 0.5, 1],\n",
    "              'classifier__var_smoothing' : [1e-10, 1e-9, 1e-8]}\n",
    "\n",
    "gs_nb = GridSearchCV(estimator = pipeline,\n",
    "                           param_grid = param_grid,\n",
    "                           scoring = 'roc_auc',\n",
    "                           cv = stratified_kfold,\n",
    "                           verbose = 5,\n",
    "                           return_train_score = True)\n",
    "\n",
    "startFitTime = time.time()\n",
    "gs_nb.fit(X, y)\n",
    "executionFitTime = (time.time() - startFitTime)\n",
    "print('Execution time in seconds: ' + str(executionFitTime))\n",
    "print('Execution time in minutes: ' + str(executionFitTime / 60))\n",
    "\n",
    "cv_score_nb = gs_nb.best_score_\n",
    "print('cv_score_lr:', cv_score_nb)\n",
    "\n",
    "cv_results_nb = gs_nb.cv_results_\n",
    "df_nb = pd.DataFrame(cv_results_nb)\n",
    "df_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "76e58b19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__var_smoothing</th>\n",
       "      <th>param_smote__sampling_strategy</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25.151571</td>\n",
       "      <td>0.886764</td>\n",
       "      <td>1.074035</td>\n",
       "      <td>0.066415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'classifier__var_smoothing': 1e-08, 'smote__sampling_strategy': 0.25}</td>\n",
       "      <td>0.534600</td>\n",
       "      <td>0.530286</td>\n",
       "      <td>0.529826</td>\n",
       "      <td>0.526204</td>\n",
       "      <td>0.536987</td>\n",
       "      <td>0.531580</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>1</td>\n",
       "      <td>0.531948</td>\n",
       "      <td>0.534733</td>\n",
       "      <td>0.532732</td>\n",
       "      <td>0.533627</td>\n",
       "      <td>0.534015</td>\n",
       "      <td>0.533411</td>\n",
       "      <td>0.000976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>27.716515</td>\n",
       "      <td>1.361949</td>\n",
       "      <td>1.064037</td>\n",
       "      <td>0.023078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'classifier__var_smoothing': 1e-08, 'smote__sampling_strategy': 0.5}</td>\n",
       "      <td>0.532922</td>\n",
       "      <td>0.530282</td>\n",
       "      <td>0.529120</td>\n",
       "      <td>0.523191</td>\n",
       "      <td>0.536300</td>\n",
       "      <td>0.530363</td>\n",
       "      <td>0.004354</td>\n",
       "      <td>2</td>\n",
       "      <td>0.532842</td>\n",
       "      <td>0.532842</td>\n",
       "      <td>0.532224</td>\n",
       "      <td>0.533881</td>\n",
       "      <td>0.532517</td>\n",
       "      <td>0.532861</td>\n",
       "      <td>0.000560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.377073</td>\n",
       "      <td>0.557480</td>\n",
       "      <td>1.094078</td>\n",
       "      <td>0.037892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'classifier__var_smoothing': 1e-09, 'smote__sampling_strategy': 0.5}</td>\n",
       "      <td>0.531489</td>\n",
       "      <td>0.529800</td>\n",
       "      <td>0.528631</td>\n",
       "      <td>0.522580</td>\n",
       "      <td>0.536396</td>\n",
       "      <td>0.529779</td>\n",
       "      <td>0.004469</td>\n",
       "      <td>3</td>\n",
       "      <td>0.531920</td>\n",
       "      <td>0.531595</td>\n",
       "      <td>0.531728</td>\n",
       "      <td>0.533150</td>\n",
       "      <td>0.531578</td>\n",
       "      <td>0.531994</td>\n",
       "      <td>0.000591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.504206</td>\n",
       "      <td>1.120828</td>\n",
       "      <td>1.110065</td>\n",
       "      <td>0.052439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'classifier__var_smoothing': 1e-09, 'smote__sampling_strategy': 0.25}</td>\n",
       "      <td>0.532245</td>\n",
       "      <td>0.528900</td>\n",
       "      <td>0.527956</td>\n",
       "      <td>0.525329</td>\n",
       "      <td>0.534369</td>\n",
       "      <td>0.529760</td>\n",
       "      <td>0.003195</td>\n",
       "      <td>4</td>\n",
       "      <td>0.530596</td>\n",
       "      <td>0.532697</td>\n",
       "      <td>0.531385</td>\n",
       "      <td>0.531917</td>\n",
       "      <td>0.532067</td>\n",
       "      <td>0.531732</td>\n",
       "      <td>0.000706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.679370</td>\n",
       "      <td>1.557167</td>\n",
       "      <td>1.220369</td>\n",
       "      <td>0.134651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'classifier__var_smoothing': 1e-10, 'smote__sampling_strategy': 0.5}</td>\n",
       "      <td>0.531387</td>\n",
       "      <td>0.528784</td>\n",
       "      <td>0.528729</td>\n",
       "      <td>0.522529</td>\n",
       "      <td>0.536513</td>\n",
       "      <td>0.529588</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>5</td>\n",
       "      <td>0.531283</td>\n",
       "      <td>0.531367</td>\n",
       "      <td>0.530981</td>\n",
       "      <td>0.532109</td>\n",
       "      <td>0.530923</td>\n",
       "      <td>0.531332</td>\n",
       "      <td>0.000424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.542884</td>\n",
       "      <td>1.751076</td>\n",
       "      <td>1.165426</td>\n",
       "      <td>0.223057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'classifier__var_smoothing': 1e-10, 'smote__sampling_strategy': 0.25}</td>\n",
       "      <td>0.529743</td>\n",
       "      <td>0.528115</td>\n",
       "      <td>0.527000</td>\n",
       "      <td>0.523511</td>\n",
       "      <td>0.531563</td>\n",
       "      <td>0.527986</td>\n",
       "      <td>0.002716</td>\n",
       "      <td>6</td>\n",
       "      <td>0.529697</td>\n",
       "      <td>0.531089</td>\n",
       "      <td>0.530544</td>\n",
       "      <td>0.530520</td>\n",
       "      <td>0.530577</td>\n",
       "      <td>0.530486</td>\n",
       "      <td>0.000447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36.281756</td>\n",
       "      <td>0.904808</td>\n",
       "      <td>1.323155</td>\n",
       "      <td>0.120614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>{'classifier__var_smoothing': 1e-08, 'smote__sampling_strategy': 1}</td>\n",
       "      <td>0.528520</td>\n",
       "      <td>0.523125</td>\n",
       "      <td>0.522471</td>\n",
       "      <td>0.522630</td>\n",
       "      <td>0.534938</td>\n",
       "      <td>0.526337</td>\n",
       "      <td>0.004853</td>\n",
       "      <td>7</td>\n",
       "      <td>0.528136</td>\n",
       "      <td>0.528843</td>\n",
       "      <td>0.529121</td>\n",
       "      <td>0.529118</td>\n",
       "      <td>0.527154</td>\n",
       "      <td>0.528475</td>\n",
       "      <td>0.000752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>38.082590</td>\n",
       "      <td>1.065586</td>\n",
       "      <td>1.595274</td>\n",
       "      <td>0.667945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>{'classifier__var_smoothing': 1e-09, 'smote__sampling_strategy': 1}</td>\n",
       "      <td>0.529030</td>\n",
       "      <td>0.522451</td>\n",
       "      <td>0.521644</td>\n",
       "      <td>0.522114</td>\n",
       "      <td>0.534116</td>\n",
       "      <td>0.525871</td>\n",
       "      <td>0.004932</td>\n",
       "      <td>8</td>\n",
       "      <td>0.527429</td>\n",
       "      <td>0.527795</td>\n",
       "      <td>0.528716</td>\n",
       "      <td>0.528655</td>\n",
       "      <td>0.526227</td>\n",
       "      <td>0.527764</td>\n",
       "      <td>0.000914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.783925</td>\n",
       "      <td>4.592491</td>\n",
       "      <td>1.441373</td>\n",
       "      <td>0.073133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>{'classifier__var_smoothing': 1e-10, 'smote__sampling_strategy': 1}</td>\n",
       "      <td>0.527925</td>\n",
       "      <td>0.522573</td>\n",
       "      <td>0.520869</td>\n",
       "      <td>0.521779</td>\n",
       "      <td>0.533168</td>\n",
       "      <td>0.525263</td>\n",
       "      <td>0.004653</td>\n",
       "      <td>9</td>\n",
       "      <td>0.527182</td>\n",
       "      <td>0.527379</td>\n",
       "      <td>0.527799</td>\n",
       "      <td>0.528207</td>\n",
       "      <td>0.525987</td>\n",
       "      <td>0.527311</td>\n",
       "      <td>0.000750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "6      25.151571      0.886764         1.074035        0.066415   \n",
       "7      27.716515      1.361949         1.064037        0.023078   \n",
       "4      27.377073      0.557480         1.094078        0.037892   \n",
       "3      25.504206      1.120828         1.110065        0.052439   \n",
       "1      31.679370      1.557167         1.220369        0.134651   \n",
       "0      29.542884      1.751076         1.165426        0.223057   \n",
       "8      36.281756      0.904808         1.323155        0.120614   \n",
       "5      38.082590      1.065586         1.595274        0.667945   \n",
       "2      44.783925      4.592491         1.441373        0.073133   \n",
       "\n",
       "  param_classifier__var_smoothing param_smote__sampling_strategy  \\\n",
       "6                             0.0                           0.25   \n",
       "7                             0.0                            0.5   \n",
       "4                             0.0                            0.5   \n",
       "3                             0.0                           0.25   \n",
       "1                             0.0                            0.5   \n",
       "0                             0.0                           0.25   \n",
       "8                             0.0                              1   \n",
       "5                             0.0                              1   \n",
       "2                             0.0                              1   \n",
       "\n",
       "                                                                   params  \\\n",
       "6  {'classifier__var_smoothing': 1e-08, 'smote__sampling_strategy': 0.25}   \n",
       "7   {'classifier__var_smoothing': 1e-08, 'smote__sampling_strategy': 0.5}   \n",
       "4   {'classifier__var_smoothing': 1e-09, 'smote__sampling_strategy': 0.5}   \n",
       "3  {'classifier__var_smoothing': 1e-09, 'smote__sampling_strategy': 0.25}   \n",
       "1   {'classifier__var_smoothing': 1e-10, 'smote__sampling_strategy': 0.5}   \n",
       "0  {'classifier__var_smoothing': 1e-10, 'smote__sampling_strategy': 0.25}   \n",
       "8     {'classifier__var_smoothing': 1e-08, 'smote__sampling_strategy': 1}   \n",
       "5     {'classifier__var_smoothing': 1e-09, 'smote__sampling_strategy': 1}   \n",
       "2     {'classifier__var_smoothing': 1e-10, 'smote__sampling_strategy': 1}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "6           0.534600           0.530286           0.529826           0.526204   \n",
       "7           0.532922           0.530282           0.529120           0.523191   \n",
       "4           0.531489           0.529800           0.528631           0.522580   \n",
       "3           0.532245           0.528900           0.527956           0.525329   \n",
       "1           0.531387           0.528784           0.528729           0.522529   \n",
       "0           0.529743           0.528115           0.527000           0.523511   \n",
       "8           0.528520           0.523125           0.522471           0.522630   \n",
       "5           0.529030           0.522451           0.521644           0.522114   \n",
       "2           0.527925           0.522573           0.520869           0.521779   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "6           0.536987         0.531580        0.003795                1   \n",
       "7           0.536300         0.530363        0.004354                2   \n",
       "4           0.536396         0.529779        0.004469                3   \n",
       "3           0.534369         0.529760        0.003195                4   \n",
       "1           0.536513         0.529588        0.004525                5   \n",
       "0           0.531563         0.527986        0.002716                6   \n",
       "8           0.534938         0.526337        0.004853                7   \n",
       "5           0.534116         0.525871        0.004932                8   \n",
       "2           0.533168         0.525263        0.004653                9   \n",
       "\n",
       "   split0_train_score  split1_train_score  split2_train_score  \\\n",
       "6            0.531948            0.534733            0.532732   \n",
       "7            0.532842            0.532842            0.532224   \n",
       "4            0.531920            0.531595            0.531728   \n",
       "3            0.530596            0.532697            0.531385   \n",
       "1            0.531283            0.531367            0.530981   \n",
       "0            0.529697            0.531089            0.530544   \n",
       "8            0.528136            0.528843            0.529121   \n",
       "5            0.527429            0.527795            0.528716   \n",
       "2            0.527182            0.527379            0.527799   \n",
       "\n",
       "   split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "6            0.533627            0.534015          0.533411         0.000976  \n",
       "7            0.533881            0.532517          0.532861         0.000560  \n",
       "4            0.533150            0.531578          0.531994         0.000591  \n",
       "3            0.531917            0.532067          0.531732         0.000706  \n",
       "1            0.532109            0.530923          0.531332         0.000424  \n",
       "0            0.530520            0.530577          0.530486         0.000447  \n",
       "8            0.529118            0.527154          0.528475         0.000752  \n",
       "5            0.528655            0.526227          0.527764         0.000914  \n",
       "2            0.528207            0.525987          0.527311         0.000750  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nb.sort_values(by = 'rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "147eb490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END classifier__var_smoothing=1e-08, smote__sampling_strategy=0.25;, score=(train=0.531, test=0.524) total time=  24.3s\n",
      "[CV 2/5] END classifier__var_smoothing=1e-08, smote__sampling_strategy=0.25;, score=(train=0.533, test=0.521) total time=  21.2s\n",
      "[CV 3/5] END classifier__var_smoothing=1e-08, smote__sampling_strategy=0.25;, score=(train=0.532, test=0.529) total time=  22.4s\n",
      "[CV 4/5] END classifier__var_smoothing=1e-08, smote__sampling_strategy=0.25;, score=(train=0.529, test=0.536) total time=  19.5s\n",
      "[CV 5/5] END classifier__var_smoothing=1e-08, smote__sampling_strategy=0.25;, score=(train=0.532, test=0.532) total time=  20.5s\n",
      "Execution time in seconds: 148.930837392807\n",
      "Execution time in minutes: 2.4821806232134502\n",
      "cv_score_lr: 0.5283880717833875\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__var_smoothing</th>\n",
       "      <th>param_smote__sampling_strategy</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.764703</td>\n",
       "      <td>1.669167</td>\n",
       "      <td>0.905583</td>\n",
       "      <td>0.059361</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'classifier__var_smoothing': 1e-08, 'smote__sampling_strategy': 0.25}</td>\n",
       "      <td>0.523613</td>\n",
       "      <td>0.521067</td>\n",
       "      <td>0.529458</td>\n",
       "      <td>0.535721</td>\n",
       "      <td>0.532082</td>\n",
       "      <td>0.528388</td>\n",
       "      <td>0.005384</td>\n",
       "      <td>1</td>\n",
       "      <td>0.531176</td>\n",
       "      <td>0.532868</td>\n",
       "      <td>0.532418</td>\n",
       "      <td>0.529313</td>\n",
       "      <td>0.531509</td>\n",
       "      <td>0.531457</td>\n",
       "      <td>0.001232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      20.764703      1.669167         0.905583        0.059361   \n",
       "\n",
       "  param_classifier__var_smoothing param_smote__sampling_strategy  \\\n",
       "0                             0.0                           0.25   \n",
       "\n",
       "                                                                   params  \\\n",
       "0  {'classifier__var_smoothing': 1e-08, 'smote__sampling_strategy': 0.25}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.523613           0.521067           0.529458           0.535721   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0           0.532082         0.528388        0.005384                1   \n",
       "\n",
       "   split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0            0.531176            0.532868            0.532418   \n",
       "\n",
       "   split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.529313            0.531509          0.531457         0.001232  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline(steps = [['smote', SMOTE(random_state = 11)],\n",
    "                             ['scaler', StandardScaler()],\n",
    "                             ['classifier', GaussianNB()]])\n",
    "\n",
    "# Define stratifiedKfold\n",
    "stratified_kfold = StratifiedKFold(n_splits = 5,\n",
    "                                   shuffle = True,\n",
    "                                   random_state = 11)\n",
    "\n",
    "param_grid = {'smote__sampling_strategy' : [0.25],\n",
    "              'classifier__var_smoothing' : [1e-8]}\n",
    "\n",
    "gs_nb_split = GridSearchCV(estimator = pipeline,\n",
    "                           param_grid = param_grid,\n",
    "                           scoring = 'roc_auc',\n",
    "                           cv = stratified_kfold,\n",
    "                           verbose = 5,\n",
    "                           return_train_score = True)\n",
    "\n",
    "startFitTime = time.time()\n",
    "gs_nb_split.fit(X_train, y_train)\n",
    "executionFitTime = (time.time() - startFitTime)\n",
    "print('Execution time in seconds: ' + str(executionFitTime))\n",
    "print('Execution time in minutes: ' + str(executionFitTime / 60))\n",
    "\n",
    "cv_score_nb_split = gs_nb_split.best_score_\n",
    "print('cv_score_lr:', cv_score_nb_split)\n",
    "\n",
    "cv_results_nb_split = gs_nb_split.cv_results_\n",
    "df_nb_split = pd.DataFrame(cv_results_nb_split)\n",
    "df_nb_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "14906d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score = 0.5314039317370987\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model with best parameters on X_test\n",
    "y_pred = gs_nb_split.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Calculate and print roc_auc score\n",
    "print('roc_auc_score =', roc_auc_score(y_test, y_pred))\n",
    "print('----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "87a0ec52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report :\n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.18      0.31     56537\n",
      "         1.0       0.09      0.87      0.16      4965\n",
      "\n",
      "    accuracy                           0.24     61502\n",
      "   macro avg       0.51      0.53      0.23     61502\n",
      "weighted avg       0.87      0.24      0.29     61502\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 24.0, 'predicted label'),\n",
       " Text(33.0, 0.5, 'true label'),\n",
       " Text(0.5, 1.0, 'Confusion Matrix test data')]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate model with best parameters on X_test\n",
    "y_pred = gs_nb_split.predict(X_test)\n",
    "\n",
    "# Print classification report with precision, recall and f1-score for each class\n",
    "from sklearn.metrics import classification_report\n",
    "print('classification_report :')\n",
    "print(' ')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print Confusion Matrix on Test data\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "data_cm = pd.DataFrame(conf_mat,\n",
    "                       index = ['can repay', 'can not repay'],\n",
    "                       columns = ['can repay', 'can not repay'])\n",
    "\n",
    "plt.figure(figsize = (6,5))\n",
    "cmap = 'YlOrBr'\n",
    "colormap = sns.heatmap(data_cm, \n",
    "                        annot=True, \n",
    "                        annot_kws ={'size':14}, \n",
    "                        cmap=cmap, \n",
    "                        fmt='.3g')\n",
    "colormap.set_xticklabels(colormap.get_xmajorticklabels(), size = 16)\n",
    "colormap.set_yticklabels(colormap.get_ymajorticklabels(), size = 16)\n",
    "    \n",
    "colormap.set(xlabel = 'predicted label',\n",
    "            ylabel = 'true label',\n",
    "            title = 'Confusion Matrix test data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2c2e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbd4e7dd",
   "metadata": {},
   "source": [
    "### AdaBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed232ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END classifier__learning_rate=1, classifier__n_estimators=100, smote__sampling_strategy=1;, score=(train=0.699, test=0.694) total time=18.3min\n",
      "[CV 2/5] END classifier__learning_rate=1, classifier__n_estimators=100, smote__sampling_strategy=1;, score=(train=0.699, test=0.699) total time=17.8min\n",
      "[CV 3/5] END classifier__learning_rate=1, classifier__n_estimators=100, smote__sampling_strategy=1;, score=(train=0.696, test=0.694) total time=17.7min\n",
      "[CV 4/5] END classifier__learning_rate=1, classifier__n_estimators=100, smote__sampling_strategy=1;, score=(train=0.699, test=0.694) total time=17.7min\n",
      "[CV 5/5] END classifier__learning_rate=1, classifier__n_estimators=100, smote__sampling_strategy=1;, score=(train=0.702, test=0.704) total time=71.1min\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline(steps = [['smote', SMOTE(random_state = 11)],\n",
    "                             ['scaler', StandardScaler()],\n",
    "                             ['classifier', AdaBoostClassifier()]])\n",
    "\n",
    "# Define stratifiedKfold\n",
    "stratified_kfold = StratifiedKFold(n_splits = 5,\n",
    "                                   shuffle = True,\n",
    "                                   random_state = 11)\n",
    "\n",
    "param_grid = {'smote__sampling_strategy': [1],\n",
    "              'classifier__n_estimators': [100],\n",
    "              'classifier__learning_rate': [1]}\n",
    "\n",
    "gs_adaboost = GridSearchCV(estimator = pipeline,\n",
    "                           param_grid = param_grid,\n",
    "                           scoring = 'roc_auc',\n",
    "                           cv = stratified_kfold,\n",
    "                           verbose = 5,\n",
    "                           return_train_score = True)\n",
    "\n",
    "startFitTime = time.time()\n",
    "gs_adaboost.fit(X, y)\n",
    "executionFitTime = (time.time() - startFitTime)\n",
    "print('Execution time in seconds: ' + str(executionFitTime))\n",
    "print('Execution time in minutes: ' + str(executionFitTime / 60))\n",
    "\n",
    "cv_score_adaboost = gs_adaboost.best_score_\n",
    "print('cv_score_adaboost:', cv_score_adaboost)\n",
    "\n",
    "cv_results_adaboost = gs_adaboost.cv_results_\n",
    "df_nb_adaboost = pd.DataFrame(cv_results_adaboost)\n",
    "df_nb_adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43e2a4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560889b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96c6015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8737567",
   "metadata": {},
   "source": [
    "### MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9218436",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline(steps = [['smote', SMOTE(random_state = 11)],\n",
    "                             ['scaler', StandardScaler()],\n",
    "                             ['classifier', MLPClassifier()]])\n",
    "\n",
    "# Define stratifiedKfold\n",
    "stratified_kfold = StratifiedKFold(n_splits = 5,\n",
    "                                   shuffle = True,\n",
    "                                   random_state = 11)\n",
    "\n",
    "param_grid = {'smote__sampling_strategy': [1]}\n",
    "\n",
    "gs_mlpc = GridSearchCV(estimator = pipeline,\n",
    "                           param_grid = param_grid,\n",
    "                           scoring = 'roc_auc',\n",
    "                           cv = stratified_kfold,\n",
    "                           verbose = 5,\n",
    "                           return_train_score = True)\n",
    "\n",
    "startFitTime = time.time()\n",
    "gs_mlpc.fit(X, y)\n",
    "executionFitTime = (time.time() - startFitTime)\n",
    "print('Execution time in seconds: ' + str(executionFitTime))\n",
    "print('Execution time in minutes: ' + str(executionFitTime / 60))\n",
    "\n",
    "cv_score_mlpc = gs_mlpc.best_score_\n",
    "print('cv_score_mlpc:', cv_score_mlpc)\n",
    "\n",
    "cv_results_mlpc = gs_mlpc.cv_results_\n",
    "df_nb_mlpc = pd.DataFrame(cv_results_mlpc)\n",
    "df_nb_mlpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782f6c39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bffd57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5b6301",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "db71c733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation score: 0.7280236282474135\n",
      "best_params: {}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "df_nan40_best_feat_100_train = df_nan40_best_feat_100[df_nan40_best_feat_100['TARGET'].notnull()]\n",
    "\n",
    "X_train = df_nan40_best_feat_100_train.drop(['index', 'SK_ID_CURR', 'TARGET'], axis = 1) \n",
    "y_train = df_nan40_best_feat_100_train['TARGET'].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "mlpc = MLPClassifier()\n",
    "\n",
    "stratified_kfold = StratifiedKFold(n_splits=5,\n",
    "                                   shuffle=True,\n",
    "                                   random_state=11)\n",
    "    \n",
    "param_grid = {}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=mlpc,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='roc_auc',\n",
    "                           cv=stratified_kfold)\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "cv_score = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "print(f'Cross-validation score: {cv_score}')\n",
    "print(f'best_params: {best_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bccad7a",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d669f4a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563cf09b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27016d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8676a70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "76675019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation score: 0.7181763254974084\n",
      "best_params: {}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "df_nan40_best_feat_100_train = df_nan40_best_feat_100[df_nan40_best_feat_100['TARGET'].notnull()]\n",
    "\n",
    "X_train = df_nan40_best_feat_100_train.drop(['index', 'SK_ID_CURR', 'TARGET'], axis = 1) \n",
    "y_train = df_nan40_best_feat_100_train['TARGET'].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "stratified_kfold = StratifiedKFold(n_splits=5,\n",
    "                                   shuffle=True,\n",
    "                                   random_state=11)\n",
    "\n",
    "param_grid = {}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rfc,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='roc_auc',\n",
    "                           cv=stratified_kfold)\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "cv_score = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "print(f'Cross-validation score: {cv_score}')\n",
    "print(f'best_params: {best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5c4f1954",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import RFECV\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a553d168",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nan40_best_feat_100_train = df_nan40_best_feat_100[df_nan40_best_feat_100['TARGET'].notnull()]\n",
    "\n",
    "X_train = df_nan40_best_feat_100_train.drop(['index', 'SK_ID_CURR', 'TARGET'], axis = 1) \n",
    "y_train = df_nan40_best_feat_100_train['TARGET'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "dc806ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Balancing data with synthetic data..\n",
      "\n",
      "Length of synthetic training data: 59979\n",
      "Length of original training data: 307507\n",
      "Length of oversampled training data: 367486\n",
      "Proportion of negative examples in original data: 0.081\n",
      "Proportion of negative examples in oversampled data: 0.23076797483441547\n"
     ]
    }
   ],
   "source": [
    "## Scaling\n",
    "scaler = preprocessing.StandardScaler() \n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "columns = X_train.columns\n",
    "\n",
    "## Over-sampling training data using SMOTE\n",
    "os = SMOTE(sampling_strategy = 0.3, random_state=0)\n",
    "os_X_train, os_y_train = os.fit_resample(X_train_scaled, y_train)\n",
    "X_train_scaled\n",
    "\n",
    "os_data_X = pd.DataFrame(data=os_X_train,columns=columns)\n",
    "os_data_y = pd.DataFrame(data=os_y_train,columns=['y'])\n",
    "\n",
    "# Oversampling report\n",
    "print(\"\\nBalancing data with synthetic data..\")\n",
    "print(\"\\nLength of synthetic training data:\",(len(os_data_X) - len(X_train)))\n",
    "print(\"Length of original training data:\",len(X_train))\n",
    "print(\"Length of oversampled training data:\",len(os_data_X))\n",
    "print(\"Proportion of negative examples in original data:\", round(len(y_train[y_train==1])/len(y_train), 3))\n",
    "print(\"Proportion of negative examples in oversampled data:\",len(os_data_y[os_data_y['y']==1])/len(os_data_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "46adaeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters by cross-validation\n",
    "param_grid = {'C' : [0.05, 0.1, 0.2],\n",
    "              'solver' : ['newton-cg']}\n",
    "\n",
    "## Add different measures for optimisation\n",
    "scores = ['accuracy', 'roc_auc', 'f1', 'recall', 'precision']\n",
    "\n",
    "### Define stratifiedKfold\n",
    "stratified_kfold = StratifiedKFold(n_splits=5,\n",
    "                                   shuffle=True,\n",
    "                                   random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "25d4ba35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning hyper-parameters for accuracy ...\n",
      "\n",
      "GridSearchCV Grid scores on development set (not on test set):\n",
      "\n",
      "0.785 (+/-0.002) for {'C': 0.05, 'solver': 'newton-cg'}\n",
      "0.785 (+/-0.002) for {'C': 0.1, 'solver': 'newton-cg'}\n",
      "0.785 (+/-0.001) for {'C': 0.2, 'solver': 'newton-cg'}\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 0.2, 'solver': 'newton-cg'}\n",
      "Tuning hyper-parameters for roc_auc ...\n",
      "\n",
      "GridSearchCV Grid scores on development set (not on test set):\n",
      "\n",
      "0.769 (+/-0.002) for {'C': 0.05, 'solver': 'newton-cg'}\n",
      "0.769 (+/-0.002) for {'C': 0.1, 'solver': 'newton-cg'}\n",
      "0.769 (+/-0.002) for {'C': 0.2, 'solver': 'newton-cg'}\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 0.2, 'solver': 'newton-cg'}\n",
      "Tuning hyper-parameters for f1 ...\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13692/1912579826.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m                           \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstratified_kfold\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                           scoring = score)\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf_lr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos_data_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos_data_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"GridSearchCV Grid scores on development set (not on test set):\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1392\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    836\u001b[0m                     )\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 838\u001b[1;33m                 out = parallel(\n\u001b[0m\u001b[0;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[0;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1046\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1047\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    678\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1587\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1588\u001b[0m             \u001b[0mprefer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"processes\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1589\u001b[1;33m         fold_coefs_ = Parallel(\n\u001b[0m\u001b[0;32m   1590\u001b[0m             \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1591\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[0;32m    821\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0msolver\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"newton-cg\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m             \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 823\u001b[1;33m             w0, n_iter_i = _newton_cg(\n\u001b[0m\u001b[0;32m    824\u001b[0m                 \u001b[0mhess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py\u001b[0m in \u001b[0;36m_newton_cg\u001b[1;34m(grad_hess, func, grad, x0, args, tol, maxiter, maxinner, line_search, warn)\u001b[0m\n\u001b[0;32m    191\u001b[0m         \u001b[1;31m# Inner loop: solve the Newton update by conjugate gradient, to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;31m# avoid inverting the Hessian\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mxsupi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_cg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfhess_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxinner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtermcond\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[0malphak\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py\u001b[0m in \u001b[0;36m_cg\u001b[1;34m(fhess_p, fgrad, maxiter, tol)\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[0mAp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfhess_p\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpsupi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m         \u001b[1;31m# check curvature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mcurv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpsupi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mHs\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m    235\u001b[0m             \u001b[0mret\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn_features\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn_features\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m             \u001b[0mret\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn_features\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulti_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn_features\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m         \u001b[0mret\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn_features\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn_features\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmulti_dot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36mmulti_dot\u001b[1;34m(arrays, out)\u001b[0m\n\u001b[0;32m   2725\u001b[0m     \u001b[1;31m# _multi_dot_three is much faster than _multi_dot_matrix_chain_order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2726\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2727\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_multi_dot_three\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2728\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2729\u001b[0m         \u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_multi_dot_matrix_chain_order\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36m_multi_dot_three\u001b[1;34m(A, B, C, out)\u001b[0m\n\u001b[0;32m   2757\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2758\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2759\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2760\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Fitting Models\n",
    "\n",
    "for score in scores:\n",
    "    \n",
    "    print(\"Tuning hyper-parameters for %s ...\" % score)\n",
    "    print()\n",
    "    lr = LogisticRegression(random_state=11)\n",
    "    clf_lr = GridSearchCV(lr,\n",
    "                          param_grid, \n",
    "                          cv = stratified_kfold,\n",
    "                          scoring = score)\n",
    "    grid = clf_lr.fit(os_data_X, np.ravel(os_data_y))\n",
    "    print(\"GridSearchCV Grid scores on development set (not on test set):\")\n",
    "    print()\n",
    "    means = grid.cv_results_['mean_test_score']\n",
    "    stds = grid.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, grid.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f18741",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ee77e2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to display all columns and all texts\n",
    "def set_pandas_display_options() -> None:\n",
    "    display = pd.options.display\n",
    "    display.max_columns = 20\n",
    "    display.max_rows = 100\n",
    "    display.max_colwidth = 300\n",
    "    display.width = None\n",
    "set_pandas_display_options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "122ba880",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__C</th>\n",
       "      <th>param_classifier__max_iter</th>\n",
       "      <th>param_classifier__solver</th>\n",
       "      <th>param_smote__sampling_strategy</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>15.886906</td>\n",
       "      <td>0.782118</td>\n",
       "      <td>0.074401</td>\n",
       "      <td>0.009369</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'classifier__C': 0.5, 'classifier__max_iter': 5000, 'classifier__solver': 'lbfgs', 'smote__sampling_strategy': 0.25}</td>\n",
       "      <td>0.744403</td>\n",
       "      <td>0.743811</td>\n",
       "      <td>0.749844</td>\n",
       "      <td>0.744626</td>\n",
       "      <td>0.744637</td>\n",
       "      <td>0.745464</td>\n",
       "      <td>0.002210</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>33.430920</td>\n",
       "      <td>0.932554</td>\n",
       "      <td>0.072407</td>\n",
       "      <td>0.003919</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5000</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'classifier__C': 0.5, 'classifier__max_iter': 5000, 'classifier__solver': 'newton-cg', 'smote__sampling_strategy': 0.25}</td>\n",
       "      <td>0.744405</td>\n",
       "      <td>0.743813</td>\n",
       "      <td>0.749838</td>\n",
       "      <td>0.744625</td>\n",
       "      <td>0.744639</td>\n",
       "      <td>0.745464</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>15.285660</td>\n",
       "      <td>0.322102</td>\n",
       "      <td>0.081986</td>\n",
       "      <td>0.009589</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'classifier__C': 0.2, 'classifier__max_iter': 5000, 'classifier__solver': 'lbfgs', 'smote__sampling_strategy': 0.25}</td>\n",
       "      <td>0.744398</td>\n",
       "      <td>0.743814</td>\n",
       "      <td>0.749834</td>\n",
       "      <td>0.744637</td>\n",
       "      <td>0.744619</td>\n",
       "      <td>0.745460</td>\n",
       "      <td>0.002207</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>28.959747</td>\n",
       "      <td>2.737443</td>\n",
       "      <td>0.073207</td>\n",
       "      <td>0.004829</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5000</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'classifier__C': 0.2, 'classifier__max_iter': 5000, 'classifier__solver': 'newton-cg', 'smote__sampling_strategy': 0.25}</td>\n",
       "      <td>0.744398</td>\n",
       "      <td>0.743813</td>\n",
       "      <td>0.749831</td>\n",
       "      <td>0.744633</td>\n",
       "      <td>0.744619</td>\n",
       "      <td>0.745459</td>\n",
       "      <td>0.002206</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14.814398</td>\n",
       "      <td>0.303162</td>\n",
       "      <td>0.077194</td>\n",
       "      <td>0.010827</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'classifier__C': 0.1, 'classifier__max_iter': 5000, 'classifier__solver': 'lbfgs', 'smote__sampling_strategy': 0.25}</td>\n",
       "      <td>0.744384</td>\n",
       "      <td>0.743808</td>\n",
       "      <td>0.749820</td>\n",
       "      <td>0.744636</td>\n",
       "      <td>0.744595</td>\n",
       "      <td>0.745448</td>\n",
       "      <td>0.002206</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26.038755</td>\n",
       "      <td>2.303059</td>\n",
       "      <td>0.070422</td>\n",
       "      <td>0.003005</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5000</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'classifier__C': 0.1, 'classifier__max_iter': 5000, 'classifier__solver': 'newton-cg', 'smote__sampling_strategy': 0.25}</td>\n",
       "      <td>0.744383</td>\n",
       "      <td>0.743810</td>\n",
       "      <td>0.749817</td>\n",
       "      <td>0.744635</td>\n",
       "      <td>0.744592</td>\n",
       "      <td>0.745448</td>\n",
       "      <td>0.002205</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.260972</td>\n",
       "      <td>0.192017</td>\n",
       "      <td>0.069414</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'classifier__C': 0.05, 'classifier__max_iter': 5000, 'classifier__solver': 'lbfgs', 'smote__sampling_strategy': 0.25}</td>\n",
       "      <td>0.744353</td>\n",
       "      <td>0.743804</td>\n",
       "      <td>0.749791</td>\n",
       "      <td>0.744625</td>\n",
       "      <td>0.744558</td>\n",
       "      <td>0.745426</td>\n",
       "      <td>0.002201</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42.397745</td>\n",
       "      <td>36.477739</td>\n",
       "      <td>0.099733</td>\n",
       "      <td>0.054906</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5000</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'classifier__C': 0.05, 'classifier__max_iter': 5000, 'classifier__solver': 'newton-cg', 'smote__sampling_strategy': 0.25}</td>\n",
       "      <td>0.744355</td>\n",
       "      <td>0.743803</td>\n",
       "      <td>0.749791</td>\n",
       "      <td>0.744623</td>\n",
       "      <td>0.744556</td>\n",
       "      <td>0.745426</td>\n",
       "      <td>0.002201</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>17.774251</td>\n",
       "      <td>0.800099</td>\n",
       "      <td>0.071210</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'classifier__C': 0.5, 'classifier__max_iter': 5000, 'classifier__solver': 'lbfgs', 'smote__sampling_strategy': 0.5}</td>\n",
       "      <td>0.741856</td>\n",
       "      <td>0.740762</td>\n",
       "      <td>0.747003</td>\n",
       "      <td>0.742043</td>\n",
       "      <td>0.741975</td>\n",
       "      <td>0.742728</td>\n",
       "      <td>0.002188</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>38.023408</td>\n",
       "      <td>2.543100</td>\n",
       "      <td>0.073798</td>\n",
       "      <td>0.004850</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5000</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'classifier__C': 0.5, 'classifier__max_iter': 5000, 'classifier__solver': 'newton-cg', 'smote__sampling_strategy': 0.5}</td>\n",
       "      <td>0.741857</td>\n",
       "      <td>0.740767</td>\n",
       "      <td>0.746997</td>\n",
       "      <td>0.742038</td>\n",
       "      <td>0.741979</td>\n",
       "      <td>0.742728</td>\n",
       "      <td>0.002185</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>17.884832</td>\n",
       "      <td>0.950829</td>\n",
       "      <td>0.073809</td>\n",
       "      <td>0.001662</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'classifier__C': 0.2, 'classifier__max_iter': 5000, 'classifier__solver': 'lbfgs', 'smote__sampling_strategy': 0.5}</td>\n",
       "      <td>0.741848</td>\n",
       "      <td>0.740769</td>\n",
       "      <td>0.746998</td>\n",
       "      <td>0.742042</td>\n",
       "      <td>0.741970</td>\n",
       "      <td>0.742725</td>\n",
       "      <td>0.002186</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>33.677562</td>\n",
       "      <td>1.930312</td>\n",
       "      <td>0.071010</td>\n",
       "      <td>0.003420</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5000</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'classifier__C': 0.2, 'classifier__max_iter': 5000, 'classifier__solver': 'newton-cg', 'smote__sampling_strategy': 0.5}</td>\n",
       "      <td>0.741850</td>\n",
       "      <td>0.740770</td>\n",
       "      <td>0.746995</td>\n",
       "      <td>0.742040</td>\n",
       "      <td>0.741969</td>\n",
       "      <td>0.742725</td>\n",
       "      <td>0.002184</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>33.140635</td>\n",
       "      <td>0.953727</td>\n",
       "      <td>0.069210</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5000</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'classifier__C': 0.1, 'classifier__max_iter': 5000, 'classifier__solver': 'newton-cg', 'smote__sampling_strategy': 0.5}</td>\n",
       "      <td>0.741837</td>\n",
       "      <td>0.740771</td>\n",
       "      <td>0.746984</td>\n",
       "      <td>0.742041</td>\n",
       "      <td>0.741954</td>\n",
       "      <td>0.742718</td>\n",
       "      <td>0.002182</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>17.241730</td>\n",
       "      <td>0.576955</td>\n",
       "      <td>0.070617</td>\n",
       "      <td>0.002784</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'classifier__C': 0.1, 'classifier__max_iter': 5000, 'classifier__solver': 'lbfgs', 'smote__sampling_strategy': 0.5}</td>\n",
       "      <td>0.741838</td>\n",
       "      <td>0.740769</td>\n",
       "      <td>0.746985</td>\n",
       "      <td>0.742039</td>\n",
       "      <td>0.741951</td>\n",
       "      <td>0.742717</td>\n",
       "      <td>0.002183</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.587283</td>\n",
       "      <td>1.474915</td>\n",
       "      <td>0.076197</td>\n",
       "      <td>0.007689</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5000</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'classifier__C': 0.05, 'classifier__max_iter': 5000, 'classifier__solver': 'newton-cg', 'smote__sampling_strategy': 0.5}</td>\n",
       "      <td>0.741815</td>\n",
       "      <td>0.740767</td>\n",
       "      <td>0.746962</td>\n",
       "      <td>0.742035</td>\n",
       "      <td>0.741930</td>\n",
       "      <td>0.742702</td>\n",
       "      <td>0.002178</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16.737329</td>\n",
       "      <td>0.621209</td>\n",
       "      <td>0.073211</td>\n",
       "      <td>0.006633</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'classifier__C': 0.05, 'classifier__max_iter': 5000, 'classifier__solver': 'lbfgs', 'smote__sampling_strategy': 0.5}</td>\n",
       "      <td>0.741813</td>\n",
       "      <td>0.740765</td>\n",
       "      <td>0.746966</td>\n",
       "      <td>0.742034</td>\n",
       "      <td>0.741929</td>\n",
       "      <td>0.742702</td>\n",
       "      <td>0.002180</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>43.072069</td>\n",
       "      <td>3.982128</td>\n",
       "      <td>0.069415</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5000</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.75</td>\n",
       "      <td>{'classifier__C': 0.5, 'classifier__max_iter': 5000, 'classifier__solver': 'newton-cg', 'smote__sampling_strategy': 0.75}</td>\n",
       "      <td>0.741156</td>\n",
       "      <td>0.740095</td>\n",
       "      <td>0.746329</td>\n",
       "      <td>0.741447</td>\n",
       "      <td>0.741335</td>\n",
       "      <td>0.742072</td>\n",
       "      <td>0.002182</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>18.848391</td>\n",
       "      <td>0.510331</td>\n",
       "      <td>0.075199</td>\n",
       "      <td>0.007869</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.75</td>\n",
       "      <td>{'classifier__C': 0.5, 'classifier__max_iter': 5000, 'classifier__solver': 'lbfgs', 'smote__sampling_strategy': 0.75}</td>\n",
       "      <td>0.741148</td>\n",
       "      <td>0.740096</td>\n",
       "      <td>0.746330</td>\n",
       "      <td>0.741447</td>\n",
       "      <td>0.741330</td>\n",
       "      <td>0.742070</td>\n",
       "      <td>0.002183</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>43.179517</td>\n",
       "      <td>4.576035</td>\n",
       "      <td>0.073603</td>\n",
       "      <td>0.004737</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5000</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.75</td>\n",
       "      <td>{'classifier__C': 0.2, 'classifier__max_iter': 5000, 'classifier__solver': 'newton-cg', 'smote__sampling_strategy': 0.75}</td>\n",
       "      <td>0.741150</td>\n",
       "      <td>0.740097</td>\n",
       "      <td>0.746327</td>\n",
       "      <td>0.741449</td>\n",
       "      <td>0.741326</td>\n",
       "      <td>0.742070</td>\n",
       "      <td>0.002182</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>19.630454</td>\n",
       "      <td>0.915988</td>\n",
       "      <td>0.073197</td>\n",
       "      <td>0.003192</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.75</td>\n",
       "      <td>{'classifier__C': 0.2, 'classifier__max_iter': 5000, 'classifier__solver': 'lbfgs', 'smote__sampling_strategy': 0.75}</td>\n",
       "      <td>0.741148</td>\n",
       "      <td>0.740092</td>\n",
       "      <td>0.746329</td>\n",
       "      <td>0.741447</td>\n",
       "      <td>0.741325</td>\n",
       "      <td>0.742068</td>\n",
       "      <td>0.002184</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>35.890857</td>\n",
       "      <td>2.272254</td>\n",
       "      <td>0.068817</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5000</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.75</td>\n",
       "      <td>{'classifier__C': 0.1, 'classifier__max_iter': 5000, 'classifier__solver': 'newton-cg', 'smote__sampling_strategy': 0.75}</td>\n",
       "      <td>0.741141</td>\n",
       "      <td>0.740097</td>\n",
       "      <td>0.746319</td>\n",
       "      <td>0.741450</td>\n",
       "      <td>0.741314</td>\n",
       "      <td>0.742064</td>\n",
       "      <td>0.002180</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>19.717735</td>\n",
       "      <td>0.503022</td>\n",
       "      <td>0.069415</td>\n",
       "      <td>0.003491</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.75</td>\n",
       "      <td>{'classifier__C': 0.1, 'classifier__max_iter': 5000, 'classifier__solver': 'lbfgs', 'smote__sampling_strategy': 0.75}</td>\n",
       "      <td>0.741141</td>\n",
       "      <td>0.740096</td>\n",
       "      <td>0.746324</td>\n",
       "      <td>0.741449</td>\n",
       "      <td>0.741309</td>\n",
       "      <td>0.742064</td>\n",
       "      <td>0.002183</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.387997</td>\n",
       "      <td>1.262690</td>\n",
       "      <td>0.070207</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5000</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.75</td>\n",
       "      <td>{'classifier__C': 0.05, 'classifier__max_iter': 5000, 'classifier__solver': 'newton-cg', 'smote__sampling_strategy': 0.75}</td>\n",
       "      <td>0.741124</td>\n",
       "      <td>0.740090</td>\n",
       "      <td>0.746304</td>\n",
       "      <td>0.741445</td>\n",
       "      <td>0.741293</td>\n",
       "      <td>0.742051</td>\n",
       "      <td>0.002179</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18.719536</td>\n",
       "      <td>0.649772</td>\n",
       "      <td>0.070610</td>\n",
       "      <td>0.002311</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.75</td>\n",
       "      <td>{'classifier__C': 0.05, 'classifier__max_iter': 5000, 'classifier__solver': 'lbfgs', 'smote__sampling_strategy': 0.75}</td>\n",
       "      <td>0.741124</td>\n",
       "      <td>0.740087</td>\n",
       "      <td>0.746305</td>\n",
       "      <td>0.741445</td>\n",
       "      <td>0.741293</td>\n",
       "      <td>0.742051</td>\n",
       "      <td>0.002180</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>21.530459</td>\n",
       "      <td>1.234893</td>\n",
       "      <td>0.070417</td>\n",
       "      <td>0.003599</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>1</td>\n",
       "      <td>{'classifier__C': 0.5, 'classifier__max_iter': 5000, 'classifier__solver': 'lbfgs', 'smote__sampling_strategy': 1}</td>\n",
       "      <td>0.741021</td>\n",
       "      <td>0.739876</td>\n",
       "      <td>0.745944</td>\n",
       "      <td>0.741180</td>\n",
       "      <td>0.741288</td>\n",
       "      <td>0.741862</td>\n",
       "      <td>0.002103</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>46.813627</td>\n",
       "      <td>4.182875</td>\n",
       "      <td>0.072394</td>\n",
       "      <td>0.003754</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5000</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>1</td>\n",
       "      <td>{'classifier__C': 0.5, 'classifier__max_iter': 5000, 'classifier__solver': 'newton-cg', 'smote__sampling_strategy': 1}</td>\n",
       "      <td>0.741020</td>\n",
       "      <td>0.739872</td>\n",
       "      <td>0.745930</td>\n",
       "      <td>0.741177</td>\n",
       "      <td>0.741290</td>\n",
       "      <td>0.741858</td>\n",
       "      <td>0.002098</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>44.881649</td>\n",
       "      <td>1.360649</td>\n",
       "      <td>0.071216</td>\n",
       "      <td>0.001356</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5000</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>1</td>\n",
       "      <td>{'classifier__C': 0.2, 'classifier__max_iter': 5000, 'classifier__solver': 'newton-cg', 'smote__sampling_strategy': 1}</td>\n",
       "      <td>0.741015</td>\n",
       "      <td>0.739873</td>\n",
       "      <td>0.745932</td>\n",
       "      <td>0.741178</td>\n",
       "      <td>0.741283</td>\n",
       "      <td>0.741856</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>21.012825</td>\n",
       "      <td>0.606392</td>\n",
       "      <td>0.078391</td>\n",
       "      <td>0.010528</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>1</td>\n",
       "      <td>{'classifier__C': 0.2, 'classifier__max_iter': 5000, 'classifier__solver': 'lbfgs', 'smote__sampling_strategy': 1}</td>\n",
       "      <td>0.741013</td>\n",
       "      <td>0.739871</td>\n",
       "      <td>0.745934</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.741284</td>\n",
       "      <td>0.741856</td>\n",
       "      <td>0.002101</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>21.207332</td>\n",
       "      <td>0.811527</td>\n",
       "      <td>0.075199</td>\n",
       "      <td>0.006327</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>1</td>\n",
       "      <td>{'classifier__C': 0.1, 'classifier__max_iter': 5000, 'classifier__solver': 'lbfgs', 'smote__sampling_strategy': 1}</td>\n",
       "      <td>0.741005</td>\n",
       "      <td>0.739874</td>\n",
       "      <td>0.745934</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.741272</td>\n",
       "      <td>0.741852</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>44.350226</td>\n",
       "      <td>2.772670</td>\n",
       "      <td>0.073386</td>\n",
       "      <td>0.006272</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5000</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>1</td>\n",
       "      <td>{'classifier__C': 0.1, 'classifier__max_iter': 5000, 'classifier__solver': 'newton-cg', 'smote__sampling_strategy': 1}</td>\n",
       "      <td>0.741008</td>\n",
       "      <td>0.739872</td>\n",
       "      <td>0.745928</td>\n",
       "      <td>0.741178</td>\n",
       "      <td>0.741273</td>\n",
       "      <td>0.741852</td>\n",
       "      <td>0.002099</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.354693</td>\n",
       "      <td>2.048348</td>\n",
       "      <td>0.072607</td>\n",
       "      <td>0.003954</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5000</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>1</td>\n",
       "      <td>{'classifier__C': 0.05, 'classifier__max_iter': 5000, 'classifier__solver': 'newton-cg', 'smote__sampling_strategy': 1}</td>\n",
       "      <td>0.740991</td>\n",
       "      <td>0.739871</td>\n",
       "      <td>0.745916</td>\n",
       "      <td>0.741175</td>\n",
       "      <td>0.741256</td>\n",
       "      <td>0.741842</td>\n",
       "      <td>0.002097</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20.536514</td>\n",
       "      <td>0.736381</td>\n",
       "      <td>0.074006</td>\n",
       "      <td>0.008860</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>1</td>\n",
       "      <td>{'classifier__C': 0.05, 'classifier__max_iter': 5000, 'classifier__solver': 'lbfgs', 'smote__sampling_strategy': 1}</td>\n",
       "      <td>0.740992</td>\n",
       "      <td>0.739872</td>\n",
       "      <td>0.745915</td>\n",
       "      <td>0.741172</td>\n",
       "      <td>0.741255</td>\n",
       "      <td>0.741841</td>\n",
       "      <td>0.002097</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "28      15.886906      0.782118         0.074401        0.009369   \n",
       "24      33.430920      0.932554         0.072407        0.003919   \n",
       "20      15.285660      0.322102         0.081986        0.009589   \n",
       "16      28.959747      2.737443         0.073207        0.004829   \n",
       "12      14.814398      0.303162         0.077194        0.010827   \n",
       "8       26.038755      2.303059         0.070422        0.003005   \n",
       "4       14.260972      0.192017         0.069414        0.003867   \n",
       "0       42.397745     36.477739         0.099733        0.054906   \n",
       "29      17.774251      0.800099         0.071210        0.003868   \n",
       "25      38.023408      2.543100         0.073798        0.004850   \n",
       "21      17.884832      0.950829         0.073809        0.001662   \n",
       "17      33.677562      1.930312         0.071010        0.003420   \n",
       "9       33.140635      0.953727         0.069210        0.000482   \n",
       "13      17.241730      0.576955         0.070617        0.002784   \n",
       "1       28.587283      1.474915         0.076197        0.007689   \n",
       "5       16.737329      0.621209         0.073211        0.006633   \n",
       "26      43.072069      3.982128         0.069415        0.001353   \n",
       "30      18.848391      0.510331         0.075199        0.007869   \n",
       "18      43.179517      4.576035         0.073603        0.004737   \n",
       "22      19.630454      0.915988         0.073197        0.003192   \n",
       "10      35.890857      2.272254         0.068817        0.000892   \n",
       "14      19.717735      0.503022         0.069415        0.003491   \n",
       "2       34.387997      1.262690         0.070207        0.002412   \n",
       "6       18.719536      0.649772         0.070610        0.002311   \n",
       "31      21.530459      1.234893         0.070417        0.003599   \n",
       "27      46.813627      4.182875         0.072394        0.003754   \n",
       "19      44.881649      1.360649         0.071216        0.001356   \n",
       "23      21.012825      0.606392         0.078391        0.010528   \n",
       "15      21.207332      0.811527         0.075199        0.006327   \n",
       "11      44.350226      2.772670         0.073386        0.006272   \n",
       "3       39.354693      2.048348         0.072607        0.003954   \n",
       "7       20.536514      0.736381         0.074006        0.008860   \n",
       "\n",
       "   param_classifier__C param_classifier__max_iter param_classifier__solver  \\\n",
       "28                 0.5                       5000                    lbfgs   \n",
       "24                 0.5                       5000                newton-cg   \n",
       "20                 0.2                       5000                    lbfgs   \n",
       "16                 0.2                       5000                newton-cg   \n",
       "12                 0.1                       5000                    lbfgs   \n",
       "8                  0.1                       5000                newton-cg   \n",
       "4                 0.05                       5000                    lbfgs   \n",
       "0                 0.05                       5000                newton-cg   \n",
       "29                 0.5                       5000                    lbfgs   \n",
       "25                 0.5                       5000                newton-cg   \n",
       "21                 0.2                       5000                    lbfgs   \n",
       "17                 0.2                       5000                newton-cg   \n",
       "9                  0.1                       5000                newton-cg   \n",
       "13                 0.1                       5000                    lbfgs   \n",
       "1                 0.05                       5000                newton-cg   \n",
       "5                 0.05                       5000                    lbfgs   \n",
       "26                 0.5                       5000                newton-cg   \n",
       "30                 0.5                       5000                    lbfgs   \n",
       "18                 0.2                       5000                newton-cg   \n",
       "22                 0.2                       5000                    lbfgs   \n",
       "10                 0.1                       5000                newton-cg   \n",
       "14                 0.1                       5000                    lbfgs   \n",
       "2                 0.05                       5000                newton-cg   \n",
       "6                 0.05                       5000                    lbfgs   \n",
       "31                 0.5                       5000                    lbfgs   \n",
       "27                 0.5                       5000                newton-cg   \n",
       "19                 0.2                       5000                newton-cg   \n",
       "23                 0.2                       5000                    lbfgs   \n",
       "15                 0.1                       5000                    lbfgs   \n",
       "11                 0.1                       5000                newton-cg   \n",
       "3                 0.05                       5000                newton-cg   \n",
       "7                 0.05                       5000                    lbfgs   \n",
       "\n",
       "   param_smote__sampling_strategy  \\\n",
       "28                           0.25   \n",
       "24                           0.25   \n",
       "20                           0.25   \n",
       "16                           0.25   \n",
       "12                           0.25   \n",
       "8                            0.25   \n",
       "4                            0.25   \n",
       "0                            0.25   \n",
       "29                            0.5   \n",
       "25                            0.5   \n",
       "21                            0.5   \n",
       "17                            0.5   \n",
       "9                             0.5   \n",
       "13                            0.5   \n",
       "1                             0.5   \n",
       "5                             0.5   \n",
       "26                           0.75   \n",
       "30                           0.75   \n",
       "18                           0.75   \n",
       "22                           0.75   \n",
       "10                           0.75   \n",
       "14                           0.75   \n",
       "2                            0.75   \n",
       "6                            0.75   \n",
       "31                              1   \n",
       "27                              1   \n",
       "19                              1   \n",
       "23                              1   \n",
       "15                              1   \n",
       "11                              1   \n",
       "3                               1   \n",
       "7                               1   \n",
       "\n",
       "                                                                                                                        params  \\\n",
       "28       {'classifier__C': 0.5, 'classifier__max_iter': 5000, 'classifier__solver': 'lbfgs', 'smote__sampling_strategy': 0.25}   \n",
       "24   {'classifier__C': 0.5, 'classifier__max_iter': 5000, 'classifier__solver': 'newton-cg', 'smote__sampling_strategy': 0.25}   \n",
       "20       {'classifier__C': 0.2, 'classifier__max_iter': 5000, 'classifier__solver': 'lbfgs', 'smote__sampling_strategy': 0.25}   \n",
       "16   {'classifier__C': 0.2, 'classifier__max_iter': 5000, 'classifier__solver': 'newton-cg', 'smote__sampling_strategy': 0.25}   \n",
       "12       {'classifier__C': 0.1, 'classifier__max_iter': 5000, 'classifier__solver': 'lbfgs', 'smote__sampling_strategy': 0.25}   \n",
       "8    {'classifier__C': 0.1, 'classifier__max_iter': 5000, 'classifier__solver': 'newton-cg', 'smote__sampling_strategy': 0.25}   \n",
       "4       {'classifier__C': 0.05, 'classifier__max_iter': 5000, 'classifier__solver': 'lbfgs', 'smote__sampling_strategy': 0.25}   \n",
       "0   {'classifier__C': 0.05, 'classifier__max_iter': 5000, 'classifier__solver': 'newton-cg', 'smote__sampling_strategy': 0.25}   \n",
       "29        {'classifier__C': 0.5, 'classifier__max_iter': 5000, 'classifier__solver': 'lbfgs', 'smote__sampling_strategy': 0.5}   \n",
       "25    {'classifier__C': 0.5, 'classifier__max_iter': 5000, 'classifier__solver': 'newton-cg', 'smote__sampling_strategy': 0.5}   \n",
       "21        {'classifier__C': 0.2, 'classifier__max_iter': 5000, 'classifier__solver': 'lbfgs', 'smote__sampling_strategy': 0.5}   \n",
       "17    {'classifier__C': 0.2, 'classifier__max_iter': 5000, 'classifier__solver': 'newton-cg', 'smote__sampling_strategy': 0.5}   \n",
       "9     {'classifier__C': 0.1, 'classifier__max_iter': 5000, 'classifier__solver': 'newton-cg', 'smote__sampling_strategy': 0.5}   \n",
       "13        {'classifier__C': 0.1, 'classifier__max_iter': 5000, 'classifier__solver': 'lbfgs', 'smote__sampling_strategy': 0.5}   \n",
       "1    {'classifier__C': 0.05, 'classifier__max_iter': 5000, 'classifier__solver': 'newton-cg', 'smote__sampling_strategy': 0.5}   \n",
       "5        {'classifier__C': 0.05, 'classifier__max_iter': 5000, 'classifier__solver': 'lbfgs', 'smote__sampling_strategy': 0.5}   \n",
       "26   {'classifier__C': 0.5, 'classifier__max_iter': 5000, 'classifier__solver': 'newton-cg', 'smote__sampling_strategy': 0.75}   \n",
       "30       {'classifier__C': 0.5, 'classifier__max_iter': 5000, 'classifier__solver': 'lbfgs', 'smote__sampling_strategy': 0.75}   \n",
       "18   {'classifier__C': 0.2, 'classifier__max_iter': 5000, 'classifier__solver': 'newton-cg', 'smote__sampling_strategy': 0.75}   \n",
       "22       {'classifier__C': 0.2, 'classifier__max_iter': 5000, 'classifier__solver': 'lbfgs', 'smote__sampling_strategy': 0.75}   \n",
       "10   {'classifier__C': 0.1, 'classifier__max_iter': 5000, 'classifier__solver': 'newton-cg', 'smote__sampling_strategy': 0.75}   \n",
       "14       {'classifier__C': 0.1, 'classifier__max_iter': 5000, 'classifier__solver': 'lbfgs', 'smote__sampling_strategy': 0.75}   \n",
       "2   {'classifier__C': 0.05, 'classifier__max_iter': 5000, 'classifier__solver': 'newton-cg', 'smote__sampling_strategy': 0.75}   \n",
       "6       {'classifier__C': 0.05, 'classifier__max_iter': 5000, 'classifier__solver': 'lbfgs', 'smote__sampling_strategy': 0.75}   \n",
       "31          {'classifier__C': 0.5, 'classifier__max_iter': 5000, 'classifier__solver': 'lbfgs', 'smote__sampling_strategy': 1}   \n",
       "27      {'classifier__C': 0.5, 'classifier__max_iter': 5000, 'classifier__solver': 'newton-cg', 'smote__sampling_strategy': 1}   \n",
       "19      {'classifier__C': 0.2, 'classifier__max_iter': 5000, 'classifier__solver': 'newton-cg', 'smote__sampling_strategy': 1}   \n",
       "23          {'classifier__C': 0.2, 'classifier__max_iter': 5000, 'classifier__solver': 'lbfgs', 'smote__sampling_strategy': 1}   \n",
       "15          {'classifier__C': 0.1, 'classifier__max_iter': 5000, 'classifier__solver': 'lbfgs', 'smote__sampling_strategy': 1}   \n",
       "11      {'classifier__C': 0.1, 'classifier__max_iter': 5000, 'classifier__solver': 'newton-cg', 'smote__sampling_strategy': 1}   \n",
       "3      {'classifier__C': 0.05, 'classifier__max_iter': 5000, 'classifier__solver': 'newton-cg', 'smote__sampling_strategy': 1}   \n",
       "7          {'classifier__C': 0.05, 'classifier__max_iter': 5000, 'classifier__solver': 'lbfgs', 'smote__sampling_strategy': 1}   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "28           0.744403           0.743811           0.749844   \n",
       "24           0.744405           0.743813           0.749838   \n",
       "20           0.744398           0.743814           0.749834   \n",
       "16           0.744398           0.743813           0.749831   \n",
       "12           0.744384           0.743808           0.749820   \n",
       "8            0.744383           0.743810           0.749817   \n",
       "4            0.744353           0.743804           0.749791   \n",
       "0            0.744355           0.743803           0.749791   \n",
       "29           0.741856           0.740762           0.747003   \n",
       "25           0.741857           0.740767           0.746997   \n",
       "21           0.741848           0.740769           0.746998   \n",
       "17           0.741850           0.740770           0.746995   \n",
       "9            0.741837           0.740771           0.746984   \n",
       "13           0.741838           0.740769           0.746985   \n",
       "1            0.741815           0.740767           0.746962   \n",
       "5            0.741813           0.740765           0.746966   \n",
       "26           0.741156           0.740095           0.746329   \n",
       "30           0.741148           0.740096           0.746330   \n",
       "18           0.741150           0.740097           0.746327   \n",
       "22           0.741148           0.740092           0.746329   \n",
       "10           0.741141           0.740097           0.746319   \n",
       "14           0.741141           0.740096           0.746324   \n",
       "2            0.741124           0.740090           0.746304   \n",
       "6            0.741124           0.740087           0.746305   \n",
       "31           0.741021           0.739876           0.745944   \n",
       "27           0.741020           0.739872           0.745930   \n",
       "19           0.741015           0.739873           0.745932   \n",
       "23           0.741013           0.739871           0.745934   \n",
       "15           0.741005           0.739874           0.745934   \n",
       "11           0.741008           0.739872           0.745928   \n",
       "3            0.740991           0.739871           0.745916   \n",
       "7            0.740992           0.739872           0.745915   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "28           0.744626           0.744637         0.745464        0.002210   \n",
       "24           0.744625           0.744639         0.745464        0.002208   \n",
       "20           0.744637           0.744619         0.745460        0.002207   \n",
       "16           0.744633           0.744619         0.745459        0.002206   \n",
       "12           0.744636           0.744595         0.745448        0.002206   \n",
       "8            0.744635           0.744592         0.745448        0.002205   \n",
       "4            0.744625           0.744558         0.745426        0.002201   \n",
       "0            0.744623           0.744556         0.745426        0.002201   \n",
       "29           0.742043           0.741975         0.742728        0.002188   \n",
       "25           0.742038           0.741979         0.742728        0.002185   \n",
       "21           0.742042           0.741970         0.742725        0.002186   \n",
       "17           0.742040           0.741969         0.742725        0.002184   \n",
       "9            0.742041           0.741954         0.742718        0.002182   \n",
       "13           0.742039           0.741951         0.742717        0.002183   \n",
       "1            0.742035           0.741930         0.742702        0.002178   \n",
       "5            0.742034           0.741929         0.742702        0.002180   \n",
       "26           0.741447           0.741335         0.742072        0.002182   \n",
       "30           0.741447           0.741330         0.742070        0.002183   \n",
       "18           0.741449           0.741326         0.742070        0.002182   \n",
       "22           0.741447           0.741325         0.742068        0.002184   \n",
       "10           0.741450           0.741314         0.742064        0.002180   \n",
       "14           0.741449           0.741309         0.742064        0.002183   \n",
       "2            0.741445           0.741293         0.742051        0.002179   \n",
       "6            0.741445           0.741293         0.742051        0.002180   \n",
       "31           0.741180           0.741288         0.741862        0.002103   \n",
       "27           0.741177           0.741290         0.741858        0.002098   \n",
       "19           0.741178           0.741283         0.741856        0.002100   \n",
       "23           0.741176           0.741284         0.741856        0.002101   \n",
       "15           0.741176           0.741272         0.741852        0.002102   \n",
       "11           0.741178           0.741273         0.741852        0.002099   \n",
       "3            0.741175           0.741256         0.741842        0.002097   \n",
       "7            0.741172           0.741255         0.741841        0.002097   \n",
       "\n",
       "    rank_test_score  \n",
       "28                1  \n",
       "24                2  \n",
       "20                3  \n",
       "16                4  \n",
       "12                5  \n",
       "8                 6  \n",
       "4                 7  \n",
       "0                 8  \n",
       "29                9  \n",
       "25               10  \n",
       "21               11  \n",
       "17               12  \n",
       "9                13  \n",
       "13               14  \n",
       "1                15  \n",
       "5                16  \n",
       "26               17  \n",
       "30               18  \n",
       "18               19  \n",
       "22               20  \n",
       "10               21  \n",
       "14               22  \n",
       "2                23  \n",
       "6                24  \n",
       "31               25  \n",
       "27               26  \n",
       "19               27  \n",
       "23               28  \n",
       "15               29  \n",
       "11               30  \n",
       "3                31  \n",
       "7                32  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by = 'rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b175734c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define true positives, false positives, false negatives and true negatives\n",
    "TP = conf_mat[0][0]\n",
    "FP = conf_mat[0][1]\n",
    "FN = conf_mat[1][0]\n",
    "TN = conf_mat[1][1]\n",
    "\n",
    "# Define business cost function\n",
    "cost = 10 * FN + FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd91be7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "48151fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0.0: 282682, 1.0: 24825})\n",
      "Execution time in seconds: 11.922111749649048\n",
      "Execution time in minutes: 0.1987018624941508\n",
      "Resampled dataset shape Counter({0.0: 282682, 1.0: 70670})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_train = df_nan40_best_feat_100_train.drop(['index', 'SK_ID_CURR', 'TARGET'], axis = 1) \n",
    "y_train = df_nan40_best_feat_100_train['TARGET'].values\n",
    "                        \n",
    "print('Original dataset shape %s' % Counter(y_train))\n",
    "\n",
    "sm = SMOTE(sampling_strategy = 0.25,\n",
    "            random_state=42)\n",
    "\n",
    "startFitTime = time.time()\n",
    "\n",
    "X_res, y_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "executionFitTime = (time.time() - startFitTime)\n",
    "print('Execution time in seconds: ' + str(executionFitTime))\n",
    "print('Execution time in minutes: ' + str(executionFitTime / 60))\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1387045c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0.0: 282682, 1.0: 24825})\n",
      "Execution time in seconds: 142.3265814781189\n",
      "Execution time in minutes: 2.3721096913019815\n",
      "Resampled dataset shape Counter({0.0: 282682, 1.0: 71946})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "X_train = df_nan40_best_feat_100_train.drop(['index', 'SK_ID_CURR', 'TARGET'], axis = 1) \n",
    "y_train = df_nan40_best_feat_100_train['TARGET'].values\n",
    "                        \n",
    "print('Original dataset shape %s' % Counter(y_train))\n",
    "\n",
    "adasyn = ADASYN(sampling_strategy = 0.25,\n",
    "                random_state=42)\n",
    "\n",
    "startFitTime = time.time()\n",
    "\n",
    "X_res, y_res = adasyn.fit_resample(X_train, y_train)\n",
    "\n",
    "executionFitTime = (time.time() - startFitTime)\n",
    "print('Execution time in seconds: ' + str(executionFitTime))\n",
    "print('Execution time in minutes: ' + str(executionFitTime / 60))\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "be2528e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0.0: 282682, 1.0: 24825})\n",
      "Execution time in seconds: 138.6216516494751\n",
      "Execution time in minutes: 2.310360860824585\n",
      "Resampled dataset shape Counter({0.0: 282682, 1.0: 70670})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "X_train = df_nan40_best_feat_100_train.drop(['index', 'SK_ID_CURR', 'TARGET'], axis = 1) \n",
    "y_train = df_nan40_best_feat_100_train['TARGET'].values\n",
    "                        \n",
    "print('Original dataset shape %s' % Counter(y_train))\n",
    "\n",
    "bordersm = BorderlineSMOTE(sampling_strategy = 0.25,\n",
    "                           random_state=42)\n",
    "\n",
    "startFitTime = time.time()\n",
    "\n",
    "X_res, y_res = bordersm.fit_resample(X_train, y_train)\n",
    "\n",
    "executionFitTime = (time.time() - startFitTime)\n",
    "print('Execution time in seconds: ' + str(executionFitTime))\n",
    "print('Execution time in minutes: ' + str(executionFitTime / 60))\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1b9cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0.0: 282682, 1.0: 24825})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "\n",
    "X_train = df_nan40_best_feat_100_train.drop(['index', 'SK_ID_CURR', 'TARGET'], axis = 1) \n",
    "y_train = df_nan40_best_feat_100_train['TARGET'].values\n",
    "                        \n",
    "print('Original dataset shape %s' % Counter(y_train))\n",
    "\n",
    "svmsm = SVMSMOTE(sampling_strategy = 0.25,\n",
    "                 random_state=42)\n",
    "\n",
    "startFitTime = time.time()\n",
    "\n",
    "X_res, y_res = svmsm.fit_resample(X_train, y_train)\n",
    "\n",
    "executionFitTime = (time.time() - startFitTime)\n",
    "print('Execution time in seconds: ' + str(executionFitTime))\n",
    "print('Execution time in minutes: ' + str(executionFitTime / 60))\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "cb39ba2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0.0: 282682, 1.0: 24825})\n",
      "Resampled dataset shape Counter({0.0: 199815, 1.0: 44558})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from imblearn.combine import SMOTEENN \n",
    "\n",
    "X_train = df_nan40_best_feat_100_train.drop(['index', 'SK_ID_CURR', 'TARGET'], axis = 1) \n",
    "y_train = df_nan40_best_feat_100_train['TARGET'].values\n",
    "                        \n",
    "print('Original dataset shape %s' % Counter(y_train))\n",
    "\n",
    "sme = SMOTEENN(sampling_strategy = 0.25, \n",
    "               random_state=42)\n",
    "\n",
    "startFitTime = time.time()\n",
    "\n",
    "X_res, y_res = sme.fit_resample(X_train, y_train)\n",
    "\n",
    "executionFitTime = (time.time() - startFitTime)\n",
    "print('Execution time in seconds: ' + str(executionFitTime))\n",
    "print('Execution time in minutes: ' + str(executionFitTime / 60))\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "319e115d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0.0: 282682, 1.0: 24825})\n",
      "Execution time in seconds: 1511.8728518486023\n",
      "Execution time in minutes: 25.19788086414337\n",
      "Resampled dataset shape Counter({0.0: 280748, 1.0: 68736})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.combine import SMOTETomek \n",
    "\n",
    "X_train = df_nan40_best_feat_100_train.drop(['index', 'SK_ID_CURR', 'TARGET'], axis = 1) \n",
    "y_train = df_nan40_best_feat_100_train['TARGET'].values\n",
    "                        \n",
    "print('Original dataset shape %s' % Counter(y_train))\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy = 0.25, \n",
    "                 random_state=42)\n",
    "\n",
    "startFitTime = time.time()\n",
    "\n",
    "X_res, y_res = smt.fit_resample(X_train, y_train)\n",
    "\n",
    "executionFitTime = (time.time() - startFitTime)\n",
    "print('Execution time in seconds: ' + str(executionFitTime))\n",
    "print('Execution time in minutes: ' + str(executionFitTime / 60))\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0622007c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3c79ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8eb13f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f1feb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "df_nan40_best_feat_100_train = df_nan40_best_feat_100[df_nan40_best_feat_100['TARGET'].notnull()]\n",
    "\n",
    "X_train = df_nan40_best_feat_100_train.drop(['index', 'SK_ID_CURR', 'TARGET'], axis = 1) \n",
    "y_train = df_nan40_best_feat_100_train['TARGET'].values\n",
    "\n",
    "pipeline = Pipeline(steps = [['smote', SMOTEENN(random_state = 11)],\n",
    "                             ['scaler', StandardScaler()],\n",
    "                             ['classifier', LogisticRegression()]])\n",
    "\n",
    "# Define stratifiedKfold\n",
    "stratified_kfold = StratifiedKFold(n_splits = 5,\n",
    "                                   shuffle = True,\n",
    "                                   random_state = 11)\n",
    "\n",
    "param_grid = {'smote__sampling_strategy' : [0.25, 0.5, 0.75, 1],\n",
    "              'classifier__C' : [0.05, 0.1, 0.2, 0.5],\n",
    "              'classifier__solver' : ['newton-cg', 'lbfgs'],\n",
    "              'classifier__max_iter' : [5000]}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = pipeline,\n",
    "                           param_grid = param_grid,\n",
    "                           scoring = 'roc_auc',\n",
    "                           cv = stratified_kfold,\n",
    "                           verbose = 5,\n",
    "                           return_train_score = True)\n",
    "\n",
    "startFitTime = time.time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "executionFitTime = (time.time() - startFitTime)\n",
    "print('Execution time in seconds: ' + str(executionFitTime))\n",
    "print('Execution time in minutes: ' + str(executionFitTime / 60))\n",
    "\n",
    "cv_score = grid_search.best_score_\n",
    "print('cv_score:', cv_score)\n",
    "\n",
    "cv_results = grid_search.cv_results_\n",
    "df = pd.DataFrame(cv_results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d72bc81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f28bced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import collections\n",
    "\n",
    "# Train_test_split 80/20 with stratify\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size = 0.2,\n",
    "                                                    stratify = y,\n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f19b9aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61502,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b5c3c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(246005, 551)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c54699d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(246005,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "50514a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END classifier__n_estimators=500;, score=(train=0.953, test=0.769) total time=  38.4s\n",
      "[CV 2/5] END classifier__n_estimators=500;, score=(train=0.953, test=0.766) total time=  28.5s\n",
      "[CV 3/5] END classifier__n_estimators=500;, score=(train=0.952, test=0.774) total time=  27.2s\n",
      "[CV 4/5] END classifier__n_estimators=500;, score=(train=0.952, test=0.774) total time=  25.7s\n",
      "[CV 5/5] END classifier__n_estimators=500;, score=(train=0.953, test=0.778) total time=  29.3s\n",
      "Execution time in seconds: 191.91669178009033\n",
      "Execution time in minutes: 3.198611529668172\n",
      "cv_score_lgbm: 0.7721773444868685\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.243915</td>\n",
       "      <td>4.437362</td>\n",
       "      <td>0.66401</td>\n",
       "      <td>0.052731</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__n_estimators': 500}</td>\n",
       "      <td>0.768811</td>\n",
       "      <td>0.76631</td>\n",
       "      <td>0.774174</td>\n",
       "      <td>0.773998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.772177</td>\n",
       "      <td>0.004059</td>\n",
       "      <td>1</td>\n",
       "      <td>0.952606</td>\n",
       "      <td>0.952678</td>\n",
       "      <td>0.951739</td>\n",
       "      <td>0.951729</td>\n",
       "      <td>0.953244</td>\n",
       "      <td>0.952399</td>\n",
       "      <td>0.000587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      29.243915      4.437362          0.66401        0.052731   \n",
       "\n",
       "  param_classifier__n_estimators                             params  \\\n",
       "0                            500  {'classifier__n_estimators': 500}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.768811            0.76631           0.774174           0.773998   \n",
       "\n",
       "   ...  mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0  ...         0.772177        0.004059                1            0.952606   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0            0.952678            0.951739            0.951729   \n",
       "\n",
       "   split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.953244          0.952399         0.000587  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create pipeline (imbpipeline) with smote, scaler and classifier steps\n",
    "# imbpipeline automatically skip the sampling method (smote) when predict is called\n",
    "# -> Consequently, there is no data leakage\n",
    "pipeline = Pipeline(steps = [['classifier', LGBMClassifier(random_state = 11)]])\n",
    "\n",
    "# Define stratifiedKfold\n",
    "stratified_kfold = StratifiedKFold(n_splits = 5,\n",
    "                                   shuffle = True,\n",
    "                                   random_state = 11)\n",
    "\n",
    "# Define param_grid for GridSearchCV\n",
    "param_grid = {'classifier__n_estimators' : [500]}\n",
    "\n",
    "# Create GridSearchCV model\n",
    "gs_lgbm = GridSearchCV(estimator = pipeline,\n",
    "                       param_grid = param_grid,\n",
    "                       scoring = 'roc_auc',\n",
    "                       cv = stratified_kfold,\n",
    "                       verbose = 5,\n",
    "                       return_train_score = True)\n",
    "\n",
    "startTime = time.time()\n",
    "gs_lgbm.fit(X_train, y_train)\n",
    "executionTime = (time.time() - startTime)\n",
    "print('Execution time in seconds: ' + str(executionTime))\n",
    "print('Execution time in minutes: ' + str(executionTime / 60))\n",
    "\n",
    "cv_score_lgbm_split = gs_lgbm.best_score_\n",
    "print('cv_score_lgbm:', cv_score_lgbm_split)\n",
    "\n",
    "cv_score_lgbm_split = gs_lgbm.cv_results_\n",
    "df_lgbmc_split = pd.DataFrame(cv_score_lgbm_split)\n",
    "df_lgbmc_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "30f8f163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score = 0.7770865841743685\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "# Evaluate model with best parameters on X_test using predict_proba to calculate AUC\n",
    "y_pred = gs_lgbm.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Calculate and print roc_auc score\n",
    "print('roc_auc_score =', roc_auc_score(y_test, y_pred))\n",
    "print('----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605b7902",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "19eaac99",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report :\n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      1.00      0.96     56537\n",
      "         1.0       0.55      0.05      0.10      4965\n",
      "\n",
      "    accuracy                           0.92     61502\n",
      "   macro avg       0.74      0.52      0.53     61502\n",
      "weighted avg       0.89      0.92      0.89     61502\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 33.0, 'predicted label'),\n",
       " Text(51.0, 0.5, 'true label'),\n",
       " Text(0.5, 1.0, 'Confusion Matrix test data')]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate model with best parameters on X_test using predict to calculate precision, recall and f1 score\n",
    "y_pred_binary = gs_lgbm.predict(X_test)\n",
    "\n",
    "# Print classification report with precision, recall and f1-score for each class\n",
    "from sklearn.metrics import classification_report\n",
    "print('classification_report :')\n",
    "print(' ')\n",
    "print(classification_report(y_test, y_pred_binary))\n",
    "\n",
    "# Print Confusion Matrix on Test data\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(y_test, y_pred_binary)\n",
    "data_cm = pd.DataFrame(conf_mat,\n",
    "                       index = ['can repay', 'can not repay'],\n",
    "                       columns = ['can repay', 'can not repay'])\n",
    "\n",
    "plt.figure(figsize = (8,6))\n",
    "cmap = 'YlOrBr'\n",
    "colormap = sns.heatmap(data_cm, \n",
    "                        annot=True, \n",
    "                        annot_kws ={'size':14}, \n",
    "                        cmap=cmap, \n",
    "                        fmt='.3g')\n",
    "colormap.set_xticklabels(colormap.get_xmajorticklabels(), size = 16)\n",
    "colormap.set_yticklabels(colormap.get_ymajorticklabels(), size = 16)\n",
    "    \n",
    "colormap.set(xlabel = 'predicted label',\n",
    "             ylabel = 'true label',\n",
    "             title = 'Confusion Matrix test data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0ec04785",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report :\n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.95      0.96     56537\n",
      "         1.0       0.53      0.63      0.57      4965\n",
      "\n",
      "    accuracy                           0.92     61502\n",
      "   macro avg       0.75      0.79      0.77     61502\n",
      "weighted avg       0.93      0.92      0.93     61502\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 33.0, 'predicted label'),\n",
       " Text(51.0, 0.5, 'true label'),\n",
       " Text(0.5, 1.0, 'Confusion Matrix test data')]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate model with best parameters on X_test using predict to calculate precision, recall and f1 score\n",
    "y_pred_binary_thres = (gs_lgbm.predict_proba(X_test)[:,1] >= 0.2).astype(bool)\n",
    "\n",
    "# Print classification report with precision, recall and f1-score for each class\n",
    "from sklearn.metrics import classification_report\n",
    "print('classification_report :')\n",
    "print(' ')\n",
    "print(classification_report(y_test, y_pred_binary_thres))\n",
    "\n",
    "# Print Confusion Matrix on Test data\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(y_test, y_pred_binary_thres)\n",
    "data_cm = pd.DataFrame(conf_mat,\n",
    "                       index = ['can repay', 'can not repay'],\n",
    "                       columns = ['can repay', 'can not repay'])\n",
    "\n",
    "plt.figure(figsize = (8,6))\n",
    "cmap = 'YlOrBr'\n",
    "colormap = sns.heatmap(data_cm, \n",
    "                        annot=True, \n",
    "                        annot_kws ={'size':14}, \n",
    "                        cmap=cmap, \n",
    "                        fmt='.3g')\n",
    "colormap.set_xticklabels(colormap.get_xmajorticklabels(), size = 16)\n",
    "colormap.set_yticklabels(colormap.get_ymajorticklabels(), size = 16)\n",
    "    \n",
    "colormap.set(xlabel = 'predicted label',\n",
    "             ylabel = 'true label',\n",
    "             title = 'Confusion Matrix test data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c3dd044c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report :\n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.82      0.90     56537\n",
      "         1.0       0.30      0.85      0.44      4965\n",
      "\n",
      "    accuracy                           0.82     61502\n",
      "   macro avg       0.64      0.84      0.67     61502\n",
      "weighted avg       0.93      0.82      0.86     61502\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 33.0, 'predicted label'),\n",
       " Text(51.0, 0.5, 'true label'),\n",
       " Text(0.5, 1.0, 'Confusion Matrix test data')]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate model with best parameters on X_test using predict to calculate precision, recall and f1 score\n",
    "y_pred_binary_thres = (gs_lgbm.predict_proba(X_test)[:,1] >= 0.1).astype(bool)\n",
    "\n",
    "# Print classification report with precision, recall and f1-score for each class\n",
    "from sklearn.metrics import classification_report\n",
    "print('classification_report :')\n",
    "print(' ')\n",
    "print(classification_report(y_test, y_pred_binary_thres))\n",
    "\n",
    "# Print Confusion Matrix on Test data\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(y_test, y_pred_binary_thres)\n",
    "data_cm = pd.DataFrame(conf_mat,\n",
    "                       index = ['can repay', 'can not repay'],\n",
    "                       columns = ['can repay', 'can not repay'])\n",
    "\n",
    "plt.figure(figsize = (8,6))\n",
    "cmap = 'YlOrBr'\n",
    "colormap = sns.heatmap(data_cm, \n",
    "                        annot=True, \n",
    "                        annot_kws ={'size':14}, \n",
    "                        cmap=cmap, \n",
    "                        fmt='.3g')\n",
    "colormap.set_xticklabels(colormap.get_xmajorticklabels(), size = 16)\n",
    "colormap.set_yticklabels(colormap.get_ymajorticklabels(), size = 16)\n",
    "    \n",
    "colormap.set(xlabel = 'predicted label',\n",
    "             ylabel = 'true label',\n",
    "             title = 'Confusion Matrix test data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8468ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1f125c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e05911e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay, precision_recall_curve, det_curve\n",
    "\n",
    "fpr, fnr, thresholds = det_curve(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "37df4d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.99204061e-01, 9.99204061e-01, 9.99186374e-01, ...,\n",
       "       1.76875321e-05, 1.76875321e-05, 0.00000000e+00])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "125c3e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 2.01409869e-04, 2.01409869e-04, ...,\n",
       "       9.99597180e-01, 9.99798590e-01, 9.99798590e-01])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "47d230bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00214957, 0.00217276, 0.00218024, ..., 0.89833885, 0.90453226,\n",
       "       0.93136308])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b64a6bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds2 = precision_recall_curve(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a9c4ee5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08078819, 0.08077324, 0.08077455, ..., 0.5       , 1.        ,\n",
       "       1.        ])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1e0df947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e+00, 9.99798590e-01, 9.99798590e-01, ...,\n",
       "       2.01409869e-04, 2.01409869e-04, 0.00000000e+00])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a42061ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00214957, 0.00217276, 0.00218024, ..., 0.89833885, 0.90453226,\n",
       "       0.93136308])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e196a444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "disp = PrecisionRecallDisplay(precision = precision, recall = recall)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "af7f077d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06417506761740842"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import fbeta_score, recall_score, precision_score, f1_score\n",
    "\n",
    "fbeta_score(y_test, y_pred_binary, average = 'binary', beta = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ace251f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall = 0.05256797583081571\n",
      "precision = 0.5494736842105263\n",
      "------------------\n",
      "f1_score = 0.09595588235294118\n",
      "------------------\n",
      "f2_score = 0.06417506761740842\n",
      "------------------\n",
      "f0.5_score = 0.19009468317552802\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "print('recall =', recall_score(y_test, y_pred_binary))\n",
    "print('precision =', precision_score(y_test, y_pred_binary))\n",
    "print('------------------')\n",
    "print('f1_score =', fbeta_score(y_test, y_pred_binary, average = 'binary', beta = 1))\n",
    "print('------------------')\n",
    "print('f2_score =', fbeta_score(y_test, y_pred_binary, average = 'binary', beta = 2))\n",
    "print('------------------')\n",
    "print('f0.5_score =', fbeta_score(y_test, y_pred_binary, average = 'binary', beta = 0.5))\n",
    "print('------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "88acf206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05256797583081571"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9cf6f615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5494736842105263"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22706a40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c688642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0cbcce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d5b397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f20572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f7a9be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "078f3e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def business_cost_func(y_true, y_pred):\n",
    "    # Build confusion matrix\n",
    "    conf_mat = confusion_matrix(y_true, y_pred)    \n",
    "    # Define true positives, false positives, false negatives and true negatives\n",
    "    FP = conf_mat[0][1]\n",
    "    FN = conf_mat[1][0]\n",
    "    # Define business cost function\n",
    "    cost = (10 * FN + FP) / y_true.size\n",
    "\n",
    "    return cost\n",
    "\n",
    "business_cost_loss = make_scorer(business_cost_func, greater_is_better = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "31c3f446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7683327371467594"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_loss = business_cost_func(y_test, y_pred_binary)\n",
    "cost_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "34c92ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END classifier__n_estimators=500;, score=(train=0.682, test=0.771) total time=  41.2s\n",
      "[CV 2/5] END classifier__n_estimators=500;, score=(train=0.687, test=0.771) total time=  39.3s\n",
      "[CV 3/5] END classifier__n_estimators=500;, score=(train=0.683, test=0.776) total time=  35.8s\n",
      "[CV 4/5] END classifier__n_estimators=500;, score=(train=0.685, test=0.767) total time=  39.4s\n",
      "[CV 5/5] END classifier__n_estimators=500;, score=(train=0.683, test=0.772) total time=  37.5s\n",
      "Execution time in seconds: 255.33988571166992\n",
      "Execution time in minutes: 4.255664761861166\n",
      "cv_score_lgbm: 0.7715336578748245\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.776258</td>\n",
       "      <td>1.786328</td>\n",
       "      <td>0.970662</td>\n",
       "      <td>0.062863</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__n_estimators': 500}</td>\n",
       "      <td>0.771227</td>\n",
       "      <td>0.771308</td>\n",
       "      <td>0.775516</td>\n",
       "      <td>0.767142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771534</td>\n",
       "      <td>0.00269</td>\n",
       "      <td>1</td>\n",
       "      <td>0.681885</td>\n",
       "      <td>0.687124</td>\n",
       "      <td>0.683284</td>\n",
       "      <td>0.68463</td>\n",
       "      <td>0.68328</td>\n",
       "      <td>0.684041</td>\n",
       "      <td>0.001769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      37.776258      1.786328         0.970662        0.062863   \n",
       "\n",
       "  param_classifier__n_estimators                             params  \\\n",
       "0                            500  {'classifier__n_estimators': 500}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.771227           0.771308           0.775516           0.767142   \n",
       "\n",
       "   ...  mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0  ...         0.771534         0.00269                1            0.681885   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0            0.687124            0.683284             0.68463   \n",
       "\n",
       "   split4_train_score  mean_train_score  std_train_score  \n",
       "0             0.68328          0.684041         0.001769  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Create pipeline (imbpipeline) with smote, scaler and classifier steps\n",
    "# imbpipeline automatically skip the sampling method (smote) when predict is called\n",
    "# -> Consequently, there is no data leakage\n",
    "pipeline = Pipeline(steps = [['classifier', LGBMClassifier(random_state = 11)]])\n",
    "\n",
    "# Define stratifiedKfold\n",
    "stratified_kfold = StratifiedKFold(n_splits = 5,\n",
    "                                   shuffle = True,\n",
    "                                   random_state = 11)\n",
    "\n",
    "param_grid = {'classifier__n_estimators' : [500]}\n",
    "\n",
    "gs_lgbm = GridSearchCV(estimator = pipeline,\n",
    "                       param_grid = param_grid,\n",
    "                       scoring = business_cost,\n",
    "                       cv = stratified_kfold,\n",
    "                       verbose = 5,\n",
    "                       return_train_score = True)\n",
    "\n",
    "startFitTime = time.time()\n",
    "gs_lgbm.fit(X, y)\n",
    "executionFitTime = (time.time() - startFitTime)\n",
    "print('Execution time in seconds: ' + str(executionFitTime))\n",
    "print('Execution time in minutes: ' + str(executionFitTime / 60))\n",
    "\n",
    "cv_score_lgbm = gs_lgbm.best_score_\n",
    "print('cv_score_lgbm:', cv_score_lgbm)\n",
    "\n",
    "cv_results_lgbm = gs_lgbm.cv_results_\n",
    "df_lgbmc = pd.DataFrame(cv_results_lgbm)\n",
    "df_lgbmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f2cebf71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV 1/5] END classifier__n_estimators=100;, score=(train=-0.767, test=-0.782) total time=  22.0s\n",
      "[CV 2/5] END classifier__n_estimators=100;, score=(train=-0.769, test=-0.783) total time=  18.7s\n",
      "[CV 3/5] END classifier__n_estimators=100;, score=(train=-0.767, test=-0.782) total time=  19.3s\n",
      "[CV 4/5] END classifier__n_estimators=100;, score=(train=-0.769, test=-0.777) total time=  20.5s\n",
      "[CV 5/5] END classifier__n_estimators=100;, score=(train=-0.765, test=-0.783) total time=  21.4s\n",
      "[CV 1/5] END classifier__n_estimators=500;, score=(train=-0.682, test=-0.771) total time=  40.5s\n",
      "[CV 2/5] END classifier__n_estimators=500;, score=(train=-0.687, test=-0.771) total time=  37.5s\n",
      "[CV 3/5] END classifier__n_estimators=500;, score=(train=-0.683, test=-0.776) total time=  39.8s\n",
      "[CV 4/5] END classifier__n_estimators=500;, score=(train=-0.685, test=-0.767) total time=  36.4s\n",
      "[CV 5/5] END classifier__n_estimators=500;, score=(train=-0.683, test=-0.772) total time=  36.5s\n",
      "Execution time in seconds: 372.0367739200592\n",
      "Execution time in minutes: 6.200612898667654\n",
      "cv_score_lgbm: -0.7715336578748245\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.724158</td>\n",
       "      <td>1.249534</td>\n",
       "      <td>0.753426</td>\n",
       "      <td>0.061971</td>\n",
       "      <td>100</td>\n",
       "      <td>{'classifier__n_estimators': 100}</td>\n",
       "      <td>-0.782040</td>\n",
       "      <td>-0.783275</td>\n",
       "      <td>-0.781987</td>\n",
       "      <td>-0.776622</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.781423</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.767098</td>\n",
       "      <td>-0.769151</td>\n",
       "      <td>-0.766741</td>\n",
       "      <td>-0.769396</td>\n",
       "      <td>-0.764506</td>\n",
       "      <td>-0.767378</td>\n",
       "      <td>0.001786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37.292613</td>\n",
       "      <td>1.713569</td>\n",
       "      <td>0.935043</td>\n",
       "      <td>0.024742</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__n_estimators': 500}</td>\n",
       "      <td>-0.771227</td>\n",
       "      <td>-0.771308</td>\n",
       "      <td>-0.775516</td>\n",
       "      <td>-0.767142</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.771534</td>\n",
       "      <td>0.002690</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.681885</td>\n",
       "      <td>-0.687124</td>\n",
       "      <td>-0.683284</td>\n",
       "      <td>-0.684630</td>\n",
       "      <td>-0.683280</td>\n",
       "      <td>-0.684041</td>\n",
       "      <td>0.001769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      19.724158      1.249534         0.753426        0.061971   \n",
       "1      37.292613      1.713569         0.935043        0.024742   \n",
       "\n",
       "  param_classifier__n_estimators                             params  \\\n",
       "0                            100  {'classifier__n_estimators': 100}   \n",
       "1                            500  {'classifier__n_estimators': 500}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0          -0.782040          -0.783275          -0.781987          -0.776622   \n",
       "1          -0.771227          -0.771308          -0.775516          -0.767142   \n",
       "\n",
       "   ...  mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0  ...        -0.781423        0.002462                2           -0.767098   \n",
       "1  ...        -0.771534        0.002690                1           -0.681885   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0           -0.769151           -0.766741           -0.769396   \n",
       "1           -0.687124           -0.683284           -0.684630   \n",
       "\n",
       "   split4_train_score  mean_train_score  std_train_score  \n",
       "0           -0.764506         -0.767378         0.001786  \n",
       "1           -0.683280         -0.684041         0.001769  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Create pipeline (imbpipeline) with smote, scaler and classifier steps\n",
    "# imbpipeline automatically skip the sampling method (smote) when predict is called\n",
    "# -> Consequently, there is no data leakage\n",
    "pipeline = Pipeline(steps = [['classifier', LGBMClassifier(random_state = 11)]])\n",
    "\n",
    "# Define stratifiedKfold\n",
    "stratified_kfold = StratifiedKFold(n_splits = 5,\n",
    "                                   shuffle = True,\n",
    "                                   random_state = 11)\n",
    "\n",
    "param_grid = {'classifier__n_estimators' : [100, 500]}\n",
    "\n",
    "gs_lgbm = GridSearchCV(estimator = pipeline,\n",
    "                       param_grid = param_grid,\n",
    "                       scoring = business_cost_loss,\n",
    "                       cv = stratified_kfold,\n",
    "                       verbose = 5,\n",
    "                       return_train_score = True)\n",
    "\n",
    "startFitTime = time.time()\n",
    "gs_lgbm.fit(X, y)\n",
    "executionFitTime = (time.time() - startFitTime)\n",
    "print('Execution time in seconds: ' + str(executionFitTime))\n",
    "print('Execution time in minutes: ' + str(executionFitTime / 60))\n",
    "\n",
    "cv_score_lgbm = gs_lgbm.best_score_\n",
    "print('cv_score_lgbm:', cv_score_lgbm)\n",
    "\n",
    "cv_results_lgbm = gs_lgbm.cv_results_\n",
    "df_lgbmc = pd.DataFrame(cv_results_lgbm)\n",
    "df_lgbmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42160f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31298b47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54800d27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e379b48e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['explained_variance', 'r2', 'max_error', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_absolute_percentage_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_root_mean_squared_error', 'neg_mean_poisson_deviance', 'neg_mean_gamma_deviance', 'accuracy', 'top_k_accuracy', 'roc_auc', 'roc_auc_ovr', 'roc_auc_ovo', 'roc_auc_ovr_weighted', 'roc_auc_ovo_weighted', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'neg_brier_score', 'adjusted_rand_score', 'rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.SCORERS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a5b628",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
